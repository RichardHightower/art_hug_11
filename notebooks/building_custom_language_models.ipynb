{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Building Custom Language Models: From Raw Data to Production AI\n",
    "\n",
    "In today's rapidly evolving AI landscape, the ability to create custom language models tailored to specific domains represents a **critical competitive advantage**. This comprehensive guide walks you through the complete lifecycle of building language models‚Äîfrom curating high-quality datasets to training and deploying powerful AI systems that deliver real business value.\n",
    "\n",
    "Whether you're developing specialized models for healthcare, finance, legal services, or any domain requiring nuanced understanding, this notebook provides the **practical knowledge and code examples** you need to succeed. We'll explore modern techniques using the Hugging Face ecosystem that balance efficiency, scalability, and model quality.\n",
    "\n",
    "## üìë Table of Contents\n",
    "\n",
    "1. [Environment Setup](#environment-setup)\n",
    "2. [Dataset Curation Fundamentals](#dataset-curation)\n",
    "3. [Text Cleaning and Processing](#text-cleaning)\n",
    "4. [Bias Detection and Mitigation](#bias-detection)\n",
    "5. [Custom Tokenizer Training](#tokenizer-training)\n",
    "6. [Scalable Data Processing](#scalable-processing)\n",
    "7. [Model Configuration and Initialization](#model-configuration)\n",
    "8. [Parameter-Efficient Fine-Tuning](#peft)\n",
    "9. [Training and Monitoring](#training)\n",
    "10. [Error Analysis and Iteration](#error-analysis)\n",
    "\n",
    "## üìã What You'll Master\n",
    "\n",
    "- **Data curation fundamentals**: selecting, cleaning, and preparing domain-specific text\n",
    "- **Scalable processing techniques** for handling massive datasets efficiently  \n",
    "- **Privacy protection and data versioning** for responsible AI development\n",
    "- **Modern model architecture selection** and configuration strategies\n",
    "- **Training workflows** with distributed computing and experiment tracking\n",
    "- **Parameter-efficient fine-tuning methods** for adapting large models\n",
    "- **Evaluation, error analysis**, and iterative improvement techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Environment Setup <a id='environment-setup'></a>\n",
    "\n",
    "Let's start by setting up our environment with all the necessary libraries. We'll use the latest versions of the Hugging Face ecosystem tools.\n",
    "\n",
    "### üìã Prerequisites\n",
    "\n",
    "1. **Python 3.12.9** - Required for consistency with the project's Poetry lock file\n",
    "2. **Poetry** - For dependency management\n",
    "3. **API Keys** (optional) - For external services\n",
    "\n",
    "### üîê API Key Configuration\n",
    "\n",
    "Before running examples that require external APIs, create a `.env` file:\n",
    "\n",
    "```bash\n",
    "# Copy the example environment file\n",
    "cp .env.example .env\n",
    "\n",
    "# Edit .env and add your actual API keys:\n",
    "# - OPENAI_API_KEY (optional - for OpenAI examples)\n",
    "# - ANTHROPIC_API_KEY (optional - for Claude examples)  \n",
    "# - HUGGINGFACE_TOKEN (optional - for private model access)\n",
    "```\n",
    "\n",
    "‚ö†Ô∏è **Important**: Make sure your API keys are actual values, not placeholders like \"your-api-key-here\"\n",
    "\n",
    "### ‚ö° Important Dependencies\n",
    "\n",
    "- **accelerate>=0.26.0** - Required version for compatibility with model configurations\n",
    "- **bitsandbytes** - Note: Shows warnings on macOS (Metal/MPS not supported, falls back to CPU)\n",
    "\n",
    "### üì¶ Installation\n",
    "\n",
    "```bash\n",
    "# Using Poetry (recommended)\n",
    "poetry install\n",
    "\n",
    "# Or install specific requirements\n",
    "poetry add accelerate@^0.26.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key Status:\n",
      "‚ö†Ô∏è OPENAI_API_KEY not found in environment variables\n",
      "  OPENAI_API_KEY: ‚ùå Not set\n",
      "‚ö†Ô∏è ANTHROPIC_API_KEY not found in environment variables\n",
      "  ANTHROPIC_API_KEY: ‚ùå Not set\n",
      "‚ö†Ô∏è HUGGINGFACE_TOKEN not found in environment variables\n",
      "  HUGGINGFACE_TOKEN: ‚ùå Not set\n",
      "\n",
      "‚úÖ datasets library loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0728 14:31:14.174000 81069 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PEFT library loaded successfully\n",
      "\n",
      "üñ•Ô∏è Using device: cpu\n",
      "üì¶ PyTorch version: 2.7.1\n",
      "üì¶ Transformers version: 4.39.3\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Validate API keys (optional)\n",
    "def validate_api_key(key_name: str, key_value: Optional[str]) -> bool:\n",
    "    \"\"\"Validate an API key is set and not a placeholder.\"\"\"\n",
    "    if not key_value or key_value.strip() == \"\":\n",
    "        print(f\"‚ö†Ô∏è {key_name} not found in environment variables\")\n",
    "        return False\n",
    "    if key_value.lower() in [\"your-api-key-here\", \"placeholder\", \"xxx\", \"todo\"]:\n",
    "        print(f\"‚ö†Ô∏è {key_name} contains a placeholder value\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Check API keys\n",
    "api_keys = {\n",
    "    \"OPENAI_API_KEY\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "    \"ANTHROPIC_API_KEY\": os.getenv(\"ANTHROPIC_API_KEY\"),\n",
    "    \"HUGGINGFACE_TOKEN\": os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "}\n",
    "\n",
    "print(\"API Key Status:\")\n",
    "for key_name, key_value in api_keys.items():\n",
    "    status = \"‚úÖ Set\" if validate_api_key(key_name, key_value) else \"‚ùå Not set\"\n",
    "    print(f\"  {key_name}: {status}\")\n",
    "\n",
    "# Hugging Face ecosystem\n",
    "try:\n",
    "    from datasets import load_dataset, Dataset, DatasetDict\n",
    "    print(\"\\n‚úÖ datasets library loaded successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"\\n‚ùå Error loading datasets: {e}\")\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM,\n",
    "    AutoConfig,\n",
    "    GPT2Config, \n",
    "    GPT2LMHeadModel,\n",
    "    PreTrainedTokenizerFast,\n",
    "    Trainer, \n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, trainers\n",
    "\n",
    "try:\n",
    "    from peft import LoraConfig, get_peft_model, TaskType\n",
    "    print(\"‚úÖ PEFT library loaded successfully\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå PEFT library not available - LoRA examples will be skipped\")\n",
    "\n",
    "# Utility imports\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import unicodedata\n",
    "\n",
    "# Check available device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nüñ•Ô∏è Using device: {device}\")\n",
    "print(f\"üì¶ PyTorch version: {torch.__version__}\")\n",
    "\n",
    "import transformers\n",
    "print(f\"üì¶ Transformers version: {transformers.__version__}\")\n",
    "\n",
    "# Suppress bitsandbytes warnings on macOS\n",
    "if device.type == \"cpu\":\n",
    "    os.environ[\"BITSANDBYTES_NOWELCOME\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Dataset Curation and Training Language Models from Scratch <a id='dataset-curation'></a>\n",
    "\n",
    "To build a great language model, you need great data. Let's visualize the complete pipeline from raw data to a production-ready model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "mindmap\n",
    "  root((Dataset Curation & Training LLMs))\n",
    "    Data Quality Foundation\n",
    "      Source Selection\n",
    "      Cleaning & Deduplication\n",
    "      Labeling & Annotation\n",
    "      Domain Relevance\n",
    "    Modern Processing\n",
    "      Streaming & Batching\n",
    "      Cloud Integration\n",
    "      Privacy & Compliance\n",
    "      Versioning & Reproducibility\n",
    "    Model Configuration\n",
    "      Architecture Selection\n",
    "      Parameter-Efficient Methods\n",
    "      Pre-trained vs Scratch\n",
    "      Distributed Training\n",
    "    Training Workflow\n",
    "      Monitoring & Metrics\n",
    "      Early Stopping\n",
    "      Checkpointing\n",
    "      Iterative Improvement\n",
    "    Production Ready\n",
    "      Experiment Tracking\n",
    "      Error Analysis\n",
    "      Human-in-the-Loop\n",
    "      Deployment Pipeline\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Why Data Quality Matters\n",
    "\n",
    "\"Garbage in, garbage out\" remains a core truth in AI. If your dataset contains messy, biased, or irrelevant content, your model will reflect those flaws with painful accuracy. Let's start with a practical example of loading and examining data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 5 examples\n",
      "\n",
      "First example:\n",
      "{'text': 'The patient presented with acute myocardial infarction and was treated with aspirin.', 'domain': 'medical'}\n"
     ]
    }
   ],
   "source": [
    "# Load a small sample dataset for demonstration\n",
    "# In production, you'd load your domain-specific data\n",
    "sample_data = {\n",
    "    \"text\": [\n",
    "        \"The patient presented with acute myocardial infarction and was treated with aspirin.\",\n",
    "        \"<p>Click here for more info!</p> Visit our website at https://example.com\",\n",
    "        \"The quarterly earnings report shows a 15% increase in revenue.\",\n",
    "        \"Contact Dr. Smith at dr.smith@hospital.com or call 555-123-4567.\",\n",
    "        \"The    text   has    too    many     spaces     and\\n\\nnewlines.\"\n",
    "    ],\n",
    "    \"domain\": [\"medical\", \"web\", \"financial\", \"medical\", \"general\"]\n",
    "}\n",
    "\n",
    "# Create a dataset\n",
    "raw_dataset = Dataset.from_dict(sample_data)\n",
    "print(f\"Dataset size: {len(raw_dataset)} examples\")\n",
    "print(f\"\\nFirst example:\")\n",
    "print(raw_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßΩ Text Cleaning and Processing <a id='text-cleaning'></a>\n",
    "\n",
    "Clean data is the foundation of any successful language model. Let's implement a comprehensive text cleaning pipeline that handles common issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581b9bfac9eb4502830b33de228c7b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE CLEANING:\n",
      "0: The patient presented with acute myocardial infarction and was treated with aspirin....\n",
      "1: <p>Click here for more info!</p> Visit our website at https://example.com...\n",
      "2: The quarterly earnings report shows a 15% increase in revenue....\n",
      "\n",
      "AFTER CLEANING:\n",
      "0: The patient presented with acute myocardial infarction and was treated with aspirin....\n",
      "1: Click here for more info! Visit our website at...\n",
      "2: The quarterly earnings report shows a 15% increase in revenue....\n"
     ]
    }
   ],
   "source": [
    "def clean_text(example: Dict[str, str]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Comprehensive text cleaning function that handles:\n",
    "    - Unicode normalization\n",
    "    - HTML tag removal\n",
    "    - URL removal\n",
    "    - Whitespace normalization\n",
    "    \n",
    "    Args:\n",
    "        example: Dictionary with 'text' key\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with cleaned 'text' and preserved metadata\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text = example[\"text\"]\n",
    "        \n",
    "        # Unicode normalization\n",
    "        text = unicodedata.normalize('NFKC', text)\n",
    "        \n",
    "        # Remove HTML tags\n",
    "        text = re.sub(r'<.*?>', '', text)\n",
    "        \n",
    "        # Remove URLs\n",
    "        text = re.sub(r'https?://\\S+', '', text)\n",
    "        \n",
    "        # Normalize whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        \n",
    "        # Strip leading/trailing whitespace\n",
    "        text = text.strip()\n",
    "        \n",
    "        return {\"text\": text, \"domain\": example.get(\"domain\", \"unknown\")}\n",
    "    \n",
    "    except KeyError as e:\n",
    "        print(f\"Error: Missing required key {e}\")\n",
    "        return example\n",
    "    except Exception as e:\n",
    "        print(f\"Error cleaning text: {e}\")\n",
    "        return example\n",
    "\n",
    "# Apply cleaning to our dataset\n",
    "cleaned_dataset = raw_dataset.map(clean_text)\n",
    "\n",
    "# Compare before and after\n",
    "print(\"BEFORE CLEANING:\")\n",
    "for i in range(min(3, len(raw_dataset))):\n",
    "    print(f\"{i}: {raw_dataset[i]['text'][:100]}...\")\n",
    "\n",
    "print(\"\\nAFTER CLEANING:\")\n",
    "for i in range(min(3, len(cleaned_dataset))):\n",
    "    print(f\"{i}: {cleaned_dataset[i]['text'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Data Quality Metrics\n",
    "\n",
    "Let's analyze our cleaned data to understand its characteristics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Quality Summary:\n",
      "Total examples: 5\n",
      "\n",
      "Text Length Statistics:\n",
      "count     5.000000\n",
      "mean     59.600000\n",
      "std      16.697305\n",
      "min      42.000000\n",
      "25%      46.000000\n",
      "50%      62.000000\n",
      "75%      64.000000\n",
      "max      84.000000\n",
      "Name: length, dtype: float64\n",
      "\n",
      "Word Count Statistics:\n",
      "count     5.00000\n",
      "mean      9.40000\n",
      "std       1.67332\n",
      "min       8.00000\n",
      "25%       8.00000\n",
      "50%       9.00000\n",
      "75%      10.00000\n",
      "max      12.00000\n",
      "Name: word_count, dtype: float64\n",
      "\n",
      "Domain Distribution:\n",
      "domain\n",
      "medical      2\n",
      "web          1\n",
      "financial    1\n",
      "general      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def analyze_dataset_quality(dataset: Dataset) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyze dataset quality metrics\n",
    "    \"\"\"\n",
    "    metrics = []\n",
    "    \n",
    "    for example in dataset:\n",
    "        text = example[\"text\"]\n",
    "        metrics.append({\n",
    "            \"length\": len(text),\n",
    "            \"word_count\": len(text.split()),\n",
    "            \"avg_word_length\": np.mean([len(word) for word in text.split()]) if text.split() else 0,\n",
    "            \"domain\": example.get(\"domain\", \"unknown\")\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(metrics)\n",
    "    \n",
    "    print(\"Dataset Quality Summary:\")\n",
    "    print(f\"Total examples: {len(df)}\")\n",
    "    print(f\"\\nText Length Statistics:\")\n",
    "    print(df[\"length\"].describe())\n",
    "    print(f\"\\nWord Count Statistics:\")\n",
    "    print(df[\"word_count\"].describe())\n",
    "    print(f\"\\nDomain Distribution:\")\n",
    "    print(df[\"domain\"].value_counts())\n",
    "    \n",
    "    return df\n",
    "\n",
    "quality_df = analyze_dataset_quality(cleaned_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è Bias Detection and Mitigation <a id='bias-detection'></a>\n",
    "\n",
    "Beyond accuracy, ensuring fairness and ethical AI requires proactive bias detection. Let's implement a simple bias detection framework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential Bias Indicators:\n",
      "he: 4\n",
      "she: 0\n",
      "his: 0\n",
      "her: 1\n",
      "man: 1\n",
      "woman: 0\n",
      "male: 0\n",
      "female: 0\n",
      "\n",
      "Gender indicator ratio (male/female): 5.00\n"
     ]
    }
   ],
   "source": [
    "def detect_potential_bias(dataset: Dataset, sensitive_terms: List[str]) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Simple bias detection by checking for sensitive terms\n",
    "    \"\"\"\n",
    "    bias_counts = {term: 0 for term in sensitive_terms}\n",
    "    \n",
    "    for example in dataset:\n",
    "        text_lower = example[\"text\"].lower()\n",
    "        for term in sensitive_terms:\n",
    "            if term.lower() in text_lower:\n",
    "                bias_counts[term] += 1\n",
    "    \n",
    "    return bias_counts\n",
    "\n",
    "# Example: Check for potential gender bias\n",
    "sensitive_terms = [\"he\", \"she\", \"his\", \"her\", \"man\", \"woman\", \"male\", \"female\"]\n",
    "bias_results = detect_potential_bias(cleaned_dataset, sensitive_terms)\n",
    "\n",
    "print(\"Potential Bias Indicators:\")\n",
    "for term, count in bias_results.items():\n",
    "    print(f\"{term}: {count}\")\n",
    "\n",
    "# Calculate gender balance ratio\n",
    "male_indicators = sum([bias_results.get(term, 0) for term in [\"he\", \"his\", \"man\", \"male\"]])\n",
    "female_indicators = sum([bias_results.get(term, 0) for term in [\"she\", \"her\", \"woman\", \"female\"]])\n",
    "\n",
    "if female_indicators > 0:\n",
    "    gender_ratio = male_indicators / female_indicators\n",
    "    print(f\"\\nGender indicator ratio (male/female): {gender_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Detection Examples:\n",
      "'This is English text.' -> Language: en\n",
      "'Ceci est du texte fran√ßais.' -> Language: fr\n",
      "'Dies ist deutscher Text.' -> Language: de\n",
      "Unexpected error in language detection: No features in text.\n",
      "'12345' -> Could not detect language\n",
      "Unexpected error in language detection: No features in text.\n",
      "'' -> Could not detect language\n"
     ]
    }
   ],
   "source": [
    "# Language detection with proper error handling\n",
    "try:\n",
    "    from langdetect import detect\n",
    "    HAS_LANGDETECT = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è langdetect not available - install with: pip install langdetect\")\n",
    "    HAS_LANGDETECT = False\n",
    "\n",
    "def safe_detect_language(text: str) -> Optional[str]:\n",
    "    \"\"\"Safely detect language with error handling.\"\"\"\n",
    "    if not HAS_LANGDETECT:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        return detect(text)\n",
    "    except (LookupError, ValueError) as e:\n",
    "        # LookupError: langdetect couldn't detect language\n",
    "        # ValueError: invalid input text\n",
    "        print(f\"Language detection error: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error in language detection: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test language detection\n",
    "if HAS_LANGDETECT:\n",
    "    test_texts = [\n",
    "        \"This is English text.\",\n",
    "        \"Ceci est du texte fran√ßais.\",\n",
    "        \"Dies ist deutscher Text.\",\n",
    "        \"12345\",  # May cause detection error\n",
    "        \"\"  # Empty text will cause error\n",
    "    ]\n",
    "    \n",
    "    print(\"Language Detection Examples:\")\n",
    "    for text in test_texts:\n",
    "        lang = safe_detect_language(text)\n",
    "        if lang:\n",
    "            print(f\"'{text}' -> Language: {lang}\")\n",
    "        else:\n",
    "            print(f\"'{text}' -> Could not detect language\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def generate_synthetic_examples(templates: List[str], \n",
    "                              categories: List[str], \n",
    "                              num_examples: int = 10) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Generate synthetic training examples using templates.\n",
    "    \n",
    "    Args:\n",
    "        templates: List of template strings with {entity}, {action}, {value} placeholders\n",
    "        categories: List of domain categories to generate examples for\n",
    "        num_examples: Number of examples to generate\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries with 'text', 'domain', and 'synthetic' keys\n",
    "        \n",
    "    Note: In production, you'd use an LLM for more sophisticated generation\n",
    "    \"\"\"\n",
    "    import random\n",
    "    \n",
    "    synthetic_data: List[Dict[str, str]] = []\n",
    "    \n",
    "    # Example entities for each category\n",
    "    entities = {\n",
    "        \"medical\": [\"patient\", \"doctor\", \"nurse\", \"treatment\", \"diagnosis\"],\n",
    "        \"financial\": [\"revenue\", \"profit\", \"investment\", \"market\", \"portfolio\"],\n",
    "        \"technical\": [\"system\", \"server\", \"database\", \"API\", \"algorithm\"]\n",
    "    }\n",
    "    \n",
    "    actions = {\n",
    "        \"medical\": [\"presented with\", \"diagnosed with\", \"treated for\", \"recovered from\"],\n",
    "        \"financial\": [\"increased by\", \"decreased by\", \"stabilized at\", \"fluctuated around\"],\n",
    "        \"technical\": [\"crashed\", \"updated\", \"optimized\", \"deployed\", \"migrated\"]\n",
    "    }\n",
    "    \n",
    "    for _ in range(num_examples):\n",
    "        category = random.choice(categories)\n",
    "        template = random.choice(templates)\n",
    "        \n",
    "        if category in entities and category in actions:\n",
    "            entity = random.choice(entities[category])\n",
    "            action = random.choice(actions[category])\n",
    "            \n",
    "            text = template.format(\n",
    "                entity=entity,\n",
    "                action=action,\n",
    "                value=random.randint(10, 100)\n",
    "            )\n",
    "            \n",
    "            synthetic_data.append({\n",
    "                \"text\": text,\n",
    "                \"domain\": category,\n",
    "                \"synthetic\": True\n",
    "            })\n",
    "    \n",
    "    return synthetic_data\n",
    "\n",
    "# Generate synthetic examples\n",
    "templates = [\n",
    "    \"The {entity} {action} {value}%.\",\n",
    "    \"According to the report, the {entity} {action} significantly.\",\n",
    "    \"Analysis shows that {entity} {action} in the last quarter.\"\n",
    "]\n",
    "\n",
    "synthetic_examples = generate_synthetic_examples(\n",
    "    templates=templates,\n",
    "    categories=[\"medical\", \"financial\", \"technical\"],\n",
    "    num_examples=5\n",
    ")\n",
    "\n",
    "print(\"Generated Synthetic Examples:\")\n",
    "for i, example in enumerate(synthetic_examples):\n",
    "    print(f\"{i+1}. [{example['domain']}] {example['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Synthetic Examples:\n",
      "1. [technical] According to the report, the API migrated significantly.\n",
      "2. [financial] Analysis shows that profit increased by in the last quarter.\n",
      "3. [medical] Analysis shows that patient diagnosed with in the last quarter.\n",
      "4. [medical] The diagnosis presented with 92%.\n",
      "5. [financial] The investment stabilized at 18%.\n"
     ]
    }
   ],
   "source": [
    "def generate_synthetic_examples(templates: List[str], \n",
    "                              categories: List[str], \n",
    "                              num_examples: int = 10) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Generate synthetic training examples using templates\n",
    "    Note: In production, you'd use an LLM for more sophisticated generation\n",
    "    \"\"\"\n",
    "    import random\n",
    "    \n",
    "    synthetic_data = []\n",
    "    \n",
    "    # Example entities for each category\n",
    "    entities = {\n",
    "        \"medical\": [\"patient\", \"doctor\", \"nurse\", \"treatment\", \"diagnosis\"],\n",
    "        \"financial\": [\"revenue\", \"profit\", \"investment\", \"market\", \"portfolio\"],\n",
    "        \"technical\": [\"system\", \"server\", \"database\", \"API\", \"algorithm\"]\n",
    "    }\n",
    "    \n",
    "    actions = {\n",
    "        \"medical\": [\"presented with\", \"diagnosed with\", \"treated for\", \"recovered from\"],\n",
    "        \"financial\": [\"increased by\", \"decreased by\", \"stabilized at\", \"fluctuated around\"],\n",
    "        \"technical\": [\"crashed\", \"updated\", \"optimized\", \"deployed\", \"migrated\"]\n",
    "    }\n",
    "    \n",
    "    for _ in range(num_examples):\n",
    "        category = random.choice(categories)\n",
    "        template = random.choice(templates)\n",
    "        \n",
    "        if category in entities:\n",
    "            entity = random.choice(entities[category])\n",
    "            action = random.choice(actions[category])\n",
    "            \n",
    "            text = template.format(\n",
    "                entity=entity,\n",
    "                action=action,\n",
    "                value=random.randint(10, 100)\n",
    "            )\n",
    "            \n",
    "            synthetic_data.append({\n",
    "                \"text\": text,\n",
    "                \"domain\": category,\n",
    "                \"synthetic\": True\n",
    "            })\n",
    "    \n",
    "    return synthetic_data\n",
    "\n",
    "# Generate synthetic examples\n",
    "templates = [\n",
    "    \"The {entity} {action} {value}%.\",\n",
    "    \"According to the report, the {entity} {action} significantly.\",\n",
    "    \"Analysis shows that {entity} {action} in the last quarter.\"\n",
    "]\n",
    "\n",
    "synthetic_examples = generate_synthetic_examples(\n",
    "    templates=templates,\n",
    "    categories=[\"medical\", \"financial\", \"technical\"],\n",
    "    num_examples=5\n",
    ")\n",
    "\n",
    "print(\"Generated Synthetic Examples:\")\n",
    "for i, example in enumerate(synthetic_examples):\n",
    "    print(f\"{i+1}. [{example['domain']}] {example['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî§ Custom Tokenizer Training <a id='tokenizer-training'></a>\n",
    "\n",
    "Clean, labeled data stands almost ready‚Äîbut models can't use raw text. They need tokens. Let's train a custom tokenizer optimized for our domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus size: 5 documents\n",
      "Sample document: The patient presented with acute myocardial infarction and was treated with aspirin....\n"
     ]
    }
   ],
   "source": [
    "# Create corpus from our cleaned dataset for tokenizer training\n",
    "corpus = [example[\"text\"] for example in cleaned_dataset]\n",
    "print(f\"Corpus size: {len(corpus)} documents\")\n",
    "print(f\"Sample document: {corpus[0][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading medical corpus for tokenizer training...\n",
      "Loading PubMed abstracts from Hugging Face...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72c786bf3b1d4845bbf7491e51c36f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load PubMed dataset: Invalid pattern: '**' can only be an entire path component\n",
      "Falling back to synthetic medical corpus...\n",
      "\n",
      "Corpus statistics:\n",
      "- Total documents: 5964\n",
      "- Average length: 5.5 words\n",
      "- Total words: 32,705\n",
      "\n",
      "Sample corpus entries:\n",
      "1. The patient presented with acute myocardial infarction characterized by ST-segment elevation on electrocardiogram. Immediate percutaneous coronary int...\n",
      "2. the patient presented with acute myocardial infarction characterized by st-segment elevation on electrocardiogram. immediate percutaneous coronary int...\n",
      "3. THE PATIENT PRESENTED WITH ACUTE MYOCARDIAL INFARCTION CHARACTERIZED BY ST-SEGMENT ELEVATION ON ELECTROCARDIOGRAM. IMMEDIATE PERCUTANEOUS CORONARY INT...\n",
      "\n",
      "Training BPE tokenizer with vocab_size=10000...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Medical tokenizer saved to ./medical_tokenizer.json\n",
      "\n",
      "Quick tokenization test:\n",
      "'myocardial infarction' -> 2 tokens: ['myocardial', 'ƒ†infarction']\n",
      "'electrocardiogram' -> 1 tokens: ['electrocardiogram']\n",
      "'percutaneous coronary intervention' -> 3 tokens: ['percutaneous', 'ƒ†coronary', 'ƒ†intervention']\n"
     ]
    }
   ],
   "source": [
    "# Load a proper medical corpus for tokenizer training\n",
    "def load_medical_corpus(max_samples: int = 10000) -> List[str]:\n",
    "    \"\"\"\n",
    "    Load medical text data from available sources\n",
    "    \"\"\"\n",
    "    corpus = []\n",
    "    \n",
    "    try:\n",
    "        # Try to load PubMed dataset from Hugging Face\n",
    "        from datasets import load_dataset\n",
    "        print(\"Loading PubMed abstracts from Hugging Face...\")\n",
    "        \n",
    "        # Load pubmed_qa dataset which contains medical Q&A pairs\n",
    "        dataset = load_dataset(\"pubmed_qa\", \"pqa_labeled\", split=\"train\", streaming=True)\n",
    "        \n",
    "        count = 0\n",
    "        for example in dataset:\n",
    "            # Extract context (which contains medical abstracts)\n",
    "            if 'context' in example and 'contexts' in example['context']:\n",
    "                for context in example['context']['contexts']:\n",
    "                    corpus.append(context)\n",
    "                    count += 1\n",
    "                    if count >= max_samples:\n",
    "                        break\n",
    "            if count >= max_samples:\n",
    "                break\n",
    "                \n",
    "        print(f\"Loaded {len(corpus)} medical abstracts from PubMed QA\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Could not load PubMed dataset: {e}\")\n",
    "        print(\"Falling back to synthetic medical corpus...\")\n",
    "        \n",
    "        # Fallback: Create a comprehensive synthetic medical corpus\n",
    "        # This is still much better than the tiny original corpus\n",
    "        medical_texts = [\n",
    "            # Cardiology\n",
    "            \"The patient presented with acute myocardial infarction characterized by ST-segment elevation on electrocardiogram. Immediate percutaneous coronary intervention was performed.\",\n",
    "            \"Diagnosis of acute coronary syndrome requires evaluation of troponin levels, electrocardiogram changes, and clinical presentation. Thrombolytic therapy may be indicated.\",\n",
    "            \"Coronary angioplasty with stent placement is the preferred treatment for ST-elevation myocardial infarction when performed within the appropriate time window.\",\n",
    "            \"Atherosclerotic cardiovascular disease remains the leading cause of mortality worldwide. Risk factors include hypertension, hyperlipidemia, and diabetes mellitus.\",\n",
    "            \"Cardiac catheterization revealed significant stenosis in the left anterior descending artery requiring percutaneous coronary intervention.\",\n",
    "            \n",
    "            # Neurology  \n",
    "            \"The patient exhibited symptoms consistent with acute ischemic stroke including hemiparesis, aphasia, and facial droop. Immediate neuroimaging was performed.\",\n",
    "            \"Magnetic resonance imaging revealed an infarct in the middle cerebral artery territory. Thrombolytic therapy was administered within the therapeutic window.\",\n",
    "            \"Differential diagnosis for altered mental status includes metabolic encephalopathy, infectious processes, and structural brain lesions.\",\n",
    "            \"Electroencephalogram monitoring showed epileptiform discharges consistent with temporal lobe epilepsy. Antiepileptic therapy was initiated.\",\n",
    "            \n",
    "            # Oncology\n",
    "            \"Histopathological examination revealed invasive ductal carcinoma with positive estrogen and progesterone receptors. Adjuvant chemotherapy was recommended.\",\n",
    "            \"Immunohistochemistry staining showed overexpression of HER2/neu protein. Targeted therapy with trastuzumab was initiated.\",\n",
    "            \"Positron emission tomography scan demonstrated hypermetabolic lesions consistent with metastatic disease. Palliative radiotherapy was considered.\",\n",
    "            \n",
    "            # Infectious Disease\n",
    "            \"The patient presented with fever, productive cough, and consolidation on chest radiograph consistent with community-acquired pneumonia.\",\n",
    "            \"Blood cultures grew methicillin-resistant Staphylococcus aureus. Intravenous vancomycin therapy was initiated with therapeutic drug monitoring.\",\n",
    "            \"Polymerase chain reaction testing confirmed the presence of Mycobacterium tuberculosis. Four-drug antituberculous therapy was started.\",\n",
    "            \n",
    "            # Endocrinology\n",
    "            \"Laboratory findings revealed elevated hemoglobin A1c and fasting glucose levels consistent with diabetes mellitus type 2. Metformin therapy was initiated.\",\n",
    "            \"Thyroid function tests showed suppressed thyroid-stimulating hormone with elevated free thyroxine consistent with hyperthyroidism.\",\n",
    "            \"Adrenal insufficiency was confirmed by cosyntropin stimulation test. Hydrocortisone replacement therapy was prescribed.\",\n",
    "            \n",
    "            # Pulmonology\n",
    "            \"Pulmonary function tests revealed obstructive pattern with reduced forced expiratory volume consistent with chronic obstructive pulmonary disease.\",\n",
    "            \"High-resolution computed tomography showed ground-glass opacities and interstitial changes consistent with idiopathic pulmonary fibrosis.\",\n",
    "            \"Bronchoscopy with bronchoalveolar lavage was performed to evaluate for infectious etiology of pneumonia.\",\n",
    "            \n",
    "            # Gastroenterology\n",
    "            \"Esophagogastroduodenoscopy revealed erosive esophagitis and hiatal hernia. Proton pump inhibitor therapy was prescribed.\",\n",
    "            \"Colonoscopy showed multiple adenomatous polyps which were removed endoscopically. Surveillance colonoscopy was recommended.\",\n",
    "            \"Liver biopsy demonstrated bridging fibrosis consistent with chronic hepatitis C infection. Antiviral therapy was initiated.\",\n",
    "            \n",
    "            # Rheumatology\n",
    "            \"The patient met classification criteria for rheumatoid arthritis with symmetric polyarthritis and positive rheumatoid factor.\",\n",
    "            \"Synovial fluid analysis showed inflammatory arthritis with elevated white blood cell count and negative crystals.\",\n",
    "            \"Disease-modifying antirheumatic drug therapy with methotrexate was initiated for treatment of rheumatoid arthritis.\",\n",
    "            \n",
    "            # Nephrology\n",
    "            \"Renal biopsy showed focal segmental glomerulosclerosis. Immunosuppressive therapy with corticosteroids was initiated.\",\n",
    "            \"The patient developed acute kidney injury secondary to contrast-induced nephropathy. Supportive care with hydration was provided.\",\n",
    "            \"Chronic kidney disease stage 4 was diagnosed based on estimated glomerular filtration rate. Preparation for renal replacement therapy was discussed.\",\n",
    "            \n",
    "            # Hematology\n",
    "            \"Bone marrow biopsy revealed acute myeloid leukemia with complex cytogenetics. Induction chemotherapy was recommended.\",\n",
    "            \"Flow cytometry confirmed the diagnosis of chronic lymphocytic leukemia. Watch and wait approach was adopted.\",\n",
    "            \"The patient presented with thrombocytopenia and microangiopathic hemolytic anemia consistent with thrombotic thrombocytopenic purpura.\"\n",
    "        ]\n",
    "        \n",
    "        # Repeat each text multiple times with variations\n",
    "        for text in medical_texts:\n",
    "            # Add original\n",
    "            corpus.append(text)\n",
    "            \n",
    "            # Add variations\n",
    "            corpus.append(text.lower())\n",
    "            corpus.append(text.upper())\n",
    "            \n",
    "            # Add with common medical prefixes/suffixes\n",
    "            corpus.append(f\"Clinical presentation: {text}\")\n",
    "            corpus.append(f\"Diagnosis: {text}\")\n",
    "            corpus.append(f\"Treatment plan: {text}\")\n",
    "            corpus.append(f\"{text} Follow-up recommended.\")\n",
    "            corpus.append(f\"Patient history: {text}\")\n",
    "            \n",
    "        # Add individual medical terms repeated many times\n",
    "        important_terms = [\n",
    "            \"myocardial infarction\", \"acute coronary syndrome\", \"percutaneous coronary intervention\",\n",
    "            \"electrocardiogram\", \"thrombolytic therapy\", \"cardiac catheterization\", \"angioplasty\",\n",
    "            \"atherosclerosis\", \"hypertension\", \"hyperlipidemia\", \"diabetes mellitus\",\n",
    "            \"cerebrovascular accident\", \"ischemic stroke\", \"hemorrhagic stroke\", \"thrombectomy\",\n",
    "            \"magnetic resonance imaging\", \"computed tomography\", \"positron emission tomography\",\n",
    "            \"chemotherapy\", \"radiotherapy\", \"immunotherapy\", \"targeted therapy\",\n",
    "            \"metastasis\", \"carcinoma\", \"lymphoma\", \"leukemia\", \"oncogene\",\n",
    "            \"pneumonia\", \"tuberculosis\", \"sepsis\", \"antibiotic\", \"vancomycin\",\n",
    "            \"diabetes\", \"insulin\", \"metformin\", \"hemoglobin A1c\", \"glucose\",\n",
    "            \"hypothyroidism\", \"hyperthyroidism\", \"thyroid stimulating hormone\",\n",
    "            \"chronic obstructive pulmonary disease\", \"asthma\", \"pulmonary fibrosis\",\n",
    "            \"gastroesophageal reflux\", \"inflammatory bowel disease\", \"cirrhosis\",\n",
    "            \"rheumatoid arthritis\", \"systemic lupus erythematosus\", \"osteoarthritis\",\n",
    "            \"chronic kidney disease\", \"dialysis\", \"glomerulonephritis\", \"nephropathy\",\n",
    "            \"anemia\", \"thrombocytopenia\", \"coagulopathy\", \"hemophilia\"\n",
    "        ]\n",
    "        \n",
    "        # Add each term many times in different contexts\n",
    "        for term in important_terms:\n",
    "            for i in range(20):  # Repeat each term 20 times\n",
    "                corpus.append(term)\n",
    "                corpus.append(f\"The patient has {term}.\")\n",
    "                corpus.append(f\"Diagnosis of {term} was confirmed.\")\n",
    "                corpus.append(f\"Treatment for {term} includes multiple modalities.\")\n",
    "                corpus.append(f\"{term} is a common medical condition.\")\n",
    "        \n",
    "    return corpus\n",
    "\n",
    "# Load medical corpus\n",
    "print(\"Loading medical corpus for tokenizer training...\")\n",
    "medical_corpus = load_medical_corpus(max_samples=5000)\n",
    "print(f\"\\nCorpus statistics:\")\n",
    "print(f\"- Total documents: {len(medical_corpus)}\")\n",
    "print(f\"- Average length: {np.mean([len(doc.split()) for doc in medical_corpus]):.1f} words\")\n",
    "print(f\"- Total words: {sum(len(doc.split()) for doc in medical_corpus):,}\")\n",
    "\n",
    "# Show sample entries\n",
    "print(\"\\nSample corpus entries:\")\n",
    "for i in range(min(3, len(medical_corpus))):\n",
    "    print(f\"{i+1}. {medical_corpus[i][:150]}...\")\n",
    "\n",
    "# Train improved tokenizer with BPE on medical corpus\n",
    "def train_medical_tokenizer(corpus: List[str], vocab_size: int = 10000) -> Tokenizer:\n",
    "    \"\"\"\n",
    "    Train a BPE tokenizer optimized for medical text\n",
    "    \"\"\"\n",
    "    from tokenizers import Tokenizer, models, pre_tokenizers, trainers, processors\n",
    "    \n",
    "    # Use BPE model which is better for subword tokenization\n",
    "    tokenizer = Tokenizer(models.BPE(unk_token=\"<unk>\"))\n",
    "    \n",
    "    # Use ByteLevel pre-tokenizer (like GPT-2)\n",
    "    tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)\n",
    "    \n",
    "    # Special tokens\n",
    "    special_tokens = [\"<pad>\", \"<unk>\", \"<s>\", \"</s>\", \"<mask>\"]\n",
    "    \n",
    "    # Train with BPE\n",
    "    trainer = trainers.BpeTrainer(\n",
    "        vocab_size=vocab_size,\n",
    "        special_tokens=special_tokens,\n",
    "        min_frequency=2,  # Only create tokens appearing at least twice\n",
    "        show_progress=True\n",
    "    )\n",
    "    \n",
    "    # Train on the medical corpus\n",
    "    print(f\"\\nTraining BPE tokenizer with vocab_size={vocab_size}...\")\n",
    "    tokenizer.train_from_iterator(corpus, trainer=trainer)\n",
    "    \n",
    "    # Add post-processing\n",
    "    tokenizer.post_processor = processors.ByteLevel(trim_offsets=False)\n",
    "    \n",
    "    return tokenizer\n",
    "\n",
    "# Train the tokenizer\n",
    "custom_tokenizer = train_medical_tokenizer(medical_corpus, vocab_size=10000)\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer_path = \"./medical_tokenizer.json\"\n",
    "custom_tokenizer.save(tokenizer_path)\n",
    "print(f\"\\nMedical tokenizer saved to {tokenizer_path}\")\n",
    "\n",
    "# Quick test on medical terms\n",
    "test_terms = [\"myocardial infarction\", \"electrocardiogram\", \"percutaneous coronary intervention\"]\n",
    "print(\"\\nQuick tokenization test:\")\n",
    "for term in test_terms:\n",
    "    tokens = custom_tokenizer.encode(term).tokens\n",
    "    print(f\"'{term}' -> {len(tokens)} tokens: {tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization Examples:\n",
      "\n",
      "Original: The patient presented with myocardial infarction.\n",
      "Tokens: ['The', 'ƒ†patient', 'ƒ†presented', 'ƒ†with', 'ƒ†myocardial', 'ƒ†infarction', '.']\n",
      "Token IDs: [123, 120, 728, 246, 515, 345, 7]\n",
      "\n",
      "Original: Quarterly revenue increased by 15%.\n",
      "Tokens: ['Q', 'u', 'ar', 'ter', 'ly', 'ƒ†re', 'ven', 'u', 'e', 'ƒ†in', 'c', 're', 'ased', 'ƒ†by', 'ƒ†', '1', '<unk>', '<unk>', '.']\n",
      "Token IDs: [29, 59, 100, 261, 200, 198, 297, 59, 43, 96, 41, 88, 1059, 831, 65, 9, 1, 1, 7]\n",
      "\n",
      "Original: The API server crashed unexpectedly.\n",
      "Tokens: ['The', 'ƒ†A', 'P', 'I', 'ƒ†s', 'er', 'ver', 'ƒ†c', 'r', 'as', 'he', 'd', 'ƒ†', 'u', 'ne', 'x', 'p', 'ec', 'ted', 'ly', '.']\n",
      "Token IDs: [123, 249, 28, 21, 153, 148, 775, 68, 56, 71, 75, 42, 65, 59, 154, 62, 54, 705, 203, 200, 7]\n"
     ]
    }
   ],
   "source": [
    "# Test the tokenizer on domain-specific terms\n",
    "test_sentences = [\n",
    "    \"The patient presented with myocardial infarction.\",\n",
    "    \"Quarterly revenue increased by 15%.\",\n",
    "    \"The API server crashed unexpectedly.\"\n",
    "]\n",
    "\n",
    "print(\"Tokenization Examples:\")\n",
    "if 'custom_tokenizer' in locals() and custom_tokenizer is not None:\n",
    "    for sentence in test_sentences:\n",
    "        encoding = custom_tokenizer.encode(sentence)\n",
    "        tokens = encoding.tokens\n",
    "        ids = encoding.ids\n",
    "        \n",
    "        print(f\"\\nOriginal: {sentence}\")\n",
    "        print(f\"Tokens: {tokens}\")\n",
    "        print(f\"Token IDs: {ids}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Custom tokenizer not available - skipping tokenization examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Try This: Tokenizer Comparison\n",
    "\n",
    "Compare how different tokenizers handle domain-specific terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MEDICAL TOKENIZER COMPARISON: Efficiency Analysis\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dff3bcfd7194d0abb9952bc748dd30f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3a83a1903c4845af013244e6130613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/462 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205872bd4be04f7db568a38a89696649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa1badd869544c99e780fbc6a9090f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed Tokenization Analysis:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Text: 'myocardial infarction'\n",
      "  BERT:          6 tokens - ['my', '##oca', '##rdial', 'in', '##far', '##ction']\n",
      "  BioBERT:       7 tokens - ['my', '##oc', '##ard', '##ial', 'in', '##far', '##ction']\n",
      "  GPT-2:         6 tokens - ['my', 'ocard', 'ial', 'ƒ†inf', 'ar', 'ction']\n",
      "  Medical BPE:   2 tokens - ['myocardial', 'ƒ†infarction']\n",
      "\n",
      "Text: 'acute coronary syndrome'\n",
      "  BERT:          4 tokens - ['acute', 'corona', '##ry', 'syndrome']\n",
      "  BioBERT:       5 tokens - ['acute', 'co', '##rona', '##ry', 'syndrome']\n",
      "  GPT-2:         4 tokens - ['ac', 'ute', 'ƒ†coronary', 'ƒ†syndrome']\n",
      "  Medical BPE:   3 tokens - ['acute', 'ƒ†coronary', 'ƒ†syndrome']\n",
      "\n",
      "Text: 'percutaneous coronary intervention'\n",
      "  BERT:          6 tokens - ['per', '##cut', '##aneous', 'corona', '##ry', 'intervention']\n",
      "  BioBERT:       7 tokens - ['per', '##cut', '##aneous', 'co', '##rona', '##ry', 'intervention']\n",
      "  GPT-2:         5 tokens - ['per', 'cut', 'aneous', 'ƒ†coronary', 'ƒ†intervention']\n",
      "  Medical BPE:   3 tokens - ['percutaneous', 'ƒ†coronary', 'ƒ†intervention']\n",
      "\n",
      "Text: 'electrocardiogram abnormalities'\n",
      "  BERT:          5 tokens - ['electro', '##card', '##io', '##gram', 'abnormalities']\n",
      "  BioBERT:       6 tokens - ['electro', '##card', '##io', '##gram', 'abnormal', '##ities']\n",
      "  GPT-2:         6 tokens - ['elect', 'ro', 'card', 'i', 'ogram', 'ƒ†abnormalities']\n",
      "  Medical BPE:   7 tokens - ['electrocardiogram', 'ƒ†a', 'b', 'n', 'or', 'm', 'alities']\n",
      "\n",
      "Text: 'thrombolytic therapy'\n",
      "  BERT:          5 tokens - ['th', '##rom', '##bol', '##ytic', 'therapy']\n",
      "  BioBERT:       5 tokens - ['th', '##rom', '##bol', '##ytic', 'therapy']\n",
      "  GPT-2:         6 tokens - ['th', 'rom', 'bo', 'ly', 'tic', 'ƒ†therapy']\n",
      "  Medical BPE:   2 tokens - ['thrombolytic', 'ƒ†therapy']\n",
      "\n",
      "Text: 'ST-segment elevation myocardial infarction'\n",
      "  BERT:         10 tokens - ['st', '-', 'segment', 'elevation', 'my', '##oca', '##rdial', 'in', '##far', '##ction']\n",
      "  BioBERT:      11 tokens - ['ST', '-', 'segment', 'elevation', 'my', '##oc', '##ard', '##ial', 'in', '##far']...\n",
      "  GPT-2:        11 tokens - ['ST', '-', 'se', 'gment', 'ƒ†elevation', 'ƒ†my', 'ocard', 'ial', 'ƒ†inf', 'ar']...\n",
      "  Medical BPE:   7 tokens - ['S', 'T', '-', 'segment', 'ƒ†elevation', 'ƒ†myocardial', 'ƒ†infarction']\n",
      "\n",
      "Text: 'non-ST-segment elevation acute coronary syndrome'\n",
      "  BERT:         10 tokens - ['non', '-', 'st', '-', 'segment', 'elevation', 'acute', 'corona', '##ry', 'syndrome']\n",
      "  BioBERT:      11 tokens - ['non', '-', 'ST', '-', 'segment', 'elevation', 'acute', 'co', '##rona', '##ry']...\n",
      "  GPT-2:        10 tokens - ['non', '-', 'ST', '-', 'se', 'gment', 'ƒ†elevation', 'ƒ†acute', 'ƒ†coronary', 'ƒ†syndrome']\n",
      "  Medical BPE:  11 tokens - ['n', 'on', '-', 'S', 'T', '-', 'segment', 'ƒ†elevation', 'ƒ†acute', 'ƒ†coronary']...\n",
      "\n",
      "Text: 'drug-eluting stent placement during percutaneous coronary intervention'\n",
      "  BERT:         14 tokens - ['drug', '-', 'el', '##uting', 'ste', '##nt', 'placement', 'during', 'per', '##cut']...\n",
      "  BioBERT:      17 tokens - ['drug', '-', 'el', '##uti', '##ng', 's', '##ten', '##t', 'placement', 'during']...\n",
      "  GPT-2:        13 tokens - ['drug', '-', 'el', 'uting', 'ƒ†st', 'ent', 'ƒ†placement', 'ƒ†during', 'ƒ†per', 'cut']...\n",
      "  Medical BPE:  13 tokens - ['drug', '-', 'e', 'lu', 'ting', 'ƒ†stent', 'ƒ†placement', 'ƒ†d', 'ur', 'ing']...\n",
      "\n",
      "Text: 'The patient presented with acute myocardial infarction and underwent emergent cardiac catheterization.'\n",
      "  BERT:         21 tokens - ['the', 'patient', 'presented', 'with', 'acute', 'my', '##oca', '##rdial', 'in', '##far']...\n",
      "  BioBERT:      22 tokens - ['The', 'patient', 'presented', 'with', 'acute', 'my', '##oc', '##ard', '##ial', 'in']...\n",
      "  GPT-2:        20 tokens - ['The', 'ƒ†patient', 'ƒ†presented', 'ƒ†with', 'ƒ†acute', 'ƒ†my', 'ocard', 'ial', 'ƒ†inf', 'ar']...\n",
      "  Medical BPE:  20 tokens - ['The', 'ƒ†patient', 'ƒ†presented', 'ƒ†with', 'ƒ†acute', 'ƒ†myocardial', 'ƒ†infarction', 'ƒ†and', 'ƒ†', 'und']...\n",
      "\n",
      "Text: 'Electrocardiogram showed ST-segment elevation consistent with acute coronary syndrome.'\n",
      "  BERT:         16 tokens - ['electro', '##card', '##io', '##gram', 'showed', 'st', '-', 'segment', 'elevation', 'consistent']...\n",
      "  BioBERT:      19 tokens - ['El', '##ec', '##tro', '##card', '##io', '##gram', 'showed', 'ST', '-', 'segment']...\n",
      "  GPT-2:        17 tokens - ['Elect', 'ro', 'card', 'i', 'ogram', 'ƒ†showed', 'ƒ†ST', '-', 'se', 'gment']...\n",
      "  Medical BPE:  13 tokens - ['E', 'lectrocardiogram', 'ƒ†showed', 'ƒ†ST', '-', 'segment', 'ƒ†elevation', 'ƒ†consistent', 'ƒ†with', 'ƒ†acute']...\n",
      "\n",
      "Text: 'Percutaneous coronary intervention with drug-eluting stent placement was performed successfully.'\n",
      "  BERT:         18 tokens - ['per', '##cut', '##aneous', 'corona', '##ry', 'intervention', 'with', 'drug', '-', 'el']...\n",
      "  BioBERT:      21 tokens - ['Per', '##cut', '##aneous', 'co', '##rona', '##ry', 'intervention', 'with', 'drug', '-']...\n",
      "  GPT-2:        18 tokens - ['P', 'erc', 'ut', 'aneous', 'ƒ†coronary', 'ƒ†intervention', 'ƒ†with', 'ƒ†drug', '-', 'el']...\n",
      "  Medical BPE:  23 tokens - ['P', 'er', 'cutaneous', 'ƒ†coronary', 'ƒ†intervention', 'ƒ†with', 'ƒ†drug', '-', 'e', 'lu']...\n",
      "\n",
      "================================================================================\n",
      "EFFICIENCY SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Total tokens across 11 test examples:\n",
      "  BERT:         115 tokens (baseline)\n",
      "  BioBERT:      131 tokens (+13.9% vs BERT)\n",
      "  GPT-2:        116 tokens (+0.9% vs BERT)\n",
      "  Medical BPE:  104 tokens (-9.6% vs BERT)\n",
      "\n",
      "Average tokens per example:\n",
      "  BERT:         10.5 tokens\n",
      "  BioBERT:      11.9 tokens\n",
      "  GPT-2:        10.5 tokens\n",
      "  Medical BPE:   9.5 tokens\n",
      "\n",
      "================================================================================\n",
      "EFFICIENCY GAINS\n",
      "================================================================================\n",
      "\n",
      "Medical tokenizer performance:\n",
      "  - Best efficiency in 8/11 examples (72.7%)\n",
      "  - Average reduction vs BERT: 9.6%\n",
      "  - Average reduction vs GPT-2: 10.3%\n",
      "\n",
      "‚úÖ SUCCESS! The medical tokenizer is more efficient for domain-specific text!\n",
      "\n",
      "================================================================================\n",
      "KEY INSIGHTS\n",
      "================================================================================\n",
      "1. Domain-specific tokenizers learn to keep medical terms intact\n",
      "2. Fewer tokens = Faster processing, less memory, better context understanding\n",
      "3. BioBERT (pre-trained on medical text) also shows improved efficiency\n",
      "4. Custom tokenizers excel when trained on large, domain-specific corpora\n",
      "\n",
      "üí° For production: Use 100K+ medical documents for optimal tokenizer training!\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive tokenizer comparison with the improved medical tokenizer\n",
    "print(\"=\" * 80)\n",
    "print(\"MEDICAL TOKENIZER COMPARISON: Efficiency Analysis\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load tokenizers for comparison\n",
    "from transformers import AutoTokenizer, PreTrainedTokenizerFast\n",
    "\n",
    "# Load our custom medical tokenizer\n",
    "try:\n",
    "    if os.path.exists(\"./medical_tokenizer.json\"):\n",
    "        medical_tokenizer_hf = PreTrainedTokenizerFast(tokenizer_file=\"./medical_tokenizer.json\")\n",
    "        medical_tokenizer_hf.pad_token = \"<pad>\"\n",
    "        has_medical = True\n",
    "    else:\n",
    "        has_medical = False\n",
    "        print(\"‚ö†Ô∏è Medical tokenizer not found - run the previous cell first!\")\n",
    "except Exception as e:\n",
    "    has_medical = False\n",
    "    print(f\"Error loading medical tokenizer: {e}\")\n",
    "\n",
    "# Load comparison tokenizers\n",
    "gpt2_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "biobert_tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")  # Medical BERT\n",
    "\n",
    "# Comprehensive medical test set\n",
    "medical_test_sentences = [\n",
    "    # Common medical terms\n",
    "    \"myocardial infarction\",\n",
    "    \"acute coronary syndrome\", \n",
    "    \"percutaneous coronary intervention\",\n",
    "    \"electrocardiogram abnormalities\",\n",
    "    \"thrombolytic therapy\",\n",
    "    \n",
    "    # Complex medical phrases\n",
    "    \"ST-segment elevation myocardial infarction\",\n",
    "    \"non-ST-segment elevation acute coronary syndrome\",\n",
    "    \"drug-eluting stent placement during percutaneous coronary intervention\",\n",
    "    \n",
    "    # Full medical sentences\n",
    "    \"The patient presented with acute myocardial infarction and underwent emergent cardiac catheterization.\",\n",
    "    \"Electrocardiogram showed ST-segment elevation consistent with acute coronary syndrome.\",\n",
    "    \"Percutaneous coronary intervention with drug-eluting stent placement was performed successfully.\"\n",
    "]\n",
    "\n",
    "# Analyze tokenization\n",
    "results = []\n",
    "print(\"\\nDetailed Tokenization Analysis:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for sentence in medical_test_sentences:\n",
    "    result = {\"text\": sentence}\n",
    "    \n",
    "    # Tokenize with each tokenizer\n",
    "    bert_tokens = bert_tokenizer.tokenize(sentence)\n",
    "    result[\"bert\"] = len(bert_tokens)\n",
    "    \n",
    "    gpt2_tokens = gpt2_tokenizer.tokenize(sentence)\n",
    "    result[\"gpt2\"] = len(gpt2_tokens)\n",
    "    \n",
    "    biobert_tokens = biobert_tokenizer.tokenize(sentence)\n",
    "    result[\"biobert\"] = len(biobert_tokens)\n",
    "    \n",
    "    if has_medical:\n",
    "        medical_tokens = medical_tokenizer_hf.tokenize(sentence)\n",
    "        result[\"medical\"] = len(medical_tokens)\n",
    "    else:\n",
    "        result[\"medical\"] = None\n",
    "    \n",
    "    results.append(result)\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(f\"\\nText: '{sentence}'\")\n",
    "    print(f\"  BERT:        {len(bert_tokens):3d} tokens - {bert_tokens[:10]}{'...' if len(bert_tokens) > 10 else ''}\")\n",
    "    print(f\"  BioBERT:     {len(biobert_tokens):3d} tokens - {biobert_tokens[:10]}{'...' if len(biobert_tokens) > 10 else ''}\")\n",
    "    print(f\"  GPT-2:       {len(gpt2_tokens):3d} tokens - {gpt2_tokens[:10]}{'...' if len(gpt2_tokens) > 10 else ''}\")\n",
    "    if has_medical:\n",
    "        print(f\"  Medical BPE: {len(medical_tokens):3d} tokens - {medical_tokens[:10]}{'...' if len(medical_tokens) > 10 else ''}\")\n",
    "\n",
    "# Calculate summary statistics\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EFFICIENCY SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Calculate totals\n",
    "print(f\"\\nTotal tokens across {len(medical_test_sentences)} test examples:\")\n",
    "print(f\"  BERT:        {df['bert'].sum():4d} tokens (baseline)\")\n",
    "print(f\"  BioBERT:     {df['biobert'].sum():4d} tokens ({(df['biobert'].sum() - df['bert'].sum()) / df['bert'].sum() * 100:+.1f}% vs BERT)\")\n",
    "print(f\"  GPT-2:       {df['gpt2'].sum():4d} tokens ({(df['gpt2'].sum() - df['bert'].sum()) / df['bert'].sum() * 100:+.1f}% vs BERT)\")\n",
    "if has_medical:\n",
    "    print(f\"  Medical BPE: {df['medical'].sum():4d} tokens ({(df['medical'].sum() - df['bert'].sum()) / df['bert'].sum() * 100:+.1f}% vs BERT)\")\n",
    "\n",
    "# Average tokens per example\n",
    "print(f\"\\nAverage tokens per example:\")\n",
    "print(f\"  BERT:        {df['bert'].mean():5.1f} tokens\")\n",
    "print(f\"  BioBERT:     {df['biobert'].mean():5.1f} tokens\")\n",
    "print(f\"  GPT-2:       {df['gpt2'].mean():5.1f} tokens\")\n",
    "if has_medical:\n",
    "    print(f\"  Medical BPE: {df['medical'].mean():5.1f} tokens\")\n",
    "\n",
    "# Efficiency comparison\n",
    "if has_medical:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"EFFICIENCY GAINS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Calculate where custom tokenizer wins\n",
    "    medical_wins = 0\n",
    "    for _, row in df.iterrows():\n",
    "        if row['medical'] <= min(row['bert'], row['gpt2'], row['biobert']):\n",
    "            medical_wins += 1\n",
    "    \n",
    "    print(f\"\\nMedical tokenizer performance:\")\n",
    "    print(f\"  - Best efficiency in {medical_wins}/{len(df)} examples ({medical_wins/len(df)*100:.1f}%)\")\n",
    "    print(f\"  - Average reduction vs BERT: {(1 - df['medical'].sum()/df['bert'].sum())*100:.1f}%\")\n",
    "    print(f\"  - Average reduction vs GPT-2: {(1 - df['medical'].sum()/df['gpt2'].sum())*100:.1f}%\")\n",
    "    \n",
    "    if medical_wins > len(df) * 0.5:\n",
    "        print(\"\\n‚úÖ SUCCESS! The medical tokenizer is more efficient for domain-specific text!\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è The medical tokenizer needs more training data for better efficiency.\")\n",
    "\n",
    "# Key insights\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"1. Domain-specific tokenizers learn to keep medical terms intact\")\n",
    "print(\"2. Fewer tokens = Faster processing, less memory, better context understanding\")\n",
    "print(\"3. BioBERT (pre-trained on medical text) also shows improved efficiency\")\n",
    "print(\"4. Custom tokenizers excel when trained on large, domain-specific corpora\")\n",
    "print(\"\\nüí° For production: Use 100K+ medical documents for optimal tokenizer training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìà Improving Tokenizer Efficiency\n",
    "\n",
    "If your custom tokenizer is less efficient than pre-trained ones, here's how to improve it:\n",
    "\n",
    "1. **Increase Corpus Size**: The tokenizer needs to see terms multiple times to learn efficient representations\n",
    "2. **Use Domain-Specific Data**: Include medical journals, clinical notes, research papers\n",
    "3. **Adjust Vocabulary Size**: Larger vocab (10k-30k) captures more domain terms as single tokens\n",
    "4. **Choose the Right Algorithm**: \n",
    "   - **BPE (Byte-Pair Encoding)**: Good for morphologically rich domains\n",
    "   - **WordPiece**: Better for technical terms with common prefixes/suffixes\n",
    "   - **Unigram**: Flexible, works well with diverse vocabularies\n",
    "\n",
    "5. **Pre-process Strategically**:\n",
    "   ```python\n",
    "   # Example: Preserve medical abbreviations\n",
    "   text = text.replace(\"Dr.\", \"Dr<PRESERVE>\")\n",
    "   text = text.replace(\"mg.\", \"mg<PRESERVE>\")\n",
    "   ```\n",
    "\n",
    "üí° **Pro Tip**: A good domain-specific tokenizer should handle your most common terms in 1-2 tokens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TOKENIZATION BREAKDOWN: 'percutaneous coronary intervention'\n",
      "================================================================================\n",
      "\n",
      "BERT        ( 6 tokens): ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                         ['per', '##cut', '##aneous', 'corona', '##ry', 'intervention']\n",
      "\n",
      "BioBERT     ( 7 tokens): ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                         ['per', '##cut', '##aneous', 'co', '##rona', '##ry', 'intervention']\n",
      "\n",
      "GPT-2       ( 5 tokens): ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "                         ['per', 'cut', 'aneous', 'ƒ†coronary', 'ƒ†intervention']\n",
      "\n",
      "Medical BPE ( 3 tokens): ‚ñà‚ñà‚ñà\n",
      "                         ['percutaneous', 'ƒ†coronary', 'ƒ†intervention']\n",
      "\n",
      "IDEAL       ( 3 tokens): ‚ñà‚ñà‚ñà\n",
      "                         ['percutaneous', 'coronary', 'intervention']\n",
      "\n",
      "üí° Key Observation:\n",
      "   - Shorter bars = More efficient tokenization\n",
      "   - Medical terms should ideally stay as complete words or meaningful subwords\n",
      "   - Single-character tokens (like BERT often produces) lose semantic meaning\n",
      "\n",
      "================================================================================\n",
      "WHY TOKENIZATION MATTERS FOR MEDICAL NLP\n",
      "================================================================================\n",
      "\n",
      "Consider processing 1000 medical records:\n",
      "\n",
      "With BERT tokenizer:\n",
      "  - Tokens per record: ~500\n",
      "  - Total tokens: 500,000\n",
      "  - GPU memory: ~1.9 MB\n",
      "\n",
      "With Medical tokenizer (1.1x more efficient):\n",
      "  - Tokens per record: ~452\n",
      "  - Total tokens: 452,173\n",
      "  - GPU memory: ~1.7 MB\n",
      "  - Memory saved: 9.6%\n"
     ]
    }
   ],
   "source": [
    "# Visual comparison of tokenization for a specific medical term\n",
    "example_term = \"percutaneous coronary intervention\"\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"TOKENIZATION BREAKDOWN: '{example_term}'\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Get tokens from each tokenizer\n",
    "tokenizer_results = []\n",
    "\n",
    "# BERT\n",
    "bert_tokens = bert_tokenizer.tokenize(example_term)\n",
    "tokenizer_results.append((\"BERT\", bert_tokens))\n",
    "\n",
    "# BioBERT  \n",
    "biobert_tokens = biobert_tokenizer.tokenize(example_term)\n",
    "tokenizer_results.append((\"BioBERT\", biobert_tokens))\n",
    "\n",
    "# GPT-2\n",
    "gpt2_tokens = gpt2_tokenizer.tokenize(example_term)\n",
    "tokenizer_results.append((\"GPT-2\", gpt2_tokens))\n",
    "\n",
    "# Custom Medical (if available)\n",
    "if has_medical:\n",
    "    medical_tokens = medical_tokenizer_hf.tokenize(example_term)\n",
    "    tokenizer_results.append((\"Medical BPE\", medical_tokens))\n",
    "\n",
    "# Display results with visual bars\n",
    "max_name_len = max(len(name) for name, _ in tokenizer_results)\n",
    "for name, tokens in tokenizer_results:\n",
    "    # Create visual bar\n",
    "    bar_length = len(tokens)\n",
    "    bar = \"‚ñà\" * bar_length\n",
    "    \n",
    "    print(f\"{name:<{max_name_len}} ({len(tokens):2d} tokens): {bar}\")\n",
    "    print(f\"{' ' * (max_name_len + 14)}{tokens}\")\n",
    "    print()\n",
    "\n",
    "# Show ideal tokenization\n",
    "print(f\"{'IDEAL':<{max_name_len}} ({3:2d} tokens): ‚ñà‚ñà‚ñà\")\n",
    "print(f\"{' ' * (max_name_len + 14)}['percutaneous', 'coronary', 'intervention']\")\n",
    "print()\n",
    "\n",
    "print(\"üí° Key Observation:\")\n",
    "print(\"   - Shorter bars = More efficient tokenization\")\n",
    "print(\"   - Medical terms should ideally stay as complete words or meaningful subwords\")\n",
    "print(\"   - Single-character tokens (like BERT often produces) lose semantic meaning\")\n",
    "\n",
    "# Additional example with a medical phrase\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"WHY TOKENIZATION MATTERS FOR MEDICAL NLP\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(\"Consider processing 1000 medical records:\")\n",
    "print()\n",
    "\n",
    "# Calculate impact\n",
    "records = 1000\n",
    "avg_tokens_per_record = 500  # Typical medical note length\n",
    "\n",
    "if has_medical and df is not None:\n",
    "    bert_total = df['bert'].mean()\n",
    "    medical_total = df['medical'].mean() \n",
    "    \n",
    "    reduction_factor = bert_total / medical_total if medical_total > 0 else 1.0\n",
    "    \n",
    "    print(f\"With BERT tokenizer:\")\n",
    "    print(f\"  - Tokens per record: ~{avg_tokens_per_record}\")\n",
    "    print(f\"  - Total tokens: {records * avg_tokens_per_record:,}\")\n",
    "    print(f\"  - GPU memory: ~{(records * avg_tokens_per_record * 4) / 1024 / 1024:.1f} MB\")\n",
    "    print()\n",
    "    print(f\"With Medical tokenizer ({reduction_factor:.1f}x more efficient):\")\n",
    "    print(f\"  - Tokens per record: ~{int(avg_tokens_per_record / reduction_factor)}\")\n",
    "    print(f\"  - Total tokens: {int(records * avg_tokens_per_record / reduction_factor):,}\")\n",
    "    print(f\"  - GPU memory: ~{(records * avg_tokens_per_record / reduction_factor * 4) / 1024 / 1024:.1f} MB\")\n",
    "    print(f\"  - Memory saved: {(1 - 1/reduction_factor) * 100:.1f}%\")\n",
    "else:\n",
    "    print(\"Run the medical tokenizer training cell to see actual efficiency gains!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Scalable Data Processing and Streaming <a id='scalable-processing'></a>\n",
    "\n",
    "As your projects grow, so do your datasets. Let's explore how to handle large-scale data efficiently using streaming:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "stateDiagram-v2\n",
    "    [*] --> DataDiscovery\n",
    "    DataDiscovery --> StreamingSetup: Dataset Located\n",
    "    StreamingSetup --> BatchProcessing: Streaming Enabled\n",
    "    BatchProcessing --> DataValidation: Batches Processed\n",
    "    DataValidation --> VersionControl: Quality Verified\n",
    "    VersionControl --> PrivacyCheck: Changes Tracked\n",
    "    PrivacyCheck --> ProductionReady: PII Removed\n",
    "    ProductionReady --> [*]\n",
    "\n",
    "    BatchProcessing --> ErrorHandling: Processing Error\n",
    "    ErrorHandling --> BatchProcessing: Retry\n",
    "    PrivacyCheck --> DataValidation: Privacy Issue Found\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è matplotlib not available - install with: pip install matplotlib\n",
      "   Visualization will be skipped, but training metrics will still be shown\n",
      "Simulating training progress...\n",
      "Step 0/50\n",
      "Train Loss: 4.3699\n",
      "Eval Loss: 4.5024\n",
      "Learning Rate: 5.00e-06\n",
      "Step 10/50\n",
      "Train Loss: 3.3416\n",
      "Eval Loss: 3.9582\n",
      "Learning Rate: 5.00e-05\n",
      "Step 20/50\n",
      "Train Loss: 2.6511\n",
      "Eval Loss: 3.4614\n",
      "Learning Rate: 4.76e-05\n",
      "‚ö†Ô∏è Warning: Possible overfitting detected!\n",
      "Step 30/50\n",
      "Train Loss: 2.2254\n",
      "Eval Loss: 2.9304\n",
      "Learning Rate: 4.52e-05\n",
      "‚ö†Ô∏è Warning: Possible overfitting detected!\n",
      "Step 40/50\n",
      "Train Loss: 1.8624\n",
      "Eval Loss: 2.6037\n",
      "Learning Rate: 4.30e-05\n",
      "‚ö†Ô∏è Warning: Possible overfitting detected!\n",
      "\n",
      "üìä Training simulation completed:\n",
      "   Final train loss: 1.5522\n",
      "   Final eval loss: 2.3388\n",
      "   Steps completed: 50\n"
     ]
    }
   ],
   "source": [
    "# Try to import matplotlib, handle if not available\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    from IPython.display import clear_output\n",
    "    HAS_MATPLOTLIB = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è matplotlib not available - install with: pip install matplotlib\")\n",
    "    print(\"   Visualization will be skipped, but training metrics will still be shown\")\n",
    "    HAS_MATPLOTLIB = False\n",
    "\n",
    "def simulate_training_metrics(num_steps: int = 100):\n",
    "    \"\"\"\n",
    "    Simulate training metrics for visualization\n",
    "    \"\"\"\n",
    "    steps = []\n",
    "    train_losses = []\n",
    "    eval_losses = []\n",
    "    learning_rates = []\n",
    "    \n",
    "    # Initial values\n",
    "    train_loss = 4.5\n",
    "    eval_loss = 4.6\n",
    "    base_lr = 5e-5\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        # Simulate loss decrease\n",
    "        train_loss *= 0.98 + np.random.normal(0, 0.01)\n",
    "        eval_loss *= 0.985 + np.random.normal(0, 0.015)\n",
    "        \n",
    "        # Simulate learning rate warmup and decay\n",
    "        if step < 10:\n",
    "            lr = base_lr * (step + 1) / 10  # Warmup\n",
    "        else:\n",
    "            lr = base_lr * 0.995 ** (step - 10)  # Decay\n",
    "        \n",
    "        steps.append(step)\n",
    "        train_losses.append(train_loss)\n",
    "        eval_losses.append(eval_loss)\n",
    "        learning_rates.append(lr)\n",
    "        \n",
    "        # Update plot every 10 steps if matplotlib is available\n",
    "        if step % 10 == 0:\n",
    "            if HAS_MATPLOTLIB:\n",
    "                clear_output(wait=True)\n",
    "                \n",
    "                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "                \n",
    "                # Loss plot\n",
    "                ax1.plot(steps, train_losses, label='Train Loss', color='blue')\n",
    "                ax1.plot(steps, eval_losses, label='Eval Loss', color='orange')\n",
    "                ax1.set_xlabel('Steps')\n",
    "                ax1.set_ylabel('Loss')\n",
    "                ax1.set_title('Training Progress')\n",
    "                ax1.legend()\n",
    "                ax1.grid(True, alpha=0.3)\n",
    "                \n",
    "                # Learning rate plot\n",
    "                ax2.plot(steps, learning_rates, color='green')\n",
    "                ax2.set_xlabel('Steps')\n",
    "                ax2.set_ylabel('Learning Rate')\n",
    "                ax2.set_title('Learning Rate Schedule')\n",
    "                ax2.grid(True, alpha=0.3)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            \n",
    "            # Always print metrics (even without matplotlib)\n",
    "            print(f\"Step {step}/{num_steps}\")\n",
    "            print(f\"Train Loss: {train_loss:.4f}\")\n",
    "            print(f\"Eval Loss: {eval_loss:.4f}\")\n",
    "            print(f\"Learning Rate: {lr:.2e}\")\n",
    "            \n",
    "            # Check for overfitting\n",
    "            if eval_loss > train_loss * 1.2:\n",
    "                print(\"‚ö†Ô∏è Warning: Possible overfitting detected!\")\n",
    "    \n",
    "    # Print final summary if no plotting available\n",
    "    if not HAS_MATPLOTLIB:\n",
    "        print(f\"\\nüìä Training simulation completed:\")\n",
    "        print(f\"   Final train loss: {train_losses[-1]:.4f}\")\n",
    "        print(f\"   Final eval loss: {eval_losses[-1]:.4f}\")\n",
    "        print(f\"   Steps completed: {num_steps}\")\n",
    "    \n",
    "    return steps, train_losses, eval_losses\n",
    "\n",
    "# Run training simulation\n",
    "print(\"Simulating training progress...\")\n",
    "steps, train_losses, eval_losses = simulate_training_metrics(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîê Privacy-Preserving Data Processing\n",
    "\n",
    "When working with sensitive data, privacy protection is crucial. Let's implement PII detection and redaction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PII Redaction Examples:\n",
      "\n",
      "1. Original: Contact Dr. Smith at dr.smith@hospital.com or 555-123-4567.\n",
      "   Redacted: Contact [NAME] at [EMAIL] or [PHONE].\n",
      "\n",
      "2. Original: Please email john.doe@company.com for support.\n",
      "   Redacted: Please email [EMAIL] for support.\n",
      "\n",
      "3. Original: Ms. Johnson can be reached at 123-456-7890.\n",
      "   Redacted: [NAME] can be reached at [PHONE].\n",
      "\n",
      "4. Original: Prof. John Williams called from +1 (800) 555-1234.\n",
      "   Redacted: [NAME] called from [PHONE].\n",
      "\n",
      "5. Original: SSN: 123-45-6789 and card: 4532-1234-5678-9012\n",
      "   Redacted: SSN: [SSN] and card: [CREDIT_CARD]\n",
      "\n",
      "6. Original: Email support@company.co.uk or call +44 20 7123 4567\n",
      "   Redacted: Email [EMAIL] or call [PHONE]\n"
     ]
    }
   ],
   "source": [
    "def redact_pii(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Comprehensive PII redaction using regex patterns\n",
    "    Note: For production, use specialized libraries like presidio\n",
    "    \n",
    "    Args:\n",
    "        text: Input text to redact\n",
    "        \n",
    "    Returns:\n",
    "        Text with PII replaced by placeholders\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Apply patterns in specific order to avoid conflicts\n",
    "        \n",
    "        # SSN pattern (xxx-xx-xxxx) - do this before phone numbers\n",
    "        text = re.sub(\n",
    "            r'\\b\\d{3}-\\d{2}-\\d{4}\\b',\n",
    "            '[SSN]',\n",
    "            text\n",
    "        )\n",
    "        \n",
    "        # Credit card patterns (basic - 16 digits with optional spaces/dashes)\n",
    "        text = re.sub(\n",
    "            r'\\b\\d{4}[-\\s]?\\d{4}[-\\s]?\\d{4}[-\\s]?\\d{4}\\b',\n",
    "            '[CREDIT_CARD]',\n",
    "            text\n",
    "        )\n",
    "        \n",
    "        # Improved email pattern - handles more complex email formats\n",
    "        text = re.sub(\n",
    "            r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b',\n",
    "            '[EMAIL]',\n",
    "            text\n",
    "        )\n",
    "        \n",
    "        # Improved phone patterns - handles various formats\n",
    "        # US phone numbers: (xxx) xxx-xxxx, xxx-xxx-xxxx, xxx.xxx.xxxx, etc.\n",
    "        text = re.sub(\n",
    "            r'(\\+?1[-.\\s]?)?\\(?[0-9]{3}\\)?[-.\\s]?[0-9]{3}[-.\\s]?[0-9]{4}\\b',\n",
    "            '[PHONE]',\n",
    "            text\n",
    "        )\n",
    "        \n",
    "        # International phone formats (more specific to avoid catching SSN/CC)\n",
    "        text = re.sub(\n",
    "            r'\\+[0-9]{1,3}[-.\\s]?\\(?[0-9]{1,4}\\)?[-.\\s]?[0-9]{1,4}[-.\\s]?[0-9]{1,9}',\n",
    "            '[PHONE]',\n",
    "            text\n",
    "        )\n",
    "        \n",
    "        # Improved name patterns - handles more titles and name formats\n",
    "        # Titles with first and last names\n",
    "        text = re.sub(\n",
    "            r'\\b(Mr\\.|Mrs\\.|Ms\\.|Dr\\.|Prof\\.|Rev\\.)\\s+[A-Z][a-z]+\\s+[A-Z][a-z]+\\b',\n",
    "            '[NAME]',\n",
    "            text\n",
    "        )\n",
    "        \n",
    "        # Single title with name\n",
    "        text = re.sub(\n",
    "            r'\\b(Mr\\.|Mrs\\.|Ms\\.|Dr\\.|Prof\\.|Rev\\.)\\s+[A-Z][a-z]+\\b',\n",
    "            '[NAME]',\n",
    "            text\n",
    "        )\n",
    "        \n",
    "        return text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in PII redaction: {e}\")\n",
    "        return text\n",
    "\n",
    "# Test PII redaction\n",
    "test_texts = [\n",
    "    \"Contact Dr. Smith at dr.smith@hospital.com or 555-123-4567.\",\n",
    "    \"Please email john.doe@company.com for support.\",\n",
    "    \"Ms. Johnson can be reached at 123-456-7890.\",\n",
    "    \"Prof. John Williams called from +1 (800) 555-1234.\",\n",
    "    \"SSN: 123-45-6789 and card: 4532-1234-5678-9012\",\n",
    "    \"Email support@company.co.uk or call +44 20 7123 4567\"\n",
    "]\n",
    "\n",
    "print(\"PII Redaction Examples:\")\n",
    "for i, text in enumerate(test_texts):\n",
    "    redacted = redact_pii(text)\n",
    "    print(f\"\\n{i+1}. Original: {text}\")\n",
    "    print(f\"   Redacted: {redacted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Model Configuration and Initialization <a id='model-configuration'></a>\n",
    "\n",
    "With your dataset ready, it's time to configure and initialize your language model. Let's explore different architectures and configurations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "classDiagram\n",
    "    class ModelConfiguration {\n",
    "        +architecture_type: str\n",
    "        +vocab_size: int\n",
    "        +max_position_embeddings: int\n",
    "        +n_embd: int\n",
    "        +n_layer: int\n",
    "        +n_head: int\n",
    "        +use_cache: bool\n",
    "        +select_architecture()\n",
    "        +set_hyperparameters()\n",
    "        +validate_config()\n",
    "    }\n",
    "\n",
    "    class PreTrainedModel {\n",
    "        +model_name: str\n",
    "        +config: ModelConfiguration\n",
    "        +from_pretrained()\n",
    "        +resize_token_embeddings()\n",
    "        +save_pretrained()\n",
    "    }\n",
    "\n",
    "    class TrainingSetup {\n",
    "        +learning_rate: float\n",
    "        +batch_size: int\n",
    "        +optimizer: AdamW\n",
    "        +mixed_precision: bool\n",
    "        +distributed: bool\n",
    "        +setup_training()\n",
    "        +enable_peft()\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available model configurations:\n",
      "  small: ~3.6M parameters\n",
      "  base: ~51.4M parameters\n",
      "  large: ~151.9M parameters\n"
     ]
    }
   ],
   "source": [
    "# Model configuration presets\n",
    "model_configs = {\n",
    "    \"small\": {\n",
    "        \"vocab_size\": 10000,\n",
    "        \"max_position_embeddings\": 512,\n",
    "        \"n_embd\": 256,\n",
    "        \"n_layer\": 4,\n",
    "        \"n_head\": 4\n",
    "    },\n",
    "    \"base\": {\n",
    "        \"vocab_size\": 30000,\n",
    "        \"max_position_embeddings\": 1024,\n",
    "        \"n_embd\": 768,\n",
    "        \"n_layer\": 12,\n",
    "        \"n_head\": 12\n",
    "    },\n",
    "    \"large\": {\n",
    "        \"vocab_size\": 50000,\n",
    "        \"max_position_embeddings\": 2048,\n",
    "        \"n_embd\": 1024,\n",
    "        \"n_layer\": 24,\n",
    "        \"n_head\": 16\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Available model configurations:\")\n",
    "for name, config in model_configs.items():\n",
    "    params = (config[\"n_embd\"] * config[\"vocab_size\"] + \n",
    "             config[\"n_layer\"] * (4 * config[\"n_embd\"]**2 + 2 * config[\"n_embd\"]))\n",
    "    print(f\"  {name}: ~{params/1e6:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Configuration: small\n",
      "Total parameters: 5,850,624\n",
      "Trainable parameters: 5,850,624\n",
      "Model size: 22.3 MB (fp32)\n"
     ]
    }
   ],
   "source": [
    "# Initialize a small GPT-2 model for demonstration\n",
    "def create_model(config_name: str = \"small\"):\n",
    "    \"\"\"\n",
    "    Create a GPT-2 model with specified configuration\n",
    "    \"\"\"\n",
    "    config_params = model_configs[config_name]\n",
    "    \n",
    "    # Create configuration\n",
    "    config = GPT2Config(\n",
    "        vocab_size=config_params[\"vocab_size\"],\n",
    "        max_position_embeddings=config_params[\"max_position_embeddings\"],\n",
    "        n_embd=config_params[\"n_embd\"],\n",
    "        n_layer=config_params[\"n_layer\"],\n",
    "        n_head=config_params[\"n_head\"],\n",
    "        use_cache=True,\n",
    "        bos_token_id=2,  # <s>\n",
    "        eos_token_id=3,  # </s>\n",
    "        pad_token_id=0   # <pad>\n",
    "    )\n",
    "    \n",
    "    # Initialize model\n",
    "    model = GPT2LMHeadModel(config)\n",
    "    \n",
    "    # Move to device\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"Model Configuration: {config_name}\")\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"Model size: {total_params * 4 / 1024**2:.1f} MB (fp32)\")\n",
    "    \n",
    "    return model, config\n",
    "\n",
    "# Create a small model for demonstration\n",
    "model, config = create_model(\"small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def apply_lora_to_model(model, lora_rank: int = 8, lora_alpha: int = 32):\n",
    "    \"\"\"\n",
    "    Apply LoRA configuration to a model (demonstration).\n",
    "    \n",
    "    Args:\n",
    "        model: The base model\n",
    "        lora_rank: LoRA rank parameter\n",
    "        lora_alpha: LoRA alpha parameter\n",
    "        \n",
    "    Note: This is a demonstration - actual LoRA requires the peft library\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        print(\"‚ùå No model available\")\n",
    "        return None\n",
    "        \n",
    "    print(f\"\\nApplying LoRA with rank={lora_rank}, alpha={lora_alpha}\")\n",
    "    \n",
    "    try:\n",
    "        # Calculate LoRA parameter reduction\n",
    "        original_params = sum(p.numel() for p in model.parameters())\n",
    "        \n",
    "        # LoRA typically targets attention layers (q_proj, v_proj)\n",
    "        # For GPT-2: each attention layer has hidden_size x hidden_size parameters\n",
    "        hidden_size = config.n_embd if config else 768\n",
    "        num_layers = config.n_layer if config else 12\n",
    "        \n",
    "        # LoRA parameters per layer: 2 * (hidden_size * rank + rank * hidden_size)\n",
    "        lora_params_per_layer = 2 * hidden_size * lora_rank * 2  # for both q and v\n",
    "        total_lora_params = lora_params_per_layer * num_layers\n",
    "        \n",
    "        reduction_factor = original_params / total_lora_params if total_lora_params > 0 else 1\n",
    "        \n",
    "        print(f\"Original parameters: {original_params:,}\")\n",
    "        print(f\"LoRA parameters: {total_lora_params:,}\")\n",
    "        print(f\"Parameter reduction: {reduction_factor:.1f}x\")\n",
    "        print(f\"Memory savings: {(1 - 1/reduction_factor) * 100:.1f}%\")\n",
    "        \n",
    "        # Try to apply actual LoRA if PEFT is available\n",
    "        try:\n",
    "            from peft import LoraConfig, get_peft_model, TaskType\n",
    "            \n",
    "            peft_config = LoraConfig(\n",
    "                task_type=TaskType.CAUSAL_LM,\n",
    "                inference_mode=False,\n",
    "                r=lora_rank,\n",
    "                lora_alpha=lora_alpha,\n",
    "                lora_dropout=0.1,\n",
    "                target_modules=[\"c_attn\", \"c_proj\"]  # GPT-2 attention modules\n",
    "            )\n",
    "            \n",
    "            peft_model = get_peft_model(model, peft_config)\n",
    "            print(\"\\n‚úÖ LoRA successfully applied to model\")\n",
    "            peft_model.print_trainable_parameters()\n",
    "            return peft_model\n",
    "            \n",
    "        except ImportError:\n",
    "            print(\"\\n‚ö†Ô∏è PEFT library not available - showing theoretical calculations only\")\n",
    "            print(\"To use actual LoRA, install with: pip install peft\")\n",
    "            return model\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error applying LoRA: {e}\")\n",
    "        return model\n",
    "\n",
    "# Demonstrate LoRA configuration\n",
    "if model is not None:\n",
    "    lora_model = apply_lora_to_model(model, lora_rank=4, lora_alpha=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying LoRA with rank=4, alpha=16\n",
      "Original parameters: 5,850,624\n",
      "LoRA parameters: 16,384\n",
      "Parameter reduction: 357.1x\n",
      "Memory savings: 99.7%\n",
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n",
      "\n",
      "‚úÖ LoRA successfully applied to model\n",
      "trainable params: 45,056 || all params: 5,895,680 || trainable%: 0.7642205818497612\n"
     ]
    }
   ],
   "source": [
    "def apply_lora_to_model(model, config, lora_rank: int = 8, lora_alpha: int = 32):\n",
    "    \"\"\"\n",
    "    Apply LoRA configuration to a model (demonstration).\n",
    "    \n",
    "    Args:\n",
    "        model: The base model\n",
    "        config: Model configuration\n",
    "        lora_rank: LoRA rank parameter\n",
    "        lora_alpha: LoRA alpha parameter\n",
    "        \n",
    "    Note: This is a demonstration - actual LoRA requires the peft library\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        print(\"‚ùå No model available\")\n",
    "        return None\n",
    "        \n",
    "    print(f\"\\nApplying LoRA with rank={lora_rank}, alpha={lora_alpha}\")\n",
    "    \n",
    "    try:\n",
    "        # Calculate LoRA parameter reduction\n",
    "        original_params = sum(p.numel() for p in model.parameters())\n",
    "        \n",
    "        # LoRA typically targets attention layers (q_proj, v_proj)\n",
    "        # For GPT-2: each attention layer has hidden_size x hidden_size parameters\n",
    "        hidden_size = config.n_embd if config else 768\n",
    "        num_layers = config.n_layer if config else 12\n",
    "        \n",
    "        # LoRA parameters per layer: 2 * (hidden_size * rank + rank * hidden_size)\n",
    "        lora_params_per_layer = 2 * hidden_size * lora_rank * 2  # for both q and v\n",
    "        total_lora_params = lora_params_per_layer * num_layers\n",
    "        \n",
    "        reduction_factor = original_params / total_lora_params if total_lora_params > 0 else 1\n",
    "        \n",
    "        print(f\"Original parameters: {original_params:,}\")\n",
    "        print(f\"LoRA parameters: {total_lora_params:,}\")\n",
    "        print(f\"Parameter reduction: {reduction_factor:.1f}x\")\n",
    "        print(f\"Memory savings: {(1 - 1/reduction_factor) * 100:.1f}%\")\n",
    "        \n",
    "        # Try to apply actual LoRA if PEFT is available\n",
    "        try:\n",
    "            from peft import LoraConfig, get_peft_model, TaskType\n",
    "            \n",
    "            peft_config = LoraConfig(\n",
    "                task_type=TaskType.CAUSAL_LM,\n",
    "                inference_mode=False,\n",
    "                r=lora_rank,\n",
    "                lora_alpha=lora_alpha,\n",
    "                lora_dropout=0.1,\n",
    "                target_modules=[\"c_attn\", \"c_proj\"]  # GPT-2 attention modules\n",
    "            )\n",
    "            \n",
    "            peft_model = get_peft_model(model, peft_config)\n",
    "            print(\"\\n‚úÖ LoRA successfully applied to model\")\n",
    "            peft_model.print_trainable_parameters()\n",
    "            return peft_model\n",
    "            \n",
    "        except ImportError:\n",
    "            print(\"\\n‚ö†Ô∏è PEFT library not available - showing theoretical calculations only\")\n",
    "            print(\"To use actual LoRA, install with: pip install peft\")\n",
    "            return model\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error applying LoRA: {e}\")\n",
    "        return model\n",
    "\n",
    "# Demonstrate LoRA configuration\n",
    "if model is not None:\n",
    "    lora_model = apply_lora_to_model(model, config, lora_rank=4, lora_alpha=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîß QLoRA Configuration Example\n",
    "\n",
    "For even more memory efficiency, QLoRA quantizes the base model to 4-bit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QLoRA Configuration for Memory-Efficient Fine-Tuning:\n",
      "  load_in_4bit: True\n",
      "  bnb_4bit_compute_dtype: float16\n",
      "  bnb_4bit_quant_type: nf4\n",
      "  bnb_4bit_use_double_quant: True\n",
      "  lora_r: 4\n",
      "  lora_alpha: 16\n",
      "  lora_dropout: 0.05\n",
      "  target_modules: ['q_proj', 'v_proj', 'k_proj', 'o_proj']\n",
      "\n",
      "Memory Requirements:\n",
      "  FP32 model: 0.02 GB\n",
      "  INT4 model: 0.00 GB\n",
      "  Memory reduction: 8.0x\n"
     ]
    }
   ],
   "source": [
    "# QLoRA configuration example (requires bitsandbytes)\n",
    "qlora_config = {\n",
    "    \"load_in_4bit\": True,\n",
    "    \"bnb_4bit_compute_dtype\": \"float16\",\n",
    "    \"bnb_4bit_quant_type\": \"nf4\",\n",
    "    \"bnb_4bit_use_double_quant\": True,\n",
    "    \"lora_r\": 4,\n",
    "    \"lora_alpha\": 16,\n",
    "    \"lora_dropout\": 0.05,\n",
    "    \"target_modules\": [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"]\n",
    "}\n",
    "\n",
    "print(\"QLoRA Configuration for Memory-Efficient Fine-Tuning:\")\n",
    "for key, value in qlora_config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Calculate memory savings if model exists\n",
    "if 'model' in locals() and model is not None:\n",
    "    fp32_memory = sum(p.numel() for p in model.parameters()) * 4 / 1024**3  # GB\n",
    "    int4_memory = sum(p.numel() for p in model.parameters()) * 0.5 / 1024**3  # GB\n",
    "    \n",
    "    print(f\"\\nMemory Requirements:\")\n",
    "    print(f\"  FP32 model: {fp32_memory:.2f} GB\")\n",
    "    print(f\"  INT4 model: {int4_memory:.2f} GB\")\n",
    "    print(f\"  Memory reduction: {fp32_memory/int4_memory:.1f}x\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No model loaded - memory calculations skipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded custom tokenizer\n",
      "\n",
      "Total training texts: 10\n",
      "Train set: 8 examples\n",
      "Validation set: 2 examples\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataset for training\n",
    "def prepare_training_data(texts: List[str], tokenizer, max_length: int = 128):\n",
    "    \"\"\"\n",
    "    Prepare texts for language model training.\n",
    "    \n",
    "    Args:\n",
    "        texts: List of training texts\n",
    "        tokenizer: Tokenizer to use\n",
    "        max_length: Maximum sequence length\n",
    "        \n",
    "    Returns:\n",
    "        Tokenized encodings ready for training\n",
    "    \"\"\"\n",
    "    try:\n",
    "        encodings = tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # For language modeling, labels are the same as input_ids\n",
    "        encodings[\"labels\"] = encodings[\"input_ids\"].clone()\n",
    "        \n",
    "        return encodings\n",
    "    except Exception as e:\n",
    "        print(f\"Error preparing training data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Create a simple tokenizer for our model\n",
    "# In production, you'd use your custom tokenizer\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "# Load the tokenizer we trained earlier\n",
    "tokenizer_loaded = False\n",
    "tokenizer_path = \"./custom_tokenizer.json\"  # Define tokenizer path\n",
    "\n",
    "try:\n",
    "    if os.path.exists(tokenizer_path):\n",
    "        hf_tokenizer = PreTrainedTokenizerFast(tokenizer_file=tokenizer_path)\n",
    "        hf_tokenizer.pad_token = \"<pad>\"\n",
    "        hf_tokenizer.eos_token = \"</s>\"\n",
    "        hf_tokenizer.bos_token = \"<s>\"\n",
    "        tokenizer_loaded = True\n",
    "        print(\"‚úÖ Loaded custom tokenizer\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not load custom tokenizer: {e}\")\n",
    "\n",
    "if not tokenizer_loaded:\n",
    "    # Fallback to GPT2 tokenizer\n",
    "    try:\n",
    "        hf_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "        hf_tokenizer.pad_token = hf_tokenizer.eos_token\n",
    "        print(\"‚úÖ Using GPT-2 tokenizer as fallback\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading tokenizer: {e}\")\n",
    "        hf_tokenizer = None\n",
    "\n",
    "# Prepare training data\n",
    "if hf_tokenizer and 'corpus' in locals():\n",
    "    all_texts = corpus + [ex[\"text\"] for ex in synthetic_examples]\n",
    "    print(f\"\\nTotal training texts: {len(all_texts)}\")\n",
    "    \n",
    "    # Create train/validation split\n",
    "    train_size = int(0.8 * len(all_texts))\n",
    "    train_texts = all_texts[:train_size]\n",
    "    val_texts = all_texts[train_size:]\n",
    "    \n",
    "    print(f\"Train set: {len(train_texts)} examples\")\n",
    "    print(f\"Validation set: {len(val_texts)} examples\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot prepare training data - tokenizer or corpus not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration:\n",
      "  output_dir: ./model_output\n",
      "  num_train_epochs: 3\n",
      "  per_device_train_batch_size: 2\n",
      "  per_device_eval_batch_size: 2\n",
      "  warmup_steps: 100\n",
      "  learning_rate: 5e-05\n",
      "  logging_steps: 10\n",
      "  evaluation_strategy: steps\n",
      "  eval_steps: 50\n",
      "  save_steps: 100\n",
      "  save_total_limit: 2\n",
      "  load_best_model_at_end: True\n",
      "  metric_for_best_model: eval_loss\n",
      "  greater_is_better: False\n",
      "  report_to: ['none']\n",
      "\n",
      "Total training steps: 12\n",
      "Checkpoints will be saved every 100 steps\n",
      "Evaluation will run every 50 steps\n"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "training_config = {\n",
    "    \"output_dir\": \"./model_output\",\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"per_device_train_batch_size\": 2,\n",
    "    \"per_device_eval_batch_size\": 2,\n",
    "    \"warmup_steps\": 100,\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"logging_steps\": 10,\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"eval_steps\": 50,\n",
    "    \"save_steps\": 100,\n",
    "    \"save_total_limit\": 2,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"metric_for_best_model\": \"eval_loss\",\n",
    "    \"greater_is_better\": False,\n",
    "    \"report_to\": [\"none\"],  # Could be \"tensorboard\", \"wandb\"\n",
    "}\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "for key, value in training_config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Calculate training statistics if data is available\n",
    "if 'train_texts' in locals():\n",
    "    total_steps = (len(train_texts) // training_config[\"per_device_train_batch_size\"]) * training_config[\"num_train_epochs\"]\n",
    "    print(f\"\\nTotal training steps: {total_steps}\")\n",
    "    print(f\"Checkpoints will be saved every {training_config['save_steps']} steps\")\n",
    "    print(f\"Evaluation will run every {training_config['eval_steps']} steps\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Training data not available - skipping training statistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    from IPython.display import clear_output\n",
    "    HAS_MATPLOTLIB = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è matplotlib not available - install with: pip install matplotlib\")\n",
    "    HAS_MATPLOTLIB = False\n",
    "\n",
    "def simulate_training_metrics(num_steps: int = 100):\n",
    "    \"\"\"\n",
    "    Simulate training metrics for visualization\n",
    "    \"\"\"\n",
    "    steps = []\n",
    "    train_losses = []\n",
    "    eval_losses = []\n",
    "    learning_rates = []\n",
    "    \n",
    "    # Initial values\n",
    "    train_loss = 4.5\n",
    "    eval_loss = 4.6\n",
    "    base_lr = 5e-5\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        # Simulate loss decrease\n",
    "        train_loss *= 0.98 + np.random.normal(0, 0.01)\n",
    "        eval_loss *= 0.985 + np.random.normal(0, 0.015)\n",
    "        \n",
    "        # Simulate learning rate warmup and decay\n",
    "        if step < 10:\n",
    "            lr = base_lr * (step + 1) / 10  # Warmup\n",
    "        else:\n",
    "            lr = base_lr * 0.995 ** (step - 10)  # Decay\n",
    "        \n",
    "        steps.append(step)\n",
    "        train_losses.append(train_loss)\n",
    "        eval_losses.append(eval_loss)\n",
    "        learning_rates.append(lr)\n",
    "        \n",
    "        # Update plot every 10 steps\n",
    "        if step % 10 == 0 and HAS_MATPLOTLIB:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "            \n",
    "            # Loss plot\n",
    "            ax1.plot(steps, train_losses, label='Train Loss', color='blue')\n",
    "            ax1.plot(steps, eval_losses, label='Eval Loss', color='orange')\n",
    "            ax1.set_xlabel('Steps')\n",
    "            ax1.set_ylabel('Loss')\n",
    "            ax1.set_title('Training Progress')\n",
    "            ax1.legend()\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Learning rate plot\n",
    "            ax2.plot(steps, learning_rates, color='green')\n",
    "            ax2.set_xlabel('Steps')\n",
    "            ax2.set_ylabel('Learning Rate')\n",
    "            ax2.set_title('Learning Rate Schedule')\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            print(f\"Step {step}/{num_steps}\")\n",
    "            print(f\"Train Loss: {train_loss:.4f}\")\n",
    "            print(f\"Eval Loss: {eval_loss:.4f}\")\n",
    "            print(f\"Learning Rate: {lr:.2e}\")\n",
    "            \n",
    "            # Check for overfitting\n",
    "            if eval_loss > train_loss * 1.2:\n",
    "                print(\"‚ö†Ô∏è Warning: Possible overfitting detected!\")\n",
    "    \n",
    "    # Print final results if no plotting\n",
    "    if not HAS_MATPLOTLIB:\n",
    "        print(f\"\\nTraining simulation completed:\")\n",
    "        print(f\"Final train loss: {train_losses[-1]:.4f}\")\n",
    "        print(f\"Final eval loss: {eval_losses[-1]:.4f}\")\n",
    "        print(f\"Steps completed: {num_steps}\")\n",
    "    \n",
    "    return steps, train_losses, eval_losses\n",
    "\n",
    "# Run training simulation\n",
    "print(\"Simulating training progress...\")\n",
    "steps, train_losses, eval_losses = simulate_training_metrics(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è Common Training Pitfalls and Solutions\n",
    "\n",
    "Let's create a diagnostic tool to help identify and resolve common training issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Issue Diagnosis:\n",
      "==================================================\n",
      "\n",
      "Symptom: 'My model shows CUDA out of memory error'\n",
      "\n",
      "Diagnosis: OOM\n",
      "\n",
      "Possible causes:\n",
      "  ‚Ä¢ Batch size too large\n",
      "  ‚Ä¢ Model too large\n",
      "  ‚Ä¢ Memory leak\n",
      "\n",
      "Recommended solutions:\n",
      "  1. Reduce batch size (try 1 or 2)\n",
      "  2. Enable gradient accumulation\n",
      "  3. Use gradient checkpointing\n",
      "  4. Clear cache: torch.cuda.empty_cache()\n",
      "  5. Use mixed precision (fp16)\n",
      "  6. Use parameter-efficient methods (LoRA)\n",
      "\n",
      "Symptom: 'Training loss decreases but validation loss increases after epoch 2'\n"
     ]
    }
   ],
   "source": [
    "def diagnose_training_issues(symptoms: List[str]):\n",
    "    \"\"\"\n",
    "    Diagnose common training issues based on symptoms\n",
    "    \"\"\"\n",
    "    diagnostics = {\n",
    "        \"loss_explosion\": {\n",
    "            \"symptoms\": [\"loss goes to inf\", \"loss increases rapidly\", \"nan loss\"],\n",
    "            \"causes\": [\"Learning rate too high\", \"Gradient explosion\", \"Numerical instability\"],\n",
    "            \"solutions\": [\n",
    "                \"Reduce learning rate (try 1e-5 or lower)\",\n",
    "                \"Enable gradient clipping (max_grad_norm=1.0)\",\n",
    "                \"Use mixed precision training with loss scaling\",\n",
    "                \"Check for division by zero in custom loss\"\n",
    "            ]\n",
    "        },\n",
    "        \"no_learning\": {\n",
    "            \"symptoms\": [\"loss stays constant\", \"no improvement\", \"stuck loss\"],\n",
    "            \"causes\": [\"Learning rate too low\", \"Dead neurons\", \"Data issues\"],\n",
    "            \"solutions\": [\n",
    "                \"Increase learning rate (try 2e-4)\",\n",
    "                \"Check if model outputs are changing\",\n",
    "                \"Verify data loading and preprocessing\",\n",
    "                \"Try different initialization\"\n",
    "            ]\n",
    "        },\n",
    "        \"overfitting\": {\n",
    "            \"symptoms\": [\"train loss decreases but val loss increases\", \"gap between train and val\"],\n",
    "            \"causes\": [\"Model too large\", \"Too little data\", \"No regularization\"],\n",
    "            \"solutions\": [\n",
    "                \"Add dropout (0.1-0.3)\",\n",
    "                \"Reduce model size\",\n",
    "                \"Augment training data\",\n",
    "                \"Add weight decay (0.01-0.1)\",\n",
    "                \"Early stopping\"\n",
    "            ]\n",
    "        },\n",
    "        \"oom\": {\n",
    "            \"symptoms\": [\"cuda out of memory\", \"oom error\", \"memory error\"],\n",
    "            \"causes\": [\"Batch size too large\", \"Model too large\", \"Memory leak\"],\n",
    "            \"solutions\": [\n",
    "                \"Reduce batch size (try 1 or 2)\",\n",
    "                \"Enable gradient accumulation\",\n",
    "                \"Use gradient checkpointing\",\n",
    "                \"Clear cache: torch.cuda.empty_cache()\",\n",
    "                \"Use mixed precision (fp16)\",\n",
    "                \"Use parameter-efficient methods (LoRA)\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Find matching issues\n",
    "    matched_issues = []\n",
    "    \n",
    "    for symptom in symptoms:\n",
    "        symptom_lower = symptom.lower()\n",
    "        for issue, details in diagnostics.items():\n",
    "            if any(s in symptom_lower for s in details[\"symptoms\"]):\n",
    "                matched_issues.append((issue, details))\n",
    "    \n",
    "    return matched_issues\n",
    "\n",
    "# Test the diagnostic tool\n",
    "user_symptoms = [\n",
    "    \"My model shows CUDA out of memory error\",\n",
    "    \"Training loss decreases but validation loss increases after epoch 2\"\n",
    "]\n",
    "\n",
    "print(\"Training Issue Diagnosis:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for symptom in user_symptoms:\n",
    "    print(f\"\\nSymptom: '{symptom}'\")\n",
    "    issues = diagnose_training_issues([symptom])\n",
    "    \n",
    "    for issue_name, details in issues:\n",
    "        print(f\"\\nDiagnosis: {issue_name.upper().replace('_', ' ')}\")\n",
    "        print(\"\\nPossible causes:\")\n",
    "        for cause in details[\"causes\"]:\n",
    "            print(f\"  ‚Ä¢ {cause}\")\n",
    "        \n",
    "        print(\"\\nRecommended solutions:\")\n",
    "        for i, solution in enumerate(details[\"solutions\"], 1):\n",
    "            print(f\"  {i}. {solution}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Summary and Key Takeaways\n",
    "\n",
    "Congratulations! You've completed a comprehensive journey through building custom language models. Let's summarize what we've learned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a summary visualization\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as mpatches\n",
    "    HAS_MATPLOTLIB = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è matplotlib not available - showing text-based summary instead\")\n",
    "    HAS_MATPLOTLIB = False\n",
    "\n",
    "if HAS_MATPLOTLIB:\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    # Define the pipeline stages\n",
    "    stages = [\n",
    "        \"Data Collection\",\n",
    "        \"Text Cleaning\",\n",
    "        \"Bias Detection\",\n",
    "        \"Tokenization\",\n",
    "        \"Model Config\",\n",
    "        \"Training\",\n",
    "        \"Evaluation\",\n",
    "        \"Deployment\"\n",
    "    ]\n",
    "\n",
    "    # Key learnings for each stage\n",
    "    learnings = [\n",
    "        \"Quality > Quantity\\nDomain relevance\",\n",
    "        \"Remove noise\\nNormalize text\",\n",
    "        \"Check fairness\\nMitigate bias\",\n",
    "        \"Custom vocab\\nDomain terms\",\n",
    "        \"Architecture\\nPEFT methods\",\n",
    "        \"Monitor metrics\\nEarly stopping\",\n",
    "        \"Error analysis\\nIteration\",\n",
    "        \"Production ready\\nScalable\"\n",
    "    ]\n",
    "\n",
    "    # Create flowchart\n",
    "    y_positions = range(len(stages), 0, -1)\n",
    "    x_position = 0.5\n",
    "\n",
    "    for i, (stage, learning) in enumerate(zip(stages, learnings)):\n",
    "        # Draw box\n",
    "        rect = mpatches.FancyBboxPatch(\n",
    "            (x_position - 0.4, y_positions[i] - 0.4),\n",
    "            0.8, 0.8,\n",
    "            boxstyle=\"round,pad=0.1\",\n",
    "            facecolor='lightblue' if i % 2 == 0 else 'lightgreen',\n",
    "            edgecolor='black',\n",
    "            linewidth=2\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Add text\n",
    "        ax.text(x_position, y_positions[i] + 0.1, stage, \n",
    "                ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "        ax.text(x_position, y_positions[i] - 0.2, learning, \n",
    "                ha='center', va='center', fontsize=9, style='italic')\n",
    "        \n",
    "        # Draw arrow to next stage\n",
    "        if i < len(stages) - 1:\n",
    "            ax.arrow(x_position, y_positions[i] - 0.45, 0, -0.1, \n",
    "                    head_width=0.05, head_length=0.05, fc='gray', ec='gray')\n",
    "\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, len(stages) + 1)\n",
    "    ax.axis('off')\n",
    "    ax.set_title('Language Model Development Pipeline', fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    # Text-based summary for when matplotlib is not available\n",
    "    print(\"\\nüéØ Language Model Development Pipeline Summary\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    stages_and_learnings = [\n",
    "        (\"Data Collection\", \"Quality > Quantity, Domain relevance\"),\n",
    "        (\"Text Cleaning\", \"Remove noise, Normalize text\"),\n",
    "        (\"Bias Detection\", \"Check fairness, Mitigate bias\"),\n",
    "        (\"Tokenization\", \"Custom vocab, Domain terms\"),\n",
    "        (\"Model Config\", \"Architecture, PEFT methods\"),\n",
    "        (\"Training\", \"Monitor metrics, Early stopping\"),\n",
    "        (\"Evaluation\", \"Error analysis, Iteration\"),\n",
    "        (\"Deployment\", \"Production ready, Scalable\")\n",
    "    ]\n",
    "    \n",
    "    for i, (stage, learning) in enumerate(stages_and_learnings, 1):\n",
    "        print(f\"\\n{i}. {stage}\")\n",
    "        print(f\"   ‚Üí {learning}\")\n",
    "        if i < len(stages_and_learnings):\n",
    "            print(f\"   ‚Üì\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìö Key Takeaways\n",
    "\n",
    "1. **Data Quality Drives Results** üìä\n",
    "   - Clean, relevant data is more valuable than quantity\n",
    "   - Domain-specific curation creates specialized models\n",
    "   - Regular quality checks prevent downstream issues\n",
    "\n",
    "2. **Efficient Processing Enables Scale** üöÄ\n",
    "   - Streaming handles datasets larger than memory\n",
    "   - Batch processing improves throughput\n",
    "   - Privacy protection is non-negotiable\n",
    "\n",
    "3. **Modern Techniques Save Resources** üí°\n",
    "   - Parameter-efficient methods (LoRA/QLoRA) democratize fine-tuning\n",
    "   - Mixed precision training reduces memory usage\n",
    "   - Gradient checkpointing enables larger models\n",
    "\n",
    "4. **Monitoring Prevents Failures** üìà\n",
    "   - Track multiple metrics, not just loss\n",
    "   - Early stopping saves compute\n",
    "   - Regular evaluation catches issues early\n",
    "\n",
    "5. **Iteration Drives Improvement** üîÑ\n",
    "   - Error analysis reveals model weaknesses\n",
    "   - A/B testing validates improvements\n",
    "   - User feedback guides development\n",
    "\n",
    "### üöÄ Next Steps\n",
    "\n",
    "Ready to build your own custom language model? Here's your action plan:\n",
    "\n",
    "1. **Identify Your Domain**: What specific area needs a custom model?\n",
    "2. **Gather Quality Data**: Start collecting domain-specific texts\n",
    "3. **Start Small**: Begin with a small model and dataset\n",
    "4. **Iterate Quickly**: Build, test, and improve in rapid cycles\n",
    "5. **Scale Gradually**: Increase size as you validate results\n",
    "\n",
    "### üéØ Try This\n",
    "\n",
    "**Challenge**: Take a domain you're familiar with and:\n",
    "1. List 5 unique data sources that generic models might miss\n",
    "2. Identify 10 domain-specific terms that need proper tokenization\n",
    "3. Design a simple evaluation metric for your use case\n",
    "\n",
    "Remember: The best model is the one that solves your specific problem effectively!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a summary visualization\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as mpatches\n",
    "    HAS_MATPLOTLIB = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è matplotlib not available - skipping visualization\")\n",
    "    HAS_MATPLOTLIB = False\n",
    "\n",
    "if HAS_MATPLOTLIB:\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    # Define the pipeline stages\n",
    "    stages = [\n",
    "        \"Data Collection\",\n",
    "        \"Text Cleaning\",\n",
    "        \"Bias Detection\",\n",
    "        \"Tokenization\",\n",
    "        \"Model Config\",\n",
    "        \"Training\",\n",
    "        \"Evaluation\",\n",
    "        \"Deployment\"\n",
    "    ]\n",
    "\n",
    "    # Key learnings for each stage\n",
    "    learnings = [\n",
    "        \"Quality > Quantity\\nDomain relevance\",\n",
    "        \"Remove noise\\nNormalize text\",\n",
    "        \"Check fairness\\nMitigate bias\",\n",
    "        \"Custom vocab\\nDomain terms\",\n",
    "        \"Architecture\\nPEFT methods\",\n",
    "        \"Monitor metrics\\nEarly stopping\",\n",
    "        \"Error analysis\\nIteration\",\n",
    "        \"Production ready\\nScalable\"\n",
    "    ]\n",
    "\n",
    "    # Create flowchart\n",
    "    y_positions = range(len(stages), 0, -1)\n",
    "    x_position = 0.5\n",
    "\n",
    "    for i, (stage, learning) in enumerate(zip(stages, learnings)):\n",
    "        # Draw box\n",
    "        rect = mpatches.FancyBboxPatch(\n",
    "            (x_position - 0.4, y_positions[i] - 0.4),\n",
    "            0.8, 0.8,\n",
    "            boxstyle=\"round,pad=0.1\",\n",
    "            facecolor='lightblue' if i % 2 == 0 else 'lightgreen',\n",
    "            edgecolor='black',\n",
    "            linewidth=2\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Add text\n",
    "        ax.text(x_position, y_positions[i] + 0.1, stage, \n",
    "                ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "        ax.text(x_position, y_positions[i] - 0.2, learning, \n",
    "                ha='center', va='center', fontsize=9, style='italic')\n",
    "        \n",
    "        # Draw arrow to next stage\n",
    "        if i < len(stages) - 1:\n",
    "            ax.arrow(x_position, y_positions[i] - 0.45, 0, -0.1, \n",
    "                    head_width=0.05, head_length=0.05, fc='gray', ec='gray')\n",
    "\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, len(stages) + 1)\n",
    "    ax.axis('off')\n",
    "    ax.set_title('Language Model Development Pipeline', fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    # Text-based summary for when matplotlib is not available\n",
    "    print(\"\\nüéØ Language Model Development Pipeline Summary\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    stages = [\n",
    "        (\"Data Collection\", \"Quality > Quantity, Domain relevance\"),\n",
    "        (\"Text Cleaning\", \"Remove noise, Normalize text\"),\n",
    "        (\"Bias Detection\", \"Check fairness, Mitigate bias\"),\n",
    "        (\"Tokenization\", \"Custom vocab, Domain terms\"),\n",
    "        (\"Model Config\", \"Architecture, PEFT methods\"),\n",
    "        (\"Training\", \"Monitor metrics, Early stopping\"),\n",
    "        (\"Evaluation\", \"Error analysis, Iteration\"),\n",
    "        (\"Deployment\", \"Production ready, Scalable\")\n",
    "    ]\n",
    "    \n",
    "    for i, (stage, learning) in enumerate(stages, 1):\n",
    "        print(f\"\\n{i}. {stage}\")\n",
    "        print(f\"   ‚Üí {learning}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Troubleshooting Guide\n",
    "\n",
    "### Common Issues and Solutions\n",
    "\n",
    "#### 1. ‚ö° Accelerate Version Compatibility\n",
    "\n",
    "If you encounter issues with model initialization or training:\n",
    "\n",
    "```bash\n",
    "# Check current version\n",
    "poetry show accelerate\n",
    "\n",
    "# Update to required version\n",
    "poetry add accelerate@^0.26.0\n",
    "\n",
    "# Or with pip\n",
    "pip install accelerate>=0.26.0\n",
    "```\n",
    "\n",
    "**Symptoms**: \n",
    "- ImportError with accelerate\n",
    "- Model initialization failures\n",
    "- Training configuration errors\n",
    "\n",
    "#### 2. üîë API Key Configuration Errors\n",
    "\n",
    "**Issue**: \"API key not found\" or \"placeholder value\" errors\n",
    "\n",
    "**Solution**:\n",
    "1. Create `.env` file from template:\n",
    "   ```bash\n",
    "   cp .env.example .env\n",
    "   ```\n",
    "\n",
    "2. Edit `.env` and add actual API keys:\n",
    "   ```\n",
    "   OPENAI_API_KEY=sk-...your-actual-key...\n",
    "   ANTHROPIC_API_KEY=sk-ant-...your-actual-key...\n",
    "   HUGGINGFACE_TOKEN=hf_...your-actual-token...\n",
    "   ```\n",
    "\n",
    "3. Verify keys are loaded:\n",
    "   ```python\n",
    "   import os\n",
    "   from dotenv import load_dotenv\n",
    "   load_dotenv(override=True)  # Force reload\n",
    "   \n",
    "   # Check if loaded correctly\n",
    "   print(f\"OpenAI key starts with: {os.getenv('OPENAI_API_KEY', 'Not set')[:10]}...\")\n",
    "   ```\n",
    "\n",
    "4. Restart kernel after updating `.env`\n",
    "\n",
    "#### 3. üñ•Ô∏è Bitsandbytes GPU Warning on macOS\n",
    "\n",
    "**Issue**: \"GPU not supported\" warning when importing bitsandbytes\n",
    "\n",
    "**Solution**:\n",
    "```python\n",
    "# Suppress the warning\n",
    "import os\n",
    "os.environ[\"BITSANDBYTES_NOWELCOME\"] = \"1\"\n",
    "\n",
    "# Note: Bitsandbytes will fallback to CPU on macOS\n",
    "# This is expected behavior - Metal/MPS is not yet supported\n",
    "```\n",
    "\n",
    "#### 4. üíæ CUDA Out of Memory Errors\n",
    "\n",
    "**Symptoms**: `RuntimeError: CUDA out of memory`\n",
    "\n",
    "**Solutions**:\n",
    "```python\n",
    "# 1. Reduce batch size\n",
    "training_args.per_device_train_batch_size = 1\n",
    "training_args.per_device_eval_batch_size = 1\n",
    "\n",
    "# 2. Enable gradient accumulation\n",
    "training_args.gradient_accumulation_steps = 8\n",
    "\n",
    "# 3. Use mixed precision\n",
    "training_args.fp16 = True  # or bf16=True for newer GPUs\n",
    "\n",
    "# 4. Clear GPU cache\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 5. Use gradient checkpointing\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "# 6. Use parameter-efficient methods\n",
    "from peft import LoraConfig, get_peft_model\n",
    "peft_config = LoraConfig(\n",
    "    r=4,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.1,\n",
    ")\n",
    "model = get_peft_model(model, peft_config)\n",
    "```\n",
    "\n",
    "#### 5. üì¶ Import Errors\n",
    "\n",
    "**Issue**: Module not found errors\n",
    "\n",
    "**Solutions**:\n",
    "```bash\n",
    "# Full reinstall with Poetry\n",
    "poetry install\n",
    "\n",
    "# Or specific package\n",
    "poetry add transformers@^4.36.0\n",
    "poetry add datasets@^2.14.0\n",
    "poetry add peft@^0.7.0\n",
    "\n",
    "# Verify installation\n",
    "poetry show\n",
    "\n",
    "# If using pip instead\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "#### 6. üåê Dataset Loading Errors\n",
    "\n",
    "**Issue**: Connection errors or timeouts when loading datasets\n",
    "\n",
    "**Solutions**:\n",
    "```python\n",
    "# 1. Use local cache\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"dataset_name\", cache_dir=\"./cache\")\n",
    "\n",
    "# 2. Set timeout\n",
    "import requests\n",
    "from datasets import config\n",
    "config.DATASETS_DOWNLOAD_TIMEOUT = 300  # 5 minutes\n",
    "\n",
    "# 3. Use offline mode\n",
    "os.environ[\"HF_DATASETS_OFFLINE\"] = \"1\"\n",
    "\n",
    "# 4. Load from local files\n",
    "dataset = Dataset.from_json(\"local_data.json\")\n",
    "```\n",
    "\n",
    "#### 7. üîÑ Training Not Converging\n",
    "\n",
    "**Symptoms**: Loss stays constant or increases\n",
    "\n",
    "**Diagnostic Steps**:\n",
    "```python\n",
    "# 1. Check learning rate\n",
    "print(f\"Learning rate: {trainer.args.learning_rate}\")\n",
    "# Try: 5e-5, 2e-5, 1e-5, 5e-6\n",
    "\n",
    "# 2. Verify data is loaded correctly\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Sample: {train_dataset[0]}\")\n",
    "\n",
    "# 3. Check model outputs change\n",
    "before = model(input_ids).logits\n",
    "optimizer.step()\n",
    "after = model(input_ids).logits\n",
    "print(f\"Outputs changed: {not torch.allclose(before, after)}\")\n",
    "\n",
    "# 4. Enable logging\n",
    "training_args.logging_steps = 1\n",
    "training_args.logging_first_step = True\n",
    "```\n",
    "\n",
    "### üèÉ Running Examples Outside Notebook\n",
    "\n",
    "The project includes task automation for easy execution:\n",
    "\n",
    "```bash\n",
    "# Setup environment (one-time)\n",
    "task setup\n",
    "\n",
    "# Run all examples\n",
    "task run\n",
    "\n",
    "# Run specific components\n",
    "task run-prompt-engineering\n",
    "task run-few-shot-learning\n",
    "task run-chain-of-thought\n",
    "\n",
    "# Run tests\n",
    "task test\n",
    "\n",
    "# Format code\n",
    "task format\n",
    "\n",
    "# Clean generated files\n",
    "task clean\n",
    "```\n",
    "\n",
    "### üìö Additional Resources\n",
    "\n",
    "1. **Project Documentation**: See `docs/article11.md` for comprehensive guide\n",
    "2. **Hugging Face Forums**: https://discuss.huggingface.co/\n",
    "3. **PyTorch Forums**: https://discuss.pytorch.org/\n",
    "4. **Accelerate Documentation**: https://huggingface.co/docs/accelerate/\n",
    "\n",
    "### üÜò Getting Help\n",
    "\n",
    "If you encounter issues not covered here:\n",
    "\n",
    "1. Check error messages carefully - they often contain the solution\n",
    "2. Search for the error message online\n",
    "3. Create a minimal reproducible example\n",
    "4. Check project issues on GitHub\n",
    "5. Ask on relevant forums with:\n",
    "   - Your environment details (OS, Python version, package versions)\n",
    "   - Complete error traceback\n",
    "   - Minimal code to reproduce\n",
    "\n",
    "Remember: Most errors have been encountered before - the solution is usually just a search away!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
