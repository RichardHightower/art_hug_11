{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title-cell",
   "metadata": {},
   "source": [
    "# üöÄ Building Custom Language Models: From Raw Data to Production AI\n",
    "\n",
    "In today's rapidly evolving AI landscape, the ability to create custom language models tailored to specific domains represents a **critical competitive advantage**. This comprehensive guide walks you through the complete lifecycle of building language models‚Äîfrom curating high-quality datasets to training and deploying powerful AI systems that deliver real business value.\n",
    "\n",
    "Whether you're developing specialized models for healthcare, finance, legal services, or any domain requiring nuanced understanding, this tutorial provides the **practical knowledge and code examples** you need to succeed. We'll explore modern techniques using the Hugging Face ecosystem that balance efficiency, scalability, and model quality.\n",
    "\n",
    "Based on the enhanced Chapter 11: Dataset Curation and Training Language Models from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intro-cell",
   "metadata": {},
   "source": [
    "## Introduction & Executive Summary\n",
    "\n",
    "In today's AI-driven world, the ability to create custom language models tailored to specific domains and tasks represents a critical competitive advantage. Whether you're developing specialized models for healthcare, finance, legal services, or any domain requiring nuanced understanding, this tutorial provides the practical knowledge and code examples you need to succeed.\n",
    "\n",
    "### üéØ Executive Summary\n",
    "\n",
    "Building effective custom language models depends critically on **high-quality, domain-specific data**. While full model training from scratch is rare due to cost and complexity, **fine-tuning pre-trained models** using Parameter-Efficient Fine-Tuning (PEFT) on curated datasets is now the standard.\n",
    "\n",
    "**Key pillars for success:**\n",
    "- üìä **High-quality data** - The foundation of all great models\n",
    "- ‚òÅÔ∏è **Scalable, privacy-aware processing** - Handle big data responsibly\n",
    "- üîÅ **Reproducible workflows** - Track everything for reliability\n",
    "- üìà **Iterative refinement and monitoring** - Continuous improvement\n",
    "\n",
    "### üìö What You'll Master:\n",
    "\n",
    "- **Data curation fundamentals**: selecting, cleaning, and preparing domain-specific text\n",
    "- **Bias detection and mitigation**: ensuring fair and ethical AI\n",
    "- **Synthetic data generation**: augmenting datasets with LLM-generated examples\n",
    "- **Scalable processing techniques** for handling massive datasets efficiently\n",
    "- **Privacy protection and data versioning** for responsible AI development\n",
    "- **Modern model architecture selection** and configuration strategies\n",
    "- **Training workflows** with distributed computing and experiment tracking\n",
    "- **Parameter-efficient fine-tuning methods** for adapting large models\n",
    "- **Evaluation, error analysis**, and iterative improvement techniques\n",
    "\n",
    "**Ever wondered what unique data could give your model an unstoppable edge?** ü§î"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65i2f60h0fk",
   "metadata": {},
   "source": [
    "## üìë Table of Contents\n",
    "\n",
    "1. [Introduction & Executive Summary](#introduction--executive-summary)\n",
    "2. [Environment Setup & Configuration](#environment-setup--configuration)\n",
    "3. [Part 1: Data Curation - The Foundation](#part-1-data-curation---the-foundation)\n",
    "   - [1.1 Basic Data Cleaning](#11-basic-data-cleaning)\n",
    "   - [1.2 Scalable Text Processing](#12-scalable-text-processing)\n",
    "   - [1.3 Language Detection & Filtering](#13-language-detection--filtering)\n",
    "   - [1.4 Privacy Protection: PII Redaction](#14-privacy-protection-pii-redaction)\n",
    "   - [1.5 Bias Detection & Mitigation](#15-bias-detection--mitigation)\n",
    "   - [1.6 Synthetic Data Generation](#16-synthetic-data-generation)\n",
    "4. [Part 2: Scaling Data Processing & Streaming](#part-2-scaling-data-processing--streaming)\n",
    "   - [2.1 Handling Large-Scale Data](#21-handling-large-scale-data)\n",
    "   - [2.2 Data Versioning & Reproducibility](#22-data-versioning--reproducibility)\n",
    "5. [Part 3: Tokenization & Vocabulary Creation](#part-3-tokenization--vocabulary-creation)\n",
    "   - [3.1 Training Custom Tokenizers](#31-training-custom-tokenizers)\n",
    "   - [3.2 Tokenizer Comparison & Analysis](#32-tokenizer-comparison--analysis)\n",
    "6. [Part 4: Model Configuration & Initialization](#part-4-model-configuration--initialization)\n",
    "   - [4.1 Architecture Selection](#41-architecture-selection)\n",
    "   - [4.2 Modern Model Configuration](#42-modern-model-configuration)\n",
    "   - [4.3 Parameter-Efficient Fine-Tuning (PEFT)](#43-parameter-efficient-fine-tuning-peft)\n",
    "7. [Part 5: Training Workflows & Evaluation](#part-5-training-workflows--evaluation)\n",
    "   - [5.1 Training Setup & Monitoring](#51-training-setup--monitoring)\n",
    "   - [5.2 Metrics & Early Stopping](#52-metrics--early-stopping)\n",
    "   - [5.3 Error Analysis & Improvement](#53-error-analysis--improvement)\n",
    "8. [Part 6: Advanced Techniques](#part-6-advanced-techniques)\n",
    "   - [6.1 Few-Shot Learning](#61-few-shot-learning)\n",
    "   - [6.2 Chain of Thought Reasoning](#62-chain-of-thought-reasoning)\n",
    "9. [Summary & Key Takeaways](#summary--key-takeaways)\n",
    "10. [Common Pitfalls & Troubleshooting](#common-pitfalls--troubleshooting)\n",
    "11. [Exercises & Next Steps](#exercises--next-steps)\n",
    "12. [Glossary of Terms](#glossary-of-terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cuxzltohx4p",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    subgraph Data[\"üìä Data Foundation\"]\n",
    "        A[Raw Text] --> B[Clean & Normalize]\n",
    "        B --> C[Remove PII]\n",
    "        C --> D[Detect Bias]\n",
    "        D --> E[Augment with Synthetic]\n",
    "    end\n",
    "    \n",
    "    subgraph Process[\"‚öôÔ∏è Processing\"]\n",
    "        E --> F[Stream & Batch]\n",
    "        F --> G[Version Control]\n",
    "        G --> H[Tokenize]\n",
    "    end\n",
    "    \n",
    "    subgraph Model[\"ü§ñ Model\"]\n",
    "        H --> I[Select Architecture]\n",
    "        I --> J[Configure]\n",
    "        J --> K[PEFT/LoRA]\n",
    "    end\n",
    "    \n",
    "    subgraph Train[\"üöÄ Training\"]\n",
    "        K --> L[Setup Training]\n",
    "        L --> M[Monitor Metrics]\n",
    "        M --> N[Iterate & Improve]\n",
    "    end\n",
    "    \n",
    "    N --> O[Production Ready Model]\n",
    "    \n",
    "    style Data fill:#e1f5fe\n",
    "    style Process fill:#f3e5f5\n",
    "    style Model fill:#e8f5e9\n",
    "    style Train fill:#fff3e0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-cell",
   "metadata": {},
   "source": [
    "## Environment Setup & Configuration\n",
    "\n",
    "First, let's set up our environment with the necessary libraries and validate our configuration. We'll ensure we have all the tools needed for building production-ready language models.\n",
    "\n",
    "### üõ†Ô∏è Prerequisites\n",
    "- Python 3.12.9 (managed via pyenv)\n",
    "- Poetry for dependency management\n",
    "- GPU/MPS support recommended for faster training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jdv36uhnfh",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è Important Notes on Library Versions\n",
    "\n",
    "> **üí° Pro Tip**: Always use the latest stable Python version (3.12.9 for this project) and ensure accelerate >= 0.26.0 to avoid compatibility issues.\n",
    "\n",
    "Due to version compatibility, we've made the following adaptations:\n",
    "1. **Accelerate Version**: Ensure you have accelerate >= 0.26.0 installed\n",
    "2. **Model Examples**: Using Llama-3/Gemma-2 where available, with GPT-2 as fallback\n",
    "3. **Streaming**: Wikipedia dataset uses latest configs (e.g., '20240101.en')\n",
    "\n",
    "These adaptations ensure smooth execution while maintaining all learning objectives!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richardhightower/src/art_hug_11/src/config.py:51: UserWarning: OPENAI_API_KEY not found in environment variables\n",
      "  warnings.warn(f\"{key_name} not found in environment variables\", UserWarning)\n",
      "/Users/richardhightower/src/art_hug_11/src/config.py:51: UserWarning: ANTHROPIC_API_KEY not found in environment variables\n",
      "  warnings.warn(f\"{key_name} not found in environment variables\", UserWarning)\n",
      "/Users/richardhightower/src/art_hug_11/src/config.py:51: UserWarning: HUGGINGFACE_TOKEN not found in environment variables\n",
      "  warnings.warn(f\"{key_name} not found in environment variables\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üöÄ Environment Configuration\n",
      "======================================================================\n",
      "Python version: 3.12.9\n",
      "PyTorch version: 2.7.1\n",
      "Transformers version: 4.39.3\n",
      "Datasets version: 2.14.4\n",
      "Device: mps\n",
      "\n",
      "üì¶ Optional Libraries:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0728 14:58:29.621000 84456 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ peft: Parameter-Efficient Fine-Tuning\n",
      "‚úÖ langdetect: Language Detection\n",
      "‚ùå fairlearn: Bias Detection (not installed)\n",
      "‚ùå presidio_analyzer: Advanced PII Detection (not installed)\n",
      "‚úÖ accelerate: Distributed Training\n",
      "\n",
      "üîê API Key Configuration:\n",
      "‚ö†Ô∏è OpenAI API key not found (some features may be limited)\n",
      "‚ö†Ô∏è Anthropic API key not found (some features may be limited)\n",
      "‚ö†Ô∏è Hugging Face API key not found (some features may be limited)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Core imports with comprehensive error handling\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "import warnings\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.append(str(Path.cwd().parent / 'src'))\n",
    "\n",
    "# Import our modules with error handling\n",
    "try:\n",
    "    from config import get_device, DATA_DIR, MODELS_DIR, validate_api_key\n",
    "except ImportError as e:\n",
    "    print(f\"Warning: Could not import config module: {e}\")\n",
    "    # Fallback definitions\n",
    "    DATA_DIR = Path.cwd() / 'data'\n",
    "    MODELS_DIR = Path.cwd() / 'models'\n",
    "    def get_device() -> str:\n",
    "        import torch\n",
    "        if torch.backends.mps.is_available():\n",
    "            return \"mps\"\n",
    "        elif torch.cuda.is_available():\n",
    "            return \"cuda\"\n",
    "        return \"cpu\"\n",
    "\n",
    "# Core library imports\n",
    "import torch\n",
    "import transformers\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Version checks and display\n",
    "print(\"=\" * 70)\n",
    "print(\"üöÄ Environment Configuration\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Python version: {sys.version.split()[0]}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "print(f\"Datasets version: {datasets.__version__}\")\n",
    "print(f\"Device: {get_device()}\")\n",
    "\n",
    "# Check for optional libraries\n",
    "optional_libs = {\n",
    "    'peft': 'Parameter-Efficient Fine-Tuning',\n",
    "    'langdetect': 'Language Detection',\n",
    "    'fairlearn': 'Bias Detection',\n",
    "    'presidio_analyzer': 'Advanced PII Detection',\n",
    "    'accelerate': 'Distributed Training'\n",
    "}\n",
    "\n",
    "print(\"\\nüì¶ Optional Libraries:\")\n",
    "for lib, description in optional_libs.items():\n",
    "    try:\n",
    "        __import__(lib)\n",
    "        print(f\"‚úÖ {lib}: {description}\")\n",
    "    except ImportError:\n",
    "        print(f\"‚ùå {lib}: {description} (not installed)\")\n",
    "\n",
    "# API Key validation\n",
    "print(\"\\nüîê API Key Configuration:\")\n",
    "api_keys = {\n",
    "    'OPENAI_API_KEY': 'OpenAI',\n",
    "    'ANTHROPIC_API_KEY': 'Anthropic',\n",
    "    'HUGGINGFACE_TOKEN': 'Hugging Face'\n",
    "}\n",
    "\n",
    "for key, service in api_keys.items():\n",
    "    if os.getenv(key):\n",
    "        print(f\"‚úÖ {service} API key found\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è {service} API key not found (some features may be limited)\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cyuv2rxx9cl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è No .env file found. Copy .env.example to .env and add your API keys\n",
      "   Example: cp ../.env.example ../.env\n",
      "‚ùå OPENAI_API_KEY: Not configured\n",
      "‚ùå ANTHROPIC_API_KEY: Not configured\n",
      "‚ùå HUGGINGFACE_TOKEN: Not configured\n"
     ]
    }
   ],
   "source": [
    "# Configure environment variables (if .env exists)\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "if Path('.env').exists():\n",
    "    load_dotenv()\n",
    "    print(\"‚úÖ Loaded environment variables from .env file\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No .env file found. Copy .env.example to .env and add your API keys\")\n",
    "    print(\"   Example: cp ../.env.example ../.env\")\n",
    "\n",
    "# Validate API keys if needed\n",
    "def check_api_key(key_name: str) -> bool:\n",
    "    \"\"\"Check if API key is valid (not empty or placeholder).\"\"\"\n",
    "    key = os.getenv(key_name, \"\")\n",
    "    if not key or key.startswith(\"your-\") or key == \"\":\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Display API key status\n",
    "for key in ['OPENAI_API_KEY', 'ANTHROPIC_API_KEY', 'HUGGINGFACE_TOKEN']:\n",
    "    if check_api_key(key):\n",
    "        print(f\"‚úÖ {key}: Valid\")\n",
    "    else:\n",
    "        print(f\"‚ùå {key}: Not configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1-header",
   "metadata": {},
   "source": [
    "## Part 1: Data Curation - The Foundation\n",
    "\n",
    "Great language models start with great data. Picture your dataset as ingredients for a gourmet meal‚Äîthe fresher and more carefully chosen, the better the final dish. **Even the most sophisticated AI architecture can't salvage a flawed foundation.**\n",
    "\n",
    "*\"Garbage in, garbage out\"* remains a core truth in AI. If your dataset contains messy, biased, or irrelevant content, your model will reflect those flaws with painful accuracy.\n",
    "\n",
    "### üéØ In this section, you'll learn:\n",
    "- ‚ú® Advanced text cleaning with Unicode normalization\n",
    "- üåç Multi-language detection and filtering\n",
    "- üîí Privacy protection with modern PII redaction\n",
    "- ‚öñÔ∏è Bias detection and mitigation strategies\n",
    "- ü§ñ Synthetic data generation for augmentation\n",
    "\n",
    "### 1.1 Basic Data Cleaning\n",
    "\n",
    "This example demonstrates how to clean raw text data by removing HTML tags, normalizing whitespace, and preparing it for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "basic-cleaning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d1e9dd5783f439aac4302a9df145eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Data Cleaning Results:\n",
      "============================================================\n",
      "\n",
      "üìù Example 1:\n",
      "Original: <p>Customer complaint: Product <b>broken</b></p>   Multiple   spaces!\n",
      "Cleaned:  Customer complaint: Product broken Multiple spaces!\n",
      "\n",
      "üìù Example 2:\n",
      "Original: <div>Great service!</div>\n",
      "\n",
      "\n",
      "Extra newlines\n",
      "Cleaned:  Great service! Extra newlines\n",
      "\n",
      "üìù Example 3:\n",
      "Original: Normal text without HTML\n",
      "Cleaned:  Normal text without HTML\n",
      "\n",
      "üìù Example 4:\n",
      "Original: Text with &amp; HTML entities &lt;encoded&gt;\n",
      "Cleaned:  Text with & HTML entities\n",
      "\n",
      "üìù Example 5:\n",
      "Original: Unicode issues: caf√©, na√Øve, r√©sum√©\n",
      "Cleaned:  Unicode issues: caf√©, na√Øve, r√©sum√©\n",
      "\n",
      "üìä Cleaning Statistics:\n",
      "Total characters reduced: 51 (23.7% reduction)\n"
     ]
    }
   ],
   "source": [
    "# Basic Data Cleaning with Hugging Face Datasets\n",
    "import re\n",
    "from datasets import Dataset\n",
    "from typing import Dict, Any\n",
    "\n",
    "# Create sample data that might come from customer logs\n",
    "sample_data = {\n",
    "    \"text\": [\n",
    "        \"<p>Customer complaint: Product <b>broken</b></p>   Multiple   spaces!\",\n",
    "        \"<div>Great service!</div>\\n\\n\\nExtra newlines\",\n",
    "        \"Normal text without HTML\",\n",
    "        \"Text with &amp; HTML entities &lt;encoded&gt;\",\n",
    "        \"Unicode issues: caf√©, na√Øve, r√©sum√©\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(sample_data)\n",
    "\n",
    "def clean_text(example: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Clean text by removing HTML and normalizing whitespace.\n",
    "    \n",
    "    Args:\n",
    "        example: Dictionary containing 'text' field\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with cleaned 'text' field\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text = example.get(\"text\", \"\")\n",
    "        \n",
    "        # Decode HTML entities\n",
    "        import html\n",
    "        text = html.unescape(text)\n",
    "        \n",
    "        # Remove HTML tags\n",
    "        text = re.sub(r'<.*?>', '', text)\n",
    "        \n",
    "        # Replace multiple spaces/newlines with a single space\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        \n",
    "        # Strip leading/trailing whitespace\n",
    "        text = text.strip()\n",
    "        \n",
    "        return {\"text\": text}\n",
    "    except Exception as e:\n",
    "        print(f\"Error cleaning text: {e}\")\n",
    "        return {\"text\": example.get(\"text\", \"\")}\n",
    "\n",
    "# Apply cleaning\n",
    "cleaned_dataset = dataset.map(clean_text)\n",
    "\n",
    "print(\"üßπ Data Cleaning Results:\")\n",
    "print(\"=\" * 60)\n",
    "for i in range(len(dataset)):\n",
    "    print(f\"\\nüìù Example {i+1}:\")\n",
    "    print(f\"Original: {dataset[i]['text']}\")\n",
    "    print(f\"Cleaned:  {cleaned_dataset[i]['text']}\")\n",
    "\n",
    "# Show statistics\n",
    "original_chars = sum(len(ex['text']) for ex in dataset)\n",
    "cleaned_chars = sum(len(ex['text']) for ex in cleaned_dataset)\n",
    "print(f\"\\nüìä Cleaning Statistics:\")\n",
    "print(f\"Total characters reduced: {original_chars - cleaned_chars} ({(1 - cleaned_chars/original_chars)*100:.1f}% reduction)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scalable-cleaning-header",
   "metadata": {},
   "source": [
    "### 1.2 Scalable Text Processing\n",
    "\n",
    "For production systems, we need more sophisticated cleaning that can handle large datasets efficiently. This example shows Unicode normalization, URL removal, and deduplication.\n",
    "\n",
    "> **üí° Pro Tip**: For multilingual datasets, always apply Unicode normalization (NFKC) to ensure consistent character representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "scalable-cleaning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98ed802530f4514a7cf325991bc024c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning Wikipedia-style examples:\n",
      "\n",
      "Example 1:\n",
      "Original: <p>Artificial intelligence (AI) is intelligence demonstrated by machines.</p> See more at https://example.com/ai\n",
      "Cleaned:  Artificial intelligence (AI) is intelligence demonstrated by machines. See more at\n",
      "\n",
      "Example 2:\n",
      "Original: Machine learning    is a subset of AI.\n",
      "\n",
      "\n",
      "It uses statistical techniques.\n",
      "Cleaned:  Machine learning is a subset of AI. It uses statistical techniques.\n",
      "\n",
      "Example 3:\n",
      "Original: Deep learning uses neural networks with multiple layers.\n",
      "Cleaned:  Deep learning uses neural networks with multiple layers.\n",
      "\n",
      "Example 4:\n",
      "Original: Natural language processing (NLP) enables computers to understand human language.\n",
      "Cleaned:  Natural language processing (NLP) enables computers to understand human language.\n"
     ]
    }
   ],
   "source": [
    "# Scalable Text Cleaning and Deduplication\n",
    "import unicodedata\n",
    "from datasets import Dataset\n",
    "\n",
    "# Since Wikipedia streaming has issues with local cache, let's create sample data\n",
    "sample_wiki_data = {\n",
    "    \"text\": [\n",
    "        \"<p>Artificial intelligence (AI) is intelligence demonstrated by machines.</p> See more at https://example.com/ai\",\n",
    "        \"Machine learning    is a subset of AI.\\n\\n\\nIt uses statistical techniques.\",\n",
    "        \"Deep learning uses neural networks with multiple layers.\",\n",
    "        \"Natural language processing (NLP) enables computers to understand human language.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "wiki_dataset = Dataset.from_dict(sample_wiki_data)\n",
    "\n",
    "def clean_text_advanced(example):\n",
    "    \"\"\"Advanced text cleaning with Unicode normalization.\"\"\"\n",
    "    text = unicodedata.normalize('NFKC', example['text'])  # Unicode normalization\n",
    "    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'https?://\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Normalize whitespace\n",
    "    text = text.strip()\n",
    "    return {\"text\": text}\n",
    "\n",
    "# Process examples\n",
    "cleaned_wiki = wiki_dataset.map(clean_text_advanced)\n",
    "\n",
    "print(\"Cleaning Wikipedia-style examples:\")\n",
    "for i in range(len(wiki_dataset)):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Original: {wiki_dataset[i]['text']}\")\n",
    "    print(f\"Cleaned:  {cleaned_wiki[i]['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "language-detection-header",
   "metadata": {},
   "source": [
    "### 1.3 Language Detection and Filtering\n",
    "\n",
    "When working with multilingual data, it's crucial to filter for your target language. This ensures model consistency and quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "language-detection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759afe268376468191818d6dd182f503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Detection Results:\n",
      "\n",
      "Original texts with detected languages:\n",
      "  [en] This is an English sentence.\n",
      "  [fr] Ceci est une phrase en fran√ßais.\n",
      "  [de] Dies ist ein deutscher Satz.\n",
      "  [en] This is another English example.\n",
      "  [ja] „Åì„Çå„ÅØÊó•Êú¨Ë™û„ÅÆÊñá„Åß„Åô„ÄÇ\n",
      "\n",
      "Filtered (English only):\n",
      "  This is an English sentence.\n",
      "  This is another English example.\n"
     ]
    }
   ],
   "source": [
    "# Automated Language Detection and Filtering\n",
    "try:\n",
    "    from langdetect import detect\n",
    "except ImportError:\n",
    "    print(\"Installing langdetect...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"langdetect\"])\n",
    "    from langdetect import detect\n",
    "\n",
    "# Sample multilingual data\n",
    "sample_texts = [\n",
    "    \"This is an English sentence.\",\n",
    "    \"Ceci est une phrase en fran√ßais.\",\n",
    "    \"Dies ist ein deutscher Satz.\",\n",
    "    \"This is another English example.\",\n",
    "    \"„Åì„Çå„ÅØÊó•Êú¨Ë™û„ÅÆÊñá„Åß„Åô„ÄÇ\"\n",
    "]\n",
    "\n",
    "dataset = Dataset.from_dict({\"text\": sample_texts})\n",
    "\n",
    "def filter_english(example):\n",
    "    \"\"\"Filter to keep only English text.\"\"\"\n",
    "    try:\n",
    "        return detect(example['text']) == 'en'\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Filter for English only\n",
    "english_dataset = dataset.filter(filter_english)\n",
    "\n",
    "print(\"Language Detection Results:\")\n",
    "print(\"\\nOriginal texts with detected languages:\")\n",
    "for text in dataset['text']:\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "    except:\n",
    "        lang = \"unknown\"\n",
    "    print(f\"  [{lang}] {text}\")\n",
    "\n",
    "print(\"\\nFiltered (English only):\")\n",
    "for text in english_dataset['text']:\n",
    "    print(f\"  {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pii-header",
   "metadata": {},
   "source": [
    "### 1.4 Privacy Protection: PII Redaction\n",
    "\n",
    "When working with user data, protecting privacy is mandatory. This example shows basic PII (Personally Identifiable Information) redaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pii-redaction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîí PII Redaction Comparison:\n",
      "======================================================================\n",
      "\n",
      "üìù Example 1:\n",
      "Original:  Contact Dr. Smith at dr.smith@example.com or 555-123-4567.\n",
      "Basic:     Contact [NAME] at [EMAIL] or [PHONE].\n",
      "Advanced:  Contact [NAME] at [EMAIL] or [PHONE].\n",
      "\n",
      "üìù Example 2:\n",
      "Original:  SSN: 123-45-6789, Credit Card: 4532-1234-5678-9012\n",
      "Basic:     SSN: 123-45-6789, Credit Card: 4532-1234-5678-9012\n",
      "Advanced:  SSN: [SSN], Credit Card: [CREDIT_CARD]\n",
      "\n",
      "üìù Example 3:\n",
      "Original:  Please email john.doe@company.com or call (555) 123-4567\n",
      "Basic:     Please email [EMAIL] or call (555) 123-4567\n",
      "Advanced:  Please email [EMAIL] or call [PHONE]\n",
      "\n",
      "üìù Example 4:\n",
      "Original:  Ms. Johnson can be reached at 123-456-7890 from IP 192.168.1.1\n",
      "Basic:     [NAME] can be reached at [PHONE] from IP 192.168.1.1\n",
      "Advanced:  [NAME] can be reached at [PHONE] from IP [IP_ADDRESS]\n",
      "\n",
      "üìù Example 5:\n",
      "Original:  Prof. Williams said to call +1-555-123-4567 for urgent matters\n",
      "Basic:     Prof. Williams said to call +1-[PHONE] for urgent matters\n",
      "Advanced:  [NAME] said to call [PHONE] for urgent matters\n",
      "\n",
      "‚ö†Ô∏è Note: For production use, consider these advanced options:\n",
      "  ‚Ä¢ presidio-analyzer: Transformer-based PII detection\n",
      "  ‚Ä¢ scrubadub: Rule-based with plugin support\n",
      "  ‚Ä¢ LLM-based detection: Use GPT-4 or Claude for context-aware PII detection\n",
      "\n",
      "üí° Install presidio for advanced PII detection:\n",
      "   pip install presidio-analyzer presidio-anonymizer\n"
     ]
    }
   ],
   "source": [
    "# Advanced PII Redaction with Multiple Approaches\n",
    "import re\n",
    "from typing import List, Tuple\n",
    "\n",
    "def basic_redact_pii(text: str) -> str:\n",
    "    \"\"\"Basic regex-based PII redaction.\"\"\"\n",
    "    # Basic patterns - low recall!\n",
    "    text = re.sub(r'[\\w\\.-]+@[\\w\\.-]+', '[EMAIL]', text)\n",
    "    text = re.sub(r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b', '[PHONE]', text)\n",
    "    text = re.sub(r'Mr\\.\\s+\\w+|Ms\\.\\s+\\w+|Dr\\.\\s+\\w+', '[NAME]', text)\n",
    "    return text\n",
    "\n",
    "def advanced_redact_pii(text: str) -> str:\n",
    "    \"\"\"Enhanced PII redaction with comprehensive patterns.\"\"\"\n",
    "    # SSN pattern (must come before phone)\n",
    "    text = re.sub(r'\\b\\d{3}-\\d{2}-\\d{4}\\b', '[SSN]', text)\n",
    "    \n",
    "    # Credit card pattern (basic - production should use Luhn check)\n",
    "    text = re.sub(r'\\b\\d{4}[\\s-]?\\d{4}[\\s-]?\\d{4}[\\s-]?\\d{4}\\b', '[CREDIT_CARD]', text)\n",
    "    \n",
    "    # Enhanced email pattern\n",
    "    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '[EMAIL]', text)\n",
    "    \n",
    "    # Enhanced phone patterns (multiple formats)\n",
    "    phone_patterns = [\n",
    "        r'(?:\\+?1[-.\\s]?)?\\(?([0-9]{3})\\)?[-.\\s]?([0-9]{3})[-.\\s]?([0-9]{4})',\n",
    "        r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b',\n",
    "        r'\\(\\d{3}\\)\\s*\\d{3}-\\d{4}'\n",
    "    ]\n",
    "    for pattern in phone_patterns:\n",
    "        text = re.sub(pattern, '[PHONE]', text)\n",
    "    \n",
    "    # Enhanced name patterns with more titles\n",
    "    titles = ['Mr', 'Ms', 'Mrs', 'Dr', 'Prof', 'Rev', 'Sr', 'Jr']\n",
    "    title_pattern = r'\\b(?:' + '|'.join(titles) + r')\\.?\\s+[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*\\b'\n",
    "    text = re.sub(title_pattern, '[NAME]', text)\n",
    "    \n",
    "    # IP addresses\n",
    "    text = re.sub(r'\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b', '[IP_ADDRESS]', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Test samples with various PII\n",
    "samples = [\n",
    "    \"Contact Dr. Smith at dr.smith@example.com or 555-123-4567.\",\n",
    "    \"SSN: 123-45-6789, Credit Card: 4532-1234-5678-9012\",\n",
    "    \"Please email john.doe@company.com or call (555) 123-4567\",\n",
    "    \"Ms. Johnson can be reached at 123-456-7890 from IP 192.168.1.1\",\n",
    "    \"Prof. Williams said to call +1-555-123-4567 for urgent matters\"\n",
    "]\n",
    "\n",
    "print(\"üîí PII Redaction Comparison:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, sample in enumerate(samples):\n",
    "    print(f\"\\nüìù Example {i+1}:\")\n",
    "    print(f\"Original:  {sample}\")\n",
    "    print(f\"Basic:     {basic_redact_pii(sample)}\")\n",
    "    print(f\"Advanced:  {advanced_redact_pii(sample)}\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è Note: For production use, consider these advanced options:\")\n",
    "print(\"  ‚Ä¢ presidio-analyzer: Transformer-based PII detection\")\n",
    "print(\"  ‚Ä¢ scrubadub: Rule-based with plugin support\")\n",
    "print(\"  ‚Ä¢ LLM-based detection: Use GPT-4 or Claude for context-aware PII detection\")\n",
    "\n",
    "# Try presidio if available\n",
    "try:\n",
    "    from presidio_analyzer import AnalyzerEngine\n",
    "    from presidio_anonymizer import AnonymizerEngine\n",
    "    \n",
    "    analyzer = AnalyzerEngine()\n",
    "    anonymizer = AnonymizerEngine()\n",
    "    \n",
    "    test_text = samples[0]\n",
    "    results = analyzer.analyze(text=test_text, language='en')\n",
    "    anonymized = anonymizer.anonymize(text=test_text, analyzer_results=results)\n",
    "    \n",
    "    print(\"\\nüöÄ Presidio (Transformer-based) Result:\")\n",
    "    print(f\"Original:    {test_text}\")\n",
    "    print(f\"Anonymized:  {anonymized.text}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"\\nüí° Install presidio for advanced PII detection:\")\n",
    "    print(\"   pip install presidio-analyzer presidio-anonymizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ypay8j46s2o",
   "metadata": {},
   "source": [
    "### 1.5 Bias Detection & Mitigation\n",
    "\n",
    "Beyond accuracy, ensuring fairness and ethical AI requires proactive bias detection. Models trained on biased data perpetuate and amplify societal inequalities.\n",
    "\n",
    "> **‚öñÔ∏è Key Principle**: Bias in data leads to bias in models. Always audit your datasets for representation gaps and demographic disparities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "voznqzsey7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Fairlearn not installed. Using mock example.\n",
      "   Install with: pip install fairlearn scikit-learn\n",
      "‚öñÔ∏è Bias Detection Analysis\n",
      "======================================================================\n",
      "\n",
      "üìä Sample Dataset:\n",
      "                                   text  predicted occupation_type  \\\n",
      "0  Software engineer position available          1            tech   \n",
      "1                 Nursing position open          1      healthcare   \n",
      "2       CEO role for experienced leader          1       executive   \n",
      "3           Secretary needed for office          0           admin   \n",
      "4                   Data scientist role          1            tech   \n",
      "5            Teacher position at school          0       education   \n",
      "\n",
      "  gender_bias_risk  \n",
      "0              low  \n",
      "1             high  \n",
      "2             high  \n",
      "3             high  \n",
      "4              low  \n",
      "5           medium  \n",
      "\n",
      "üìà Manual Bias Analysis:\n",
      "  tech: 100.00% accuracy\n",
      "  healthcare: 100.00% accuracy\n",
      "  executive: 100.00% accuracy\n",
      "  admin: 0.00% accuracy\n",
      "  education: 0.00% accuracy\n",
      "\n",
      "üéØ Bias Mitigation Strategies:\n",
      "  ‚úÖ Audit data sources for representation gaps\n",
      "  ‚úÖ Rebalance datasets to ensure fair representation\n",
      "  ‚úÖ Use targeted augmentation for underrepresented groups\n",
      "  ‚úÖ Monitor fairness metrics throughout training\n",
      "  ‚úÖ Involve diverse stakeholders in data curation\n",
      "\n",
      "üîÑ Bias Mitigation through Augmentation:\n",
      "Original: The chairman announced his decision\n",
      "Variations: ['the chairperson announced his decision', 'the chair announced his decision', 'tshe chairman announced his decision', 'tthey chairman announced his decision', 'The chairman announced his decision', 'the chairman announced their decision', 'the chairman announced her decision']\n"
     ]
    }
   ],
   "source": [
    "# Bias Detection and Mitigation Example\n",
    "try:\n",
    "    from fairlearn.metrics import MetricFrame\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    fairlearn_available = True\n",
    "except ImportError:\n",
    "    fairlearn_available = False\n",
    "    print(\"‚ö†Ô∏è Fairlearn not installed. Using mock example.\")\n",
    "    print(\"   Install with: pip install fairlearn scikit-learn\")\n",
    "\n",
    "# Create a sample dataset with potential bias\n",
    "sample_predictions = pd.DataFrame({\n",
    "    'text': [\n",
    "        'Software engineer position available',\n",
    "        'Nursing position open',\n",
    "        'CEO role for experienced leader',\n",
    "        'Secretary needed for office',\n",
    "        'Data scientist role',\n",
    "        'Teacher position at school'\n",
    "    ],\n",
    "    'true_label': [1, 1, 1, 1, 1, 1],  # All are job postings\n",
    "    'predicted': [1, 1, 1, 0, 1, 0],   # Model predictions\n",
    "    'occupation_type': ['tech', 'healthcare', 'executive', 'admin', 'tech', 'education'],\n",
    "    'gender_bias_risk': ['low', 'high', 'high', 'high', 'low', 'medium']\n",
    "})\n",
    "\n",
    "print(\"‚öñÔ∏è Bias Detection Analysis\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nüìä Sample Dataset:\")\n",
    "print(sample_predictions[['text', 'predicted', 'occupation_type', 'gender_bias_risk']])\n",
    "\n",
    "if fairlearn_available:\n",
    "    # Analyze bias across occupation types\n",
    "    metric_frame = MetricFrame(\n",
    "        metrics=accuracy_score,\n",
    "        y_true=sample_predictions['true_label'],\n",
    "        y_pred=sample_predictions['predicted'],\n",
    "        sensitive_features=sample_predictions['occupation_type']\n",
    "    )\n",
    "    \n",
    "    print(\"\\nüìà Performance by Occupation Type:\")\n",
    "    print(metric_frame.by_group)\n",
    "    \n",
    "    # Calculate disparity\n",
    "    disparity = metric_frame.difference(method='between_groups')\n",
    "    print(f\"\\n‚ö†Ô∏è Maximum accuracy disparity: {disparity:.2f}\")\n",
    "else:\n",
    "    # Manual bias analysis\n",
    "    print(\"\\nüìà Manual Bias Analysis:\")\n",
    "    for occ_type in sample_predictions['occupation_type'].unique():\n",
    "        mask = sample_predictions['occupation_type'] == occ_type\n",
    "        acc = (sample_predictions[mask]['true_label'] == \n",
    "                sample_predictions[mask]['predicted']).mean()\n",
    "        print(f\"  {occ_type}: {acc:.2%} accuracy\")\n",
    "\n",
    "print(\"\\nüéØ Bias Mitigation Strategies:\")\n",
    "print(\"  ‚úÖ Audit data sources for representation gaps\")\n",
    "print(\"  ‚úÖ Rebalance datasets to ensure fair representation\")\n",
    "print(\"  ‚úÖ Use targeted augmentation for underrepresented groups\")\n",
    "print(\"  ‚úÖ Monitor fairness metrics throughout training\")\n",
    "print(\"  ‚úÖ Involve diverse stakeholders in data curation\")\n",
    "\n",
    "# Demonstrate text augmentation for bias mitigation\n",
    "def mitigate_gender_bias(text: str) -> List[str]:\n",
    "    \"\"\"Generate gender-neutral variations of text.\"\"\"\n",
    "    variations = [text]\n",
    "    \n",
    "    # Simple pronoun swapping (production should use more sophisticated methods)\n",
    "    gendered_terms = {\n",
    "        'he': ['they', 'she'],\n",
    "        'his': ['their', 'her'],\n",
    "        'him': ['them', 'her'],\n",
    "        'chairman': ['chairperson', 'chair'],\n",
    "        'businessman': ['businessperson', 'business professional'],\n",
    "        'salesman': ['salesperson', 'sales professional']\n",
    "    }\n",
    "    \n",
    "    for term, replacements in gendered_terms.items():\n",
    "        if term in text.lower():\n",
    "            for replacement in replacements:\n",
    "                variations.append(text.lower().replace(term, replacement))\n",
    "    \n",
    "    return list(set(variations))\n",
    "\n",
    "# Example of bias mitigation through augmentation\n",
    "test_text = \"The chairman announced his decision\"\n",
    "variations = mitigate_gender_bias(test_text)\n",
    "print(f\"\\nüîÑ Bias Mitigation through Augmentation:\")\n",
    "print(f\"Original: {test_text}\")\n",
    "print(f\"Variations: {variations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qidvap02ed",
   "metadata": {},
   "source": [
    "### 1.6 Synthetic Data Generation\n",
    "\n",
    "In data-scarce domains or when dealing with privacy constraints, synthetic data generation provides a powerful augmentation strategy. Modern LLMs can generate high-quality training examples that maintain semantic coherence while expanding dataset diversity.\n",
    "\n",
    "> **ü§ñ Pro Tip**: Mix synthetic and real data in a 20-30% ratio for optimal results. Always validate synthetic examples against real data distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "jqpk3e3w5h",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richardhightower/src/art_hug_11/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Synthetic Data Generation Examples:\n",
      "======================================================================\n",
      "\n",
      "üìù Synthetic Example 1 (billing):\n",
      "Text: <%= customer.query('billing') %> <%= query('billing') %>\n",
      "\n",
      "The final query will return the billing information provided by the client.\n",
      "\n",
      "Using the Salesforce API\n",
      "\n",
      "You can use the Salesforce API to access your products, manage your business, or create custom Sales\n",
      "\n",
      "üìù Synthetic Example 2 (technical issues):\n",
      "Text: #1 Create an account using a valid username and password: create-account -username'myuser@example.com' create-account -password'mypassword' #2 Configure the application: create-app -app 'example.com' create-app -app \"example.com\" create-app -app \"\n",
      "\n",
      "üìù Synthetic Example 3 (technical issues):\n",
      "Text: 1) Set the HTTP Status code of your website for this query.\n",
      "\n",
      "2) Set the HTTP Status code of your website for the following query:\n",
      "\n",
      "http://example.com/status-code/\n",
      "\n",
      "3) Set the HTTP Status code of your website for the following query:\n",
      "\n",
      "http://example.com\n",
      "\n",
      "üìù Synthetic Example 4 (feature requests):\n",
      "Text: $query = new QueryBuilder('select id from Customers.Customer_ID', 'add', 'from Customer.Customer_ID', 'to Customer.Customer_ID'); $query->execute(); // query will generate a query for the customer name\n",
      "\n",
      "Create a full-fledged user support query\n",
      "\n",
      "$query->execute();\n",
      "\n",
      "üìä Dataset Composition:\n",
      "  Real examples: 3\n",
      "  Synthetic examples: 4\n",
      "  Synthetic ratio: 57.1%\n",
      "\n",
      "‚úÖ Best Practices for Synthetic Data:\n",
      "  ‚Ä¢ Validate against real data distributions\n",
      "  ‚Ä¢ Monitor model performance on held-out real data\n",
      "  ‚Ä¢ Document generation process for reproducibility\n",
      "  ‚Ä¢ Ensure synthetic data doesn't leak sensitive patterns\n",
      "\n",
      "üéØ Try This: Modify the prompt template to generate domain-specific examples!\n",
      "Example prompts:\n",
      "  - 'Write a medical diagnosis for a patient with {symptom}:'\n",
      "  - 'Create a legal contract clause about {topic}:'\n"
     ]
    }
   ],
   "source": [
    "# Synthetic Data Generation for Enhanced Training\n",
    "from transformers import pipeline\n",
    "import random\n",
    "\n",
    "# Initialize text generation pipeline (using smaller model for demo)\n",
    "try:\n",
    "    generator = pipeline(\"text-generation\", model=\"gpt2\", device=-1)\n",
    "    generator_available = True\n",
    "except Exception as e:\n",
    "    generator_available = False\n",
    "    print(f\"‚ö†Ô∏è Could not load generator: {e}\")\n",
    "\n",
    "def generate_synthetic_examples(\n",
    "    prompt_template: str, \n",
    "    num_examples: int = 5, \n",
    "    categories: Optional[List[str]] = None,\n",
    "    max_length: int = 100\n",
    ") -> List[Dict[str, str]]:\n",
    "    \"\"\"Generate synthetic training examples using LLM-based augmentation.\"\"\"\n",
    "    synthetic_data = []\n",
    "    \n",
    "    if not generator_available:\n",
    "        # Fallback: Create template-based examples\n",
    "        templates = [\n",
    "            \"The patient experienced {symptom} and required {treatment}.\",\n",
    "            \"Customer reported {issue} with {product}.\",\n",
    "            \"Analysis shows {finding} in {domain}.\"\n",
    "        ]\n",
    "        \n",
    "        symptoms = [\"fever\", \"headache\", \"fatigue\", \"chest pain\"]\n",
    "        treatments = [\"medication\", \"rest\", \"monitoring\", \"intervention\"]\n",
    "        \n",
    "        for i in range(num_examples):\n",
    "            template = random.choice(templates)\n",
    "            if \"{symptom}\" in template:\n",
    "                text = template.format(\n",
    "                    symptom=random.choice(symptoms),\n",
    "                    treatment=random.choice(treatments)\n",
    "                )\n",
    "            else:\n",
    "                text = template.format(\n",
    "                    issue=\"performance degradation\",\n",
    "                    product=\"software system\",\n",
    "                    finding=\"anomalous patterns\",\n",
    "                    domain=\"data analysis\"\n",
    "                )\n",
    "            \n",
    "            synthetic_data.append({\n",
    "                'text': text,\n",
    "                'category': categories[i % len(categories)] if categories else 'general',\n",
    "                'synthetic': True\n",
    "            })\n",
    "    else:\n",
    "        # Use LLM for generation\n",
    "        for i in range(num_examples):\n",
    "            if categories:\n",
    "                category = random.choice(categories)\n",
    "                prompt = prompt_template.format(category=category)\n",
    "            else:\n",
    "                prompt = prompt_template\n",
    "            \n",
    "            # Generate with controlled randomness\n",
    "            result = generator(\n",
    "                prompt,\n",
    "                max_length=max_length,\n",
    "                temperature=0.8,\n",
    "                do_sample=True,\n",
    "                top_p=0.9,\n",
    "                pad_token_id=generator.tokenizer.eos_token_id\n",
    "            )\n",
    "            \n",
    "            generated_text = result[0]['generated_text']\n",
    "            # Extract only the new content (remove prompt)\n",
    "            new_content = generated_text[len(prompt):].strip()\n",
    "            \n",
    "            synthetic_data.append({\n",
    "                'text': new_content if new_content else generated_text,\n",
    "                'category': category if categories else 'general',\n",
    "                'synthetic': True\n",
    "            })\n",
    "    \n",
    "    return synthetic_data\n",
    "\n",
    "# Example: Generate customer support queries\n",
    "prompt_template = \"Generate a realistic customer support query about {category}:\"\n",
    "categories = [\"billing\", \"technical issues\", \"account access\", \"feature requests\"]\n",
    "\n",
    "print(\"ü§ñ Synthetic Data Generation Examples:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "synthetic_examples = generate_synthetic_examples(\n",
    "    prompt_template, \n",
    "    num_examples=4, \n",
    "    categories=categories,\n",
    "    max_length=80\n",
    ")\n",
    "\n",
    "for i, example in enumerate(synthetic_examples):\n",
    "    print(f\"\\nüìù Synthetic Example {i+1} ({example['category']}):\")\n",
    "    print(f\"Text: {example['text']}\")\n",
    "\n",
    "# Demonstrate mixing synthetic with real data\n",
    "real_data = [\n",
    "    {'text': 'I cannot log into my account', 'category': 'account access', 'synthetic': False},\n",
    "    {'text': 'My bill is incorrect this month', 'category': 'billing', 'synthetic': False},\n",
    "    {'text': 'The app crashes on startup', 'category': 'technical issues', 'synthetic': False}\n",
    "]\n",
    "\n",
    "# Mix datasets\n",
    "mixed_dataset = real_data + synthetic_examples\n",
    "synthetic_ratio = sum(1 for ex in mixed_dataset if ex['synthetic']) / len(mixed_dataset)\n",
    "\n",
    "print(f\"\\nüìä Dataset Composition:\")\n",
    "print(f\"  Real examples: {len(real_data)}\")\n",
    "print(f\"  Synthetic examples: {len(synthetic_examples)}\")\n",
    "print(f\"  Synthetic ratio: {synthetic_ratio:.1%}\")\n",
    "\n",
    "print(\"\\n‚úÖ Best Practices for Synthetic Data:\")\n",
    "print(\"  ‚Ä¢ Validate against real data distributions\")\n",
    "print(\"  ‚Ä¢ Monitor model performance on held-out real data\")\n",
    "print(\"  ‚Ä¢ Document generation process for reproducibility\")\n",
    "print(\"  ‚Ä¢ Ensure synthetic data doesn't leak sensitive patterns\")\n",
    "\n",
    "# Try This: Experiment with different prompts\n",
    "print(\"\\nüéØ Try This: Modify the prompt template to generate domain-specific examples!\")\n",
    "print(\"Example prompts:\")\n",
    "print(\"  - 'Write a medical diagnosis for a patient with {symptom}:'\")\n",
    "print(\"  - 'Create a legal contract clause about {topic}:'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-header",
   "metadata": {},
   "source": [
    "## Part 2: Scaling Data Processing & Streaming\n",
    "\n",
    "As your projects grow, so do your datasets‚Äîsometimes reaching terabytes or more. Loading all this data at once resembles trying to cook every dish in a restaurant simultaneously: the kitchen will grind to a halt. Instead, you need smart, scalable workflows.\n",
    "\n",
    "### 2.1 Handling Large-Scale Data\n",
    "\n",
    "When working with massive datasets, streaming allows you to process data without loading everything into memory. Data streaming lets you process one record at a time, or in manageable batches, keeping only a small portion in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "streaming-batch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc86e41ad924cbfa9b9013aeed674c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Processing Example:\n",
      "Processing examples (truncated to 200 chars):\n",
      "\n",
      "Example 1:\n",
      "Original length: 790 chars\n",
      "Processed (first 100 chars): The development of artificial intelligence has revolutionized many industries. The development of ar...\n",
      "Processed length: 200 chars\n",
      "\n",
      "Example 2:\n",
      "Original length: 780 chars\n",
      "Processed (first 100 chars): Machine learning algorithms can learn from data without explicit programming. Machine learning algor...\n",
      "Processed length: 200 chars\n",
      "\n",
      "Example 3:\n",
      "Original length: 800 chars\n",
      "Processed (first 100 chars): Deep neural networks have achieved state-of-the-art results in computer vision. Deep neural networks...\n",
      "Processed length: 200 chars\n",
      "\n",
      "Example 4:\n",
      "Original length: 840 chars\n",
      "Processed (first 100 chars): Natural language processing enables machines to understand and generate human text. Natural language...\n",
      "Processed length: 200 chars\n",
      "\n",
      "Example 5:\n",
      "Original length: 850 chars\n",
      "Processed (first 100 chars): Reinforcement learning allows agents to learn through interaction with environments. Reinforcement l...\n",
      "Processed length: 200 chars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Streaming and Batch Processing Example\n",
    "def process_batch(batch):\n",
    "    \"\"\"Process a batch of examples - here we truncate text.\"\"\"\n",
    "    return {\"processed_text\": [t[:200] if len(t) > 200 else t for t in batch[\"text\"]]}\n",
    "\n",
    "# Create a larger sample dataset to demonstrate batching\n",
    "large_sample_data = {\n",
    "    \"text\": [\n",
    "        \"The development of artificial intelligence has revolutionized many industries. \" * 10,\n",
    "        \"Machine learning algorithms can learn from data without explicit programming. \" * 10,\n",
    "        \"Deep neural networks have achieved state-of-the-art results in computer vision. \" * 10,\n",
    "        \"Natural language processing enables machines to understand and generate human text. \" * 10,\n",
    "        \"Reinforcement learning allows agents to learn through interaction with environments. \" * 10,\n",
    "    ]\n",
    "}\n",
    "\n",
    "large_dataset = Dataset.from_dict(large_sample_data)\n",
    "\n",
    "# Process data in batches\n",
    "processed = large_dataset.map(process_batch, batched=True, batch_size=2)\n",
    "\n",
    "print(\"Batch Processing Example:\")\n",
    "print(\"Processing examples (truncated to 200 chars):\\n\")\n",
    "\n",
    "for i, example in enumerate(processed):\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"Original length: {len(large_dataset[i]['text'])} chars\")\n",
    "    print(f\"Processed (first 100 chars): {example['processed_text'][:100]}...\")\n",
    "    print(f\"Processed length: {len(example['processed_text'])} chars\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6pdwtadp5bp",
   "metadata": {},
   "source": [
    "### 2.2 Data Versioning & Reproducibility\n",
    "\n",
    "In professional AI projects, you must know exactly what data went into your model and how it was processed. Consider this as keeping a precise recipe‚Äîso you (or your team) can always recreate results or explain decisions.\n",
    "\n",
    "> **üîñ Key Principle**: Track every change to your data just like you track code changes. Data versioning is essential for reproducible ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "hrfl34zrpah",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Data Versioning Example\n",
      "======================================================================\n",
      "\n",
      "üîç Data Lineage:\n",
      "\n",
      "üìå v_20250728_145956_1006e09bdda96243\n",
      "   Timestamp: 2025-07-28T14:59:56.111581\n",
      "   Hash: 1006e09bdda96243\n",
      "   Shape: 3\n",
      "   Steps: Loaded from source\n",
      "\n",
      "üìå v_20250728_145956_4b08911a4d1e5415\n",
      "   Timestamp: 2025-07-28T14:59:56.111641\n",
      "   Hash: 4b08911a4d1e5415\n",
      "   Shape: 3\n",
      "   Steps: Loaded from source ‚Üí Applied text cleaning\n",
      "\n",
      "üìå v_20250728_145956_4b08911a4d1e5415\n",
      "   Timestamp: 2025-07-28T14:59:56.111695\n",
      "   Hash: 4b08911a4d1e5415\n",
      "   Shape: 3\n",
      "   Steps: Loaded from source ‚Üí Applied text cleaning ‚Üí Filtered by length\n",
      "\n",
      "üõ†Ô∏è Production Data Versioning Tools:\n",
      "  ‚Ä¢ DVC (Data Version Control): Git-like versioning for data\n",
      "  ‚Ä¢ LakeFS: Data lake with Git-like operations\n",
      "  ‚Ä¢ Delta Lake: ACID transactions for big data\n",
      "  ‚Ä¢ Weights & Biases: Experiment tracking with data versioning\n",
      "\n",
      "üîÑ Reproducibility Check:\n",
      "To reproduce model trained with v_20250728_145956_4b08911a4d1e5415:\n",
      "  1. Checkout data version: v_20250728_145956_4b08911a4d1e5415\n",
      "  2. Apply processing: ['Loaded from source', 'Applied text cleaning', 'Filtered by length']\n",
      "  3. Use metadata: {'filter_criteria': 'length > 10'}\n"
     ]
    }
   ],
   "source": [
    "# Data Versioning and Reproducibility Example\n",
    "import hashlib\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "class DataVersionTracker:\n",
    "    \"\"\"Simple data versioning system for reproducibility.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.versions = []\n",
    "        \n",
    "    def create_version(\n",
    "        self, \n",
    "        data: Any, \n",
    "        processing_steps: List[str],\n",
    "        metadata: Optional[Dict] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Create a versioned snapshot of data and processing.\"\"\"\n",
    "        # Calculate data hash\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            data_str = data.to_json()\n",
    "        elif isinstance(data, list):\n",
    "            data_str = json.dumps(data, sort_keys=True)\n",
    "        else:\n",
    "            data_str = str(data)\n",
    "            \n",
    "        data_hash = hashlib.sha256(data_str.encode()).hexdigest()[:16]\n",
    "        \n",
    "        # Create version entry\n",
    "        version = {\n",
    "            'version_id': f\"v_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{data_hash}\",\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'data_hash': data_hash,\n",
    "            'processing_steps': processing_steps,\n",
    "            'metadata': metadata or {},\n",
    "            'data_shape': getattr(data, 'shape', len(data) if isinstance(data, list) else None)\n",
    "        }\n",
    "        \n",
    "        self.versions.append(version)\n",
    "        return version['version_id']\n",
    "    \n",
    "    def get_lineage(self) -> pd.DataFrame:\n",
    "        \"\"\"Get the complete data lineage.\"\"\"\n",
    "        return pd.DataFrame(self.versions)\n",
    "\n",
    "# Example usage\n",
    "tracker = DataVersionTracker()\n",
    "\n",
    "# Track initial raw data\n",
    "raw_data = [\"Sample text 1\", \"Sample text 2\", \"Sample text 3\"]\n",
    "v1 = tracker.create_version(\n",
    "    data=raw_data,\n",
    "    processing_steps=[\"Loaded from source\"],\n",
    "    metadata={'source': 'customer_logs.csv', 'rows': len(raw_data)}\n",
    ")\n",
    "\n",
    "# Track after cleaning\n",
    "cleaned_data = [text.lower().strip() for text in raw_data]\n",
    "v2 = tracker.create_version(\n",
    "    data=cleaned_data,\n",
    "    processing_steps=[\"Loaded from source\", \"Applied text cleaning\"],\n",
    "    metadata={'cleaning_method': 'lowercase_and_strip'}\n",
    ")\n",
    "\n",
    "# Track after filtering\n",
    "filtered_data = [text for text in cleaned_data if len(text) > 10]\n",
    "v3 = tracker.create_version(\n",
    "    data=filtered_data,\n",
    "    processing_steps=[\"Loaded from source\", \"Applied text cleaning\", \"Filtered by length\"],\n",
    "    metadata={'filter_criteria': 'length > 10'}\n",
    ")\n",
    "\n",
    "print(\"üìä Data Versioning Example\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Show lineage\n",
    "lineage = tracker.get_lineage()\n",
    "print(\"\\nüîç Data Lineage:\")\n",
    "for _, version in lineage.iterrows():\n",
    "    print(f\"\\nüìå {version['version_id']}\")\n",
    "    print(f\"   Timestamp: {version['timestamp']}\")\n",
    "    print(f\"   Hash: {version['data_hash']}\")\n",
    "    print(f\"   Shape: {version['data_shape']}\")\n",
    "    print(f\"   Steps: {' ‚Üí '.join(version['processing_steps'])}\")\n",
    "\n",
    "print(\"\\nüõ†Ô∏è Production Data Versioning Tools:\")\n",
    "print(\"  ‚Ä¢ DVC (Data Version Control): Git-like versioning for data\")\n",
    "print(\"  ‚Ä¢ LakeFS: Data lake with Git-like operations\")\n",
    "print(\"  ‚Ä¢ Delta Lake: ACID transactions for big data\")\n",
    "print(\"  ‚Ä¢ Weights & Biases: Experiment tracking with data versioning\")\n",
    "\n",
    "# Demonstrate reproducibility\n",
    "print(\"\\nüîÑ Reproducibility Check:\")\n",
    "print(f\"To reproduce model trained with {v3}:\")\n",
    "print(f\"  1. Checkout data version: {v3}\")\n",
    "print(f\"  2. Apply processing: {tracker.versions[-1]['processing_steps']}\")\n",
    "print(f\"  3. Use metadata: {tracker.versions[-1]['metadata']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2-header",
   "metadata": {},
   "source": "<cell_type>markdown</cell_type>## Part 3: Tokenization & Vocabulary Creation\n\nClean, labeled data is almost ready‚Äîbut models can't use raw text. They need tokens: units like words, subwords, or characters. Tokenization bridges the gap.\n\n### 3.1 Training Custom Tokenizers\n\nFor specialized domains, training a custom tokenizer can dramatically improve model performance by ensuring important terms aren't fragmented.\n\n> **üî§ Key Concept**: Domain-specific tokenizers learn to keep medical terms like \"electrocardiogram\" as single tokens instead of breaking them into meaningless subwords. This leads to better understanding and more efficient processing.\n\nIn this section, we'll train a medical BPE (Byte-Pair Encoding) tokenizer that:\n- Preserves medical terminology intact\n- Reduces token count by up to 50% for medical text\n- Improves model context window utilization\n- Handles both common and rare medical terms effectively"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom-tokenizer",
   "metadata": {},
   "outputs": [],
   "source": "# Training a Custom Medical Tokenizer with BPE\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom typing import List\nfrom tokenizers import Tokenizer, models, pre_tokenizers, trainers, processors\n\ndef load_medical_corpus(max_samples: int = 10000) -> List[str]:\n    \"\"\"\n    Load medical text data from available sources\n    \"\"\"\n    corpus = []\n    \n    try:\n        # Try to load PubMed dataset from Hugging Face\n        from datasets import load_dataset\n        print(\"Loading PubMed abstracts from Hugging Face...\")\n        \n        # Load pubmed_qa dataset which contains medical Q&A pairs\n        dataset = load_dataset(\"pubmed_qa\", \"pqa_labeled\", split=\"train\", streaming=True)\n        \n        count = 0\n        for example in dataset:\n            # Extract context (which contains medical abstracts)\n            if 'context' in example and 'contexts' in example['context']:\n                for context in example['context']['contexts']:\n                    corpus.append(context)\n                    count += 1\n                    if count >= max_samples:\n                        break\n            if count >= max_samples:\n                break\n                \n        print(f\"Loaded {len(corpus)} medical abstracts from PubMed QA\")\n        \n    except Exception as e:\n        print(f\"Could not load PubMed dataset: {e}\")\n        print(\"Falling back to comprehensive synthetic medical corpus...\")\n        \n        # Fallback: Create a comprehensive synthetic medical corpus\n        # This is still much better than the tiny original corpus\n        medical_texts = [\n            # Cardiology\n            \"The patient presented with acute myocardial infarction characterized by ST-segment elevation on electrocardiogram. Immediate percutaneous coronary intervention was performed.\",\n            \"Diagnosis of acute coronary syndrome requires evaluation of troponin levels, electrocardiogram changes, and clinical presentation. Thrombolytic therapy may be indicated.\",\n            \"Coronary angioplasty with stent placement is the preferred treatment for ST-elevation myocardial infarction when performed within the appropriate time window.\",\n            \"Atherosclerotic cardiovascular disease remains the leading cause of mortality worldwide. Risk factors include hypertension, hyperlipidemia, and diabetes mellitus.\",\n            \"Cardiac catheterization revealed significant stenosis in the left anterior descending artery requiring percutaneous coronary intervention.\",\n            \n            # Neurology  \n            \"The patient exhibited symptoms consistent with acute ischemic stroke including hemiparesis, aphasia, and facial droop. Immediate neuroimaging was performed.\",\n            \"Magnetic resonance imaging revealed an infarct in the middle cerebral artery territory. Thrombolytic therapy was administered within the therapeutic window.\",\n            \"Differential diagnosis for altered mental status includes metabolic encephalopathy, infectious processes, and structural brain lesions.\",\n            \"Electroencephalogram monitoring showed epileptiform discharges consistent with temporal lobe epilepsy. Antiepileptic therapy was initiated.\",\n            \n            # Oncology\n            \"Histopathological examination revealed invasive ductal carcinoma with positive estrogen and progesterone receptors. Adjuvant chemotherapy was recommended.\",\n            \"Immunohistochemistry staining showed overexpression of HER2/neu protein. Targeted therapy with trastuzumab was initiated.\",\n            \"Positron emission tomography scan demonstrated hypermetabolic lesions consistent with metastatic disease. Palliative radiotherapy was considered.\",\n            \n            # Infectious Disease\n            \"The patient presented with fever, productive cough, and consolidation on chest radiograph consistent with community-acquired pneumonia.\",\n            \"Blood cultures grew methicillin-resistant Staphylococcus aureus. Intravenous vancomycin therapy was initiated with therapeutic drug monitoring.\",\n            \"Polymerase chain reaction testing confirmed the presence of Mycobacterium tuberculosis. Four-drug antituberculous therapy was started.\",\n            \n            # Endocrinology\n            \"Laboratory findings revealed elevated hemoglobin A1c and fasting glucose levels consistent with diabetes mellitus type 2. Metformin therapy was initiated.\",\n            \"Thyroid function tests showed suppressed thyroid-stimulating hormone with elevated free thyroxine consistent with hyperthyroidism.\",\n            \"Adrenal insufficiency was confirmed by cosyntropin stimulation test. Hydrocortisone replacement therapy was prescribed.\",\n            \n            # Pulmonology\n            \"Pulmonary function tests revealed obstructive pattern with reduced forced expiratory volume consistent with chronic obstructive pulmonary disease.\",\n            \"High-resolution computed tomography showed ground-glass opacities and interstitial changes consistent with idiopathic pulmonary fibrosis.\",\n            \"Bronchoscopy with bronchoalveolar lavage was performed to evaluate for infectious etiology of pneumonia.\",\n            \n            # Gastroenterology\n            \"Esophagogastroduodenoscopy revealed erosive esophagitis and hiatal hernia. Proton pump inhibitor therapy was prescribed.\",\n            \"Colonoscopy showed multiple adenomatous polyps which were removed endoscopically. Surveillance colonoscopy was recommended.\",\n            \"Liver biopsy demonstrated bridging fibrosis consistent with chronic hepatitis C infection. Antiviral therapy was initiated.\",\n            \n            # Rheumatology\n            \"The patient met classification criteria for rheumatoid arthritis with symmetric polyarthritis and positive rheumatoid factor.\",\n            \"Synovial fluid analysis showed inflammatory arthritis with elevated white blood cell count and negative crystals.\",\n            \"Disease-modifying antirheumatic drug therapy with methotrexate was initiated for treatment of rheumatoid arthritis.\",\n            \n            # Nephrology\n            \"Renal biopsy showed focal segmental glomerulosclerosis. Immunosuppressive therapy with corticosteroids was initiated.\",\n            \"The patient developed acute kidney injury secondary to contrast-induced nephropathy. Supportive care with hydration was provided.\",\n            \"Chronic kidney disease stage 4 was diagnosed based on estimated glomerular filtration rate. Preparation for renal replacement therapy was discussed.\",\n            \n            # Hematology\n            \"Bone marrow biopsy revealed acute myeloid leukemia with complex cytogenetics. Induction chemotherapy was recommended.\",\n            \"Flow cytometry confirmed the diagnosis of chronic lymphocytic leukemia. Watch and wait approach was adopted.\",\n            \"The patient presented with thrombocytopenia and microangiopathic hemolytic anemia consistent with thrombotic thrombocytopenic purpura.\"\n        ]\n        \n        # Repeat each text multiple times with variations\n        for text in medical_texts:\n            # Add original\n            corpus.append(text)\n            \n            # Add variations\n            corpus.append(text.lower())\n            corpus.append(text.upper())\n            \n            # Add with common medical prefixes/suffixes\n            corpus.append(f\"Clinical presentation: {text}\")\n            corpus.append(f\"Diagnosis: {text}\")\n            corpus.append(f\"Treatment plan: {text}\")\n            corpus.append(f\"{text} Follow-up recommended.\")\n            corpus.append(f\"Patient history: {text}\")\n            \n        # Add individual medical terms repeated many times\n        important_terms = [\n            \"myocardial infarction\", \"acute coronary syndrome\", \"percutaneous coronary intervention\",\n            \"electrocardiogram\", \"thrombolytic therapy\", \"cardiac catheterization\", \"angioplasty\",\n            \"atherosclerosis\", \"hypertension\", \"hyperlipidemia\", \"diabetes mellitus\",\n            \"cerebrovascular accident\", \"ischemic stroke\", \"hemorrhagic stroke\", \"thrombectomy\",\n            \"magnetic resonance imaging\", \"computed tomography\", \"positron emission tomography\",\n            \"chemotherapy\", \"radiotherapy\", \"immunotherapy\", \"targeted therapy\",\n            \"metastasis\", \"carcinoma\", \"lymphoma\", \"leukemia\", \"oncogene\",\n            \"pneumonia\", \"tuberculosis\", \"sepsis\", \"antibiotic\", \"vancomycin\",\n            \"diabetes\", \"insulin\", \"metformin\", \"hemoglobin A1c\", \"glucose\",\n            \"hypothyroidism\", \"hyperthyroidism\", \"thyroid stimulating hormone\",\n            \"chronic obstructive pulmonary disease\", \"asthma\", \"pulmonary fibrosis\",\n            \"gastroesophageal reflux\", \"inflammatory bowel disease\", \"cirrhosis\",\n            \"rheumatoid arthritis\", \"systemic lupus erythematosus\", \"osteoarthritis\",\n            \"chronic kidney disease\", \"dialysis\", \"glomerulonephritis\", \"nephropathy\",\n            \"anemia\", \"thrombocytopenia\", \"coagulopathy\", \"hemophilia\"\n        ]\n        \n        # Add each term many times in different contexts\n        for term in important_terms:\n            for i in range(20):  # Repeat each term 20 times\n                corpus.append(term)\n                corpus.append(f\"The patient has {term}.\")\n                corpus.append(f\"Diagnosis of {term} was confirmed.\")\n                corpus.append(f\"Treatment for {term} includes multiple modalities.\")\n                corpus.append(f\"{term} is a common medical condition.\")\n        \n    return corpus\n\n# Load medical corpus\nprint(\"Loading medical corpus for tokenizer training...\")\nmedical_corpus = load_medical_corpus(max_samples=5000)\nprint(f\"\\nCorpus statistics:\")\nprint(f\"- Total documents: {len(medical_corpus)}\")\nprint(f\"- Average length: {np.mean([len(doc.split()) for doc in medical_corpus]):.1f} words\")\nprint(f\"- Total words: {sum(len(doc.split()) for doc in medical_corpus):,}\")\n\n# Show sample entries\nprint(\"\\nSample corpus entries:\")\nfor i in range(min(3, len(medical_corpus))):\n    print(f\"{i+1}. {medical_corpus[i][:150]}...\")\n\n# Train improved tokenizer with BPE on medical corpus\ndef train_medical_tokenizer(corpus: List[str], vocab_size: int = 10000) -> Tokenizer:\n    \"\"\"\n    Train a BPE tokenizer optimized for medical text\n    \"\"\"\n    # Use BPE model which is better for subword tokenization\n    tokenizer = Tokenizer(models.BPE(unk_token=\"<unk>\"))\n    \n    # Use ByteLevel pre-tokenizer (like GPT-2)\n    tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)\n    \n    # Special tokens\n    special_tokens = [\"<pad>\", \"<unk>\", \"<s>\", \"</s>\", \"<mask>\"]\n    \n    # Train with BPE\n    trainer = trainers.BpeTrainer(\n        vocab_size=vocab_size,\n        special_tokens=special_tokens,\n        min_frequency=2,  # Only create tokens appearing at least twice\n        show_progress=True\n    )\n    \n    # Train on the medical corpus\n    print(f\"\\nTraining BPE tokenizer with vocab_size={vocab_size}...\")\n    tokenizer.train_from_iterator(corpus, trainer=trainer)\n    \n    # Add post-processing\n    tokenizer.post_processor = processors.ByteLevel(trim_offsets=False)\n    \n    return tokenizer\n\n# Train the tokenizer\ncustom_tokenizer = train_medical_tokenizer(medical_corpus, vocab_size=10000)\n\n# Save the tokenizer\ntokenizer_path = DATA_DIR / \"medical_tokenizer.json\"\nDATA_DIR.mkdir(parents=True, exist_ok=True)  # Ensure directory exists\ncustom_tokenizer.save(str(tokenizer_path))\n\n# Load into Hugging Face\nfrom transformers import PreTrainedTokenizerFast\ncustom_tokenizer_hf = PreTrainedTokenizerFast(tokenizer_file=str(tokenizer_path))\ncustom_tokenizer_hf.pad_token = \"<pad>\"\n\nprint(f\"\\n‚úÖ Medical tokenizer saved to {tokenizer_path}\")\nprint(f\"Vocabulary size: {custom_tokenizer_hf.vocab_size}\")\n\n# Quick test on medical terms\ntest_terms = [\"myocardial infarction\", \"electrocardiogram\", \"percutaneous coronary intervention\"]\nprint(\"\\nQuick tokenization test:\")\nfor term in test_terms:\n    tokens = custom_tokenizer.encode(term).tokens\n    print(f\"'{term}' -> {len(tokens)} tokens: {tokens}\")\n\n# Demonstrate the importance of domain-specific tokenization\nprint(\"\\nüí° Why Domain-Specific Tokenization Matters:\")\nprint(\"- Medical terms stay intact (e.g., 'electrocardiogram' as 1 token)\")\nprint(\"- Better context understanding (fewer tokens = more room for context)\")\nprint(\"- Improved efficiency (reduced computational costs)\")\nprint(\"- More accurate representations of domain concepts\")"
  },
  {
   "cell_type": "markdown",
   "id": "tokenizer-comparison-header",
   "metadata": {},
   "source": [
    "### 2.2 Comparing Tokenizers\n",
    "\n",
    "Let's compare how a general-purpose tokenizer handles domain-specific terms versus our custom tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tokenizer-comparison",
   "metadata": {},
   "outputs": [],
   "source": "# Comprehensive tokenizer comparison with advanced visualization\nprint(\"=\" * 80)\nprint(\"MEDICAL TOKENIZER COMPARISON WITH ADVANCED VISUALIZATION\")\nprint(\"=\" * 80)\n\n# Import visualization libraries with proper error handling\ntry:\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n    from matplotlib.patches import Rectangle\n    import matplotlib.patches as mpatches\n    HAS_MATPLOTLIB = True\n    # Set style for better visuals\n    plt.style.use('seaborn-v0_8-darkgrid')\n    sns.set_palette(\"husl\")\nexcept ImportError:\n    HAS_MATPLOTLIB = False\n    print(\"‚ö†Ô∏è matplotlib/seaborn not available - install with: pip install matplotlib seaborn\")\n    print(\"   Text-based analysis will be shown instead.\")\n\n# Load tokenizers for comparison\nfrom transformers import AutoTokenizer, PreTrainedTokenizerFast\n\n# Load our custom medical tokenizer\ntokenizer_path = DATA_DIR / \"medical_tokenizer.json\"\ntry:\n    if tokenizer_path.exists():\n        medical_tokenizer_hf = PreTrainedTokenizerFast(tokenizer_file=str(tokenizer_path))\n        medical_tokenizer_hf.pad_token = \"<pad>\"\n        has_medical = True\n        print(\"‚úÖ Successfully loaded custom medical tokenizer\")\n    else:\n        has_medical = False\n        print(\"‚ö†Ô∏è Medical tokenizer not found - run the previous cell first!\")\nexcept Exception as e:\n    has_medical = False\n    print(f\"‚ùå Error loading medical tokenizer: {e}\")\n\n# Load comparison tokenizers\ngpt2_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\nbert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n\n# Try to load BioBERT (medical BERT)\ntry:\n    biobert_tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")\n    has_biobert = True\n    print(\"‚úÖ Successfully loaded BioBERT tokenizer\")\nexcept:\n    has_biobert = False\n    print(\"‚ö†Ô∏è BioBERT not available, using standard comparisons only\")\n\n# Comprehensive medical test set\nmedical_test_sentences = [\n    # Common medical terms\n    \"myocardial infarction\",\n    \"acute coronary syndrome\", \n    \"percutaneous coronary intervention\",\n    \"electrocardiogram abnormalities\",\n    \"thrombolytic therapy\",\n    \n    # Complex medical phrases\n    \"ST-segment elevation myocardial infarction\",\n    \"non-ST-segment elevation acute coronary syndrome\",\n    \"drug-eluting stent placement during percutaneous coronary intervention\",\n    \n    # Full medical sentences\n    \"The patient presented with acute myocardial infarction and underwent emergent cardiac catheterization.\",\n    \"Electrocardiogram showed ST-segment elevation consistent with acute coronary syndrome.\",\n    \"Percutaneous coronary intervention with drug-eluting stent placement was performed successfully.\"\n]\n\n# Analyze tokenization\nresults = []\nprint(\"\\nDetailed Tokenization Analysis:\")\nprint(\"-\" * 80)\n\nfor sentence in medical_test_sentences:\n    result = {\"text\": sentence}\n    \n    # Tokenize with each tokenizer\n    bert_tokens = bert_tokenizer.tokenize(sentence)\n    result[\"bert\"] = len(bert_tokens)\n    result[\"bert_tokens\"] = bert_tokens\n    \n    gpt2_tokens = gpt2_tokenizer.tokenize(sentence)\n    result[\"gpt2\"] = len(gpt2_tokens)\n    result[\"gpt2_tokens\"] = gpt2_tokens\n    \n    if has_biobert:\n        biobert_tokens = biobert_tokenizer.tokenize(sentence)\n        result[\"biobert\"] = len(biobert_tokens)\n        result[\"biobert_tokens\"] = biobert_tokens\n    \n    if has_medical:\n        medical_tokens = medical_tokenizer_hf.tokenize(sentence)\n        result[\"medical\"] = len(medical_tokens)\n        result[\"medical_tokens\"] = medical_tokens\n    \n    results.append(result)\n    \n    # Print detailed results\n    print(f\"\\nText: '{sentence}'\")\n    print(f\"  BERT:        {len(bert_tokens):3d} tokens - {bert_tokens[:10]}{'...' if len(bert_tokens) > 10 else ''}\")\n    if has_biobert:\n        print(f\"  BioBERT:     {len(biobert_tokens):3d} tokens - {biobert_tokens[:10]}{'...' if len(biobert_tokens) > 10 else ''}\")\n    print(f\"  GPT-2:       {len(gpt2_tokens):3d} tokens - {gpt2_tokens[:10]}{'...' if len(gpt2_tokens) > 10 else ''}\")\n    if has_medical:\n        print(f\"  Medical BPE: {len(medical_tokens):3d} tokens - {medical_tokens[:10]}{'...' if len(medical_tokens) > 10 else ''}\")\n\n# Convert to DataFrame for analysis\ndf = pd.DataFrame(results)\n\n# Calculate summary statistics\nprint(\"\\n\" + \"=\" * 80)\nprint(\"EFFICIENCY SUMMARY\")\nprint(\"=\" * 80)\n\ntokenizers = [\"bert\", \"gpt2\"]\nif has_biobert:\n    tokenizers.append(\"biobert\")\nif has_medical:\n    tokenizers.append(\"medical\")\n\nprint(f\"\\nTotal tokens across {len(medical_test_sentences)} test examples:\")\nfor tokenizer in tokenizers:\n    if tokenizer in df.columns:\n        total = df[tokenizer].sum()\n        print(f\"  {tokenizer.upper():<12} {total:4d} tokens\")\n\n# Create advanced visualizations if matplotlib is available\nif HAS_MATPLOTLIB:\n    # Create a comprehensive figure with multiple subplots\n    fig = plt.figure(figsize=(16, 12))\n    \n    # --- Subplot 1: Total Token Count Comparison ---\n    ax1 = plt.subplot(3, 3, 1)\n    totals = []\n    labels = []\n    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n    \n    for i, tokenizer in enumerate(tokenizers):\n        if tokenizer in df.columns:\n            totals.append(df[tokenizer].sum())\n            labels.append(tokenizer.upper())\n    \n    bars = ax1.bar(labels, totals, color=colors[:len(labels)])\n    ax1.set_title('Total Tokens Across All Examples', fontsize=14, fontweight='bold')\n    ax1.set_ylabel('Total Token Count')\n    ax1.set_xlabel('Tokenizer')\n    \n    # Add value labels on bars\n    for bar, total in zip(bars, totals):\n        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5, \n                 str(total), ha='center', va='bottom', fontweight='bold')\n    \n    # --- Subplot 2: Token Count by Example Type ---\n    ax2 = plt.subplot(3, 3, 2)\n    # Group examples by type\n    simple_terms = df.iloc[:5][tokenizers].mean()\n    complex_phrases = df.iloc[5:8][tokenizers].mean()\n    full_sentences = df.iloc[8:][tokenizers].mean()\n    \n    x = np.arange(3)\n    width = 0.2\n    \n    for i, tokenizer in enumerate(tokenizers):\n        if tokenizer in df.columns:\n            values = [simple_terms[tokenizer], complex_phrases[tokenizer], full_sentences[tokenizer]]\n            ax2.bar(x + i*width, values, width, label=tokenizer.upper(), color=colors[i])\n    \n    ax2.set_xlabel('Example Type')\n    ax2.set_ylabel('Average Token Count')\n    ax2.set_title('Average Tokens by Example Complexity', fontsize=14, fontweight='bold')\n    ax2.set_xticks(x + width * (len(tokenizers)-1) / 2)\n    ax2.set_xticklabels(['Simple Terms', 'Complex Phrases', 'Full Sentences'])\n    ax2.legend()\n    \n    # --- Subplot 3: Efficiency Gains Heatmap ---\n    ax3 = plt.subplot(3, 3, 3)\n    if has_medical and 'medical' in df.columns:\n        # Calculate percentage reduction for medical tokenizer\n        efficiency_matrix = []\n        for tokenizer in ['bert', 'gpt2', 'biobert']:\n            if tokenizer in df.columns:\n                reduction = ((df[tokenizer] - df['medical']) / df[tokenizer] * 100).values\n                efficiency_matrix.append(reduction)\n        \n        efficiency_array = np.array(efficiency_matrix)\n        im = ax3.imshow(efficiency_array, cmap='RdYlGn', aspect='auto', vmin=-50, vmax=50)\n        \n        # Set ticks\n        ax3.set_yticks(range(len([t for t in ['bert', 'gpt2', 'biobert'] if t in df.columns])))\n        ax3.set_yticklabels([t.upper() for t in ['bert', 'gpt2', 'biobert'] if t in df.columns])\n        ax3.set_xticks(range(len(df)))\n        ax3.set_xticklabels([f\"Ex{i+1}\" for i in range(len(df))], rotation=45)\n        \n        # Add colorbar\n        cbar = plt.colorbar(im, ax=ax3)\n        cbar.set_label('Reduction %', rotation=270, labelpad=15)\n        \n        ax3.set_title('Medical Tokenizer Efficiency Gains (%)', fontsize=14, fontweight='bold')\n        \n        # Add text annotations\n        for i in range(efficiency_array.shape[0]):\n            for j in range(efficiency_array.shape[1]):\n                text = ax3.text(j, i, f'{efficiency_array[i, j]:.0f}',\n                               ha=\"center\", va=\"center\", color=\"black\", fontsize=8)\n    \n    # --- Subplot 4: Token Length Distribution ---\n    ax4 = plt.subplot(3, 3, 4)\n    for tokenizer in tokenizers:\n        if tokenizer in df.columns and f\"{tokenizer}_tokens\" in df.columns:\n            all_tokens = []\n            for tokens in df[f\"{tokenizer}_tokens\"]:\n                all_tokens.extend([len(t.replace('ƒ†', '').replace('##', '')) for t in tokens])\n            \n            # Create histogram\n            ax4.hist(all_tokens, bins=range(1, max(all_tokens)+2), alpha=0.5, \n                    label=tokenizer.upper(), density=True)\n    \n    ax4.set_xlabel('Token Length (characters)')\n    ax4.set_ylabel('Density')\n    ax4.set_title('Token Length Distribution', fontsize=14, fontweight='bold')\n    ax4.legend()\n    \n    # --- Subplot 5: Memory Impact Visualization ---\n    ax5 = plt.subplot(3, 3, 5)\n    if has_medical:\n        # Calculate memory usage for 1M documents\n        docs = 1_000_000\n        avg_doc_length = 500  # tokens\n        bytes_per_token = 2  # assuming int16 token IDs\n        \n        memory_usage = []\n        for tokenizer in tokenizers:\n            if tokenizer in df.columns:\n                avg_tokens = df[tokenizer].mean()\n                scale_factor = avg_tokens / df['bert'].mean() if 'bert' in df.columns else 1\n                memory_mb = (docs * avg_doc_length * scale_factor * bytes_per_token) / (1024 * 1024)\n                memory_usage.append(memory_mb)\n        \n        bars = ax5.bar(labels, memory_usage, color=colors[:len(labels)])\n        ax5.set_ylabel('Memory (MB)')\n        ax5.set_title('Memory Usage for 1M Documents', fontsize=14, fontweight='bold')\n        \n        # Add value labels\n        for bar, mem in zip(bars, memory_usage):\n            ax5.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 10,\n                    f'{mem:.0f}MB', ha='center', va='bottom')\n    \n    # --- Subplot 6: Tokenization Speed Simulation ---\n    ax6 = plt.subplot(3, 3, 6)\n    # Simulate tokenization speed based on token count (inverse relationship)\n    base_speed = 1000  # docs/second for BERT\n    speeds = []\n    \n    for tokenizer in tokenizers:\n        if tokenizer in df.columns:\n            # Fewer tokens = faster processing\n            relative_tokens = df[tokenizer].sum() / df['bert'].sum() if 'bert' in df.columns else 1\n            speed = base_speed / relative_tokens\n            speeds.append(speed)\n    \n    bars = ax6.bar(labels, speeds, color=colors[:len(labels)])\n    ax6.set_ylabel('Documents/Second')\n    ax6.set_title('Estimated Processing Speed', fontsize=14, fontweight='bold')\n    \n    for bar, speed in zip(bars, speeds):\n        ax6.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 10,\n                f'{speed:.0f}', ha='center', va='bottom')\n    \n    # --- Subplot 7: Line Plot of Token Counts ---\n    ax7 = plt.subplot(3, 3, 7)\n    for i, tokenizer in enumerate(tokenizers):\n        if tokenizer in df.columns:\n            ax7.plot(range(len(df)), df[tokenizer], marker='o', \n                    label=tokenizer.upper(), linewidth=2, markersize=8)\n    \n    ax7.set_xlabel('Example Index')\n    ax7.set_ylabel('Token Count')\n    ax7.set_title('Token Count Progression', fontsize=14, fontweight='bold')\n    ax7.legend()\n    ax7.grid(True, alpha=0.3)\n    \n    # --- Subplot 8: Cost Comparison (for API-based models) ---\n    ax8 = plt.subplot(3, 3, 8)\n    # Assume $0.002 per 1K tokens (typical GPT pricing)\n    cost_per_1k = 0.002\n    costs = []\n    \n    for tokenizer in tokenizers:\n        if tokenizer in df.columns:\n            total_tokens = df[tokenizer].sum()\n            # Scale up to 1M documents\n            scaled_tokens = total_tokens * (1_000_000 / len(df))\n            cost = (scaled_tokens / 1000) * cost_per_1k\n            costs.append(cost)\n    \n    bars = ax8.bar(labels, costs, color=colors[:len(labels)])\n    ax8.set_ylabel('Cost (USD)')\n    ax8.set_title('Estimated API Cost for 1M Documents', fontsize=14, fontweight='bold')\n    \n    for bar, cost in zip(bars, costs):\n        ax8.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50,\n                f'${cost:,.0f}', ha='center', va='bottom')\n    \n    # --- Subplot 9: Key Metrics Summary ---\n    ax9 = plt.subplot(3, 3, 9)\n    ax9.axis('off')\n    \n    # Create summary text\n    summary_text = \"üéØ KEY INSIGHTS\\n\\n\"\n    \n    if has_medical and 'medical' in df.columns:\n        bert_total = df['bert'].sum() if 'bert' in df.columns else 0\n        medical_total = df['medical'].sum()\n        reduction = (1 - medical_total/bert_total) * 100 if bert_total > 0 else 0\n        \n        summary_text += f\"‚úÖ Token Reduction: {reduction:.1f}%\\n\"\n        summary_text += f\"‚úÖ Memory Savings: ~{reduction:.0f}%\\n\"\n        summary_text += f\"‚úÖ Speed Increase: ~{100/(100-reduction):.1f}x\\n\"\n        summary_text += f\"‚úÖ Cost Reduction: {reduction:.0f}%\\n\\n\"\n        \n        # Find best performing examples\n        best_examples = []\n        for i, row in df.iterrows():\n            if 'bert' in row and 'medical' in row:\n                example_reduction = (1 - row['medical']/row['bert']) * 100\n                if example_reduction > 40:\n                    best_examples.append((i+1, example_reduction))\n        \n        if best_examples:\n            summary_text += \"üí° Best Performance:\\n\"\n            for idx, red in sorted(best_examples, key=lambda x: x[1], reverse=True)[:3]:\n                summary_text += f\"  Example {idx}: {red:.0f}% reduction\\n\"\n    \n    ax9.text(0.1, 0.9, summary_text, transform=ax9.transAxes, \n            fontsize=12, verticalalignment='top',\n            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n    \n    plt.tight_layout()\n    plt.savefig('tokenizer_comparison_comprehensive.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n# Print final insights\nprint(\"\\n\" + \"=\" * 80)\nprint(\"KEY INSIGHTS FROM COMPREHENSIVE ANALYSIS\")\nprint(\"=\" * 80)\nprint(\"1. Domain-specific tokenizers significantly reduce token counts\")\nprint(\"2. Fewer tokens lead to:\")\nprint(\"   ‚Ä¢ Faster processing and training\")\nprint(\"   ‚Ä¢ Lower memory usage and costs\")\nprint(\"   ‚Ä¢ Better context window utilization\")\nprint(\"   ‚Ä¢ More semantic coherence\")\nprint(\"3. Medical terminology benefits most from specialized tokenization\")\nprint(\"4. Even small efficiency gains compound at scale\")\n\nif has_medical:\n    # Show specific efficiency examples\n    print(f\"\\nüìä Concrete Example: 'percutaneous coronary intervention'\")\n    for idx, row in df.iterrows():\n        if \"percutaneous coronary intervention\" in row['text']:\n            print(f\"\\nTokenization comparison:\")\n            for tokenizer in tokenizers:\n                if tokenizer in df.columns:\n                    count = row[tokenizer]\n                    print(f\"  {tokenizer.upper():10} {count:3d} tokens\")\n            break\n\nprint(\"\\nüí° For production: Train tokenizers on 100K+ domain documents!\")"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ox91j5cq6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TOKENIZATION VISUALIZATION: How Different Tokenizers Split Medical Terms\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EFFICIENCY COMPARISON: Token Counts for Medical Terms\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Efficiency Summary:\n",
      "--------------------------------------------------\n",
      "\n",
      "'myocardial infarction':\n",
      "  BERT: 6 tokens (baseline)\n",
      "  GPT2: 6 tokens (+0.0% vs BERT)\n",
      "  BIOBERT: 7 tokens (+0.0% vs BERT)\n",
      "\n",
      "'electrocardiogram':\n",
      "  BERT: 4 tokens (baseline)\n",
      "  GPT2: 5 tokens (+0.0% vs BERT)\n",
      "  BIOBERT: 4 tokens (+0.0% vs BERT)\n",
      "\n",
      "'thrombolytic therapy':\n",
      "  BERT: 5 tokens (baseline)\n",
      "  GPT2: 6 tokens (+0.0% vs BERT)\n",
      "  BIOBERT: 5 tokens (+0.0% vs BERT)\n",
      "\n",
      "'cardiac catheterization':\n",
      "  BERT: 5 tokens (baseline)\n",
      "  GPT2: 5 tokens (+0.0% vs BERT)\n",
      "  BIOBERT: 5 tokens (+0.0% vs BERT)\n",
      "\n",
      "'percutaneous coronary intervention':\n",
      "  BERT: 6 tokens (baseline)\n",
      "  GPT2: 5 tokens (+16.7% vs BERT)\n",
      "  BIOBERT: 7 tokens (+0.0% vs BERT)\n",
      "\n",
      "üéØ Key Takeaway: Domain-specific tokenizers can significantly reduce token counts\n",
      "   for specialized terminology, leading to more efficient model training and inference!\n"
     ]
    }
   ],
   "source": [
    "# Visual comparison of tokenization for a specific medical term\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TOKENIZATION VISUALIZATION: How Different Tokenizers Split Medical Terms\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Select a complex medical term for detailed analysis\n",
    "example_term = \"percutaneous coronary intervention\"\n",
    "\n",
    "# Create figure with subplots for each tokenizer\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "fig.suptitle(f'Tokenization of: \"{example_term}\"', fontsize=16, fontweight='bold')\n",
    "\n",
    "tokenizer_configs = [\n",
    "    (\"BERT\", bert_tokenizer, axes[0, 0]),\n",
    "    (\"GPT-2\", gpt2_tokenizer, axes[0, 1]),\n",
    "]\n",
    "\n",
    "if has_biobert:\n",
    "    tokenizer_configs.append((\"BioBERT\", biobert_tokenizer, axes[1, 0]))\n",
    "if has_medical:\n",
    "    tokenizer_configs.append((\"Medical BPE\", medical_tokenizer_hf, axes[1, 1]))\n",
    "\n",
    "# Process each tokenizer\n",
    "for name, tokenizer, ax in tokenizer_configs:\n",
    "    tokens = tokenizer.tokenize(example_term)\n",
    "    token_count = len(tokens)\n",
    "    \n",
    "    # Create color map for tokens\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, token_count))\n",
    "    \n",
    "    # Create horizontal bar chart\n",
    "    y_positions = np.arange(len(tokens))\n",
    "    token_lengths = [len(token.replace('ƒ†', '').replace('##', '')) for token in tokens]\n",
    "    \n",
    "    bars = ax.barh(y_positions, token_lengths, color=colors)\n",
    "    \n",
    "    # Add token text\n",
    "    for i, (bar, token) in enumerate(zip(bars, tokens)):\n",
    "        ax.text(bar.get_width() / 2, bar.get_y() + bar.get_height() / 2,\n",
    "                token, ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    ax.set_yticks(y_positions)\n",
    "    ax.set_yticklabels([f\"Token {i+1}\" for i in range(len(tokens))])\n",
    "    ax.set_xlabel('Character Length')\n",
    "    ax.set_title(f'{name} ({token_count} tokens)', fontsize=12)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "# Remove empty subplots\n",
    "for ax in axes.flat:\n",
    "    if not ax.has_data():\n",
    "        ax.set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create a summary comparison chart\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EFFICIENCY COMPARISON: Token Counts for Medical Terms\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Test multiple medical terms\n",
    "medical_terms = [\n",
    "    \"myocardial infarction\",\n",
    "    \"electrocardiogram\",\n",
    "    \"thrombolytic therapy\",\n",
    "    \"cardiac catheterization\",\n",
    "    \"percutaneous coronary intervention\"\n",
    "]\n",
    "\n",
    "# Calculate token counts\n",
    "comparison_data = []\n",
    "for term in medical_terms:\n",
    "    row = {\"term\": term}\n",
    "    row[\"bert\"] = len(bert_tokenizer.tokenize(term))\n",
    "    row[\"gpt2\"] = len(gpt2_tokenizer.tokenize(term))\n",
    "    if has_biobert:\n",
    "        row[\"biobert\"] = len(biobert_tokenizer.tokenize(term))\n",
    "    if has_medical:\n",
    "        row[\"medical\"] = len(medical_tokenizer_hf.tokenize(term))\n",
    "    comparison_data.append(row)\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "# Create grouped bar chart\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(medical_terms))\n",
    "width = 0.2\n",
    "multiplier = 0\n",
    "\n",
    "tokenizer_names = [\"bert\", \"gpt2\"]\n",
    "if has_biobert:\n",
    "    tokenizer_names.append(\"biobert\")\n",
    "if has_medical:\n",
    "    tokenizer_names.append(\"medical\")\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "\n",
    "for i, tokenizer in enumerate(tokenizer_names):\n",
    "    offset = width * multiplier\n",
    "    rects = ax.bar(x + offset, comparison_df[tokenizer], width, \n",
    "                    label=tokenizer.upper(), color=colors[i])\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{int(height)}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom',\n",
    "                    fontsize=8)\n",
    "    \n",
    "    multiplier += 1\n",
    "\n",
    "ax.set_xlabel('Medical Terms', fontsize=12)\n",
    "ax.set_ylabel('Token Count', fontsize=12)\n",
    "ax.set_title('Tokenization Efficiency Comparison Across Medical Terms', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x + width * (len(tokenizer_names) - 1) / 2)\n",
    "ax.set_xticklabels([term.replace(' ', '\\n') for term in medical_terms], fontsize=10)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print efficiency summary\n",
    "print(\"\\nEfficiency Summary:\")\n",
    "print(\"-\" * 50)\n",
    "for term in medical_terms:\n",
    "    print(f\"\\n'{term}':\")\n",
    "    row = comparison_df[comparison_df['term'] == term].iloc[0]\n",
    "    baseline = row['bert']\n",
    "    for tokenizer in tokenizer_names:\n",
    "        count = row[tokenizer]\n",
    "        efficiency = ((baseline - count) / baseline * 100) if count < baseline else 0\n",
    "        print(f\"  {tokenizer.upper()}: {count} tokens\" + \n",
    "              (f\" ({efficiency:+.1f}% vs BERT)\" if tokenizer != 'bert' else \" (baseline)\"))\n",
    "\n",
    "print(\"\\nüéØ Key Takeaway: Domain-specific tokenizers can significantly reduce token counts\")\n",
    "print(\"   for specialized terminology, leading to more efficient model training and inference!\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "jrn901pt5g9",
   "source": "# Enhanced Tokenization Breakdown Visualization\nprint(\"\\n\" + \"=\" * 80)\nprint(\"ADVANCED TOKENIZATION VISUALIZATION: Token Efficiency Analysis\")\nprint(\"=\" * 80)\n\n# Select a complex medical term for detailed analysis\nexample_term = \"percutaneous coronary intervention\"\n\n# Prepare for visualization\nif HAS_MATPLOTLIB:\n    # Create a sophisticated visualization showing how each tokenizer breaks down the term\n    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n    fig.suptitle(f'Tokenization Breakdown: \"{example_term}\"', fontsize=18, fontweight='bold')\n    \n    tokenizer_configs = [\n        (\"BERT\", bert_tokenizer, axes[0, 0]),\n        (\"GPT-2\", gpt2_tokenizer, axes[0, 1]),\n    ]\n    \n    if has_biobert:\n        tokenizer_configs.append((\"BioBERT\", biobert_tokenizer, axes[1, 0]))\n    if has_medical:\n        tokenizer_configs.append((\"Medical BPE\", medical_tokenizer_hf, axes[1, 1]))\n    \n    # Color palette for tokens\n    colors = plt.cm.Set3(np.linspace(0, 1, 20))\n    \n    # Process each tokenizer\n    for name, tokenizer, ax in tokenizer_configs:\n        tokens = tokenizer.tokenize(example_term)\n        token_count = len(tokens)\n        \n        # Create visual representation\n        y_pos = 0.5\n        x_pos = 0\n        \n        # Draw each token as a colored box\n        for i, token in enumerate(tokens):\n            # Clean token for display\n            display_token = token.replace('ƒ†', '').replace('##', '')\n            token_width = len(display_token) * 0.1\n            \n            # Draw rectangle\n            rect = plt.Rectangle((x_pos, y_pos - 0.2), token_width, 0.4,\n                               facecolor=colors[i % len(colors)],\n                               edgecolor='black', linewidth=2)\n            ax.add_patch(rect)\n            \n            # Add token text\n            ax.text(x_pos + token_width/2, y_pos, display_token,\n                   ha='center', va='center', fontsize=11, fontweight='bold')\n            \n            # Add original token below in smaller font\n            ax.text(x_pos + token_width/2, y_pos - 0.35, token,\n                   ha='center', va='center', fontsize=8, style='italic')\n            \n            x_pos += token_width + 0.05\n        \n        # Set axis properties\n        ax.set_xlim(-0.1, max(3.5, x_pos))\n        ax.set_ylim(0, 1)\n        ax.set_title(f'{name}: {token_count} tokens', fontsize=14, fontweight='bold')\n        ax.axis('off')\n        \n        # Add efficiency indicator\n        efficiency_color = 'green' if token_count <= 5 else 'orange' if token_count <= 8 else 'red'\n        ax.text(0.95, 0.95, f\"Efficiency: {'High' if token_count <= 5 else 'Medium' if token_count <= 8 else 'Low'}\",\n               transform=ax.transAxes, ha='right', va='top',\n               bbox=dict(boxstyle='round', facecolor=efficiency_color, alpha=0.3))\n    \n    # Remove empty subplots\n    for ax in axes.flat:\n        if not ax.has_data():\n            ax.set_visible(False)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Create a comprehensive comparison chart\n    print(\"\\n\" + \"=\" * 80)\n    print(\"MEMORY AND COMPUTATIONAL IMPACT ANALYSIS\")\n    print(\"=\" * 80)\n    \n    # Create impact visualization\n    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n    \n    # Calculate impacts for 1M medical records\n    records = 1_000_000\n    avg_tokens_per_record = 500\n    \n    # Memory impact chart\n    ax1.set_title('Memory Impact for 1M Medical Records', fontsize=14, fontweight='bold')\n    \n    memory_data = []\n    tokenizer_names = []\n    \n    for tokenizer_name, tokenizer_obj in [('BERT', bert_tokenizer), ('GPT-2', gpt2_tokenizer)]:\n        if tokenizer_obj:\n            tokens = len(tokenizer_obj.tokenize(example_term))\n            # Estimate based on token ratio\n            token_ratio = tokens / 3  # Ideal is 3 tokens\n            memory_gb = (records * avg_tokens_per_record * token_ratio * 2) / (1024**3)\n            memory_data.append(memory_gb)\n            tokenizer_names.append(tokenizer_name)\n    \n    if has_biobert:\n        tokens = len(biobert_tokenizer.tokenize(example_term))\n        token_ratio = tokens / 3\n        memory_gb = (records * avg_tokens_per_record * token_ratio * 2) / (1024**3)\n        memory_data.append(memory_gb)\n        tokenizer_names.append('BioBERT')\n    \n    if has_medical:\n        tokens = len(medical_tokenizer_hf.tokenize(example_term))\n        token_ratio = tokens / 3\n        memory_gb = (records * avg_tokens_per_record * token_ratio * 2) / (1024**3)\n        memory_data.append(memory_gb)\n        tokenizer_names.append('Medical BPE')\n    \n    bars1 = ax1.bar(tokenizer_names, memory_data, color=['#ff9999', '#66b3ff', '#99ff99', '#ffcc99'])\n    ax1.set_ylabel('Memory (GB)')\n    ax1.set_xlabel('Tokenizer')\n    \n    # Add value labels\n    for bar, mem in zip(bars1, memory_data):\n        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n                f'{mem:.1f} GB', ha='center', va='bottom')\n    \n    # Training time impact chart\n    ax2.set_title('Estimated Training Time Impact', fontsize=14, fontweight='bold')\n    \n    # Base time for BERT (hours)\n    base_time = 24\n    time_data = []\n    \n    for i, name in enumerate(tokenizer_names):\n        # Training time scales with token count\n        relative_time = memory_data[i] / memory_data[0] if memory_data[0] > 0 else 1\n        time_hours = base_time * relative_time\n        time_data.append(time_hours)\n    \n    bars2 = ax2.bar(tokenizer_names, time_data, color=['#ff9999', '#66b3ff', '#99ff99', '#ffcc99'])\n    ax2.set_ylabel('Training Time (hours)')\n    ax2.set_xlabel('Tokenizer')\n    \n    for bar, time in zip(bars2, time_data):\n        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n                f'{time:.1f}h', ha='center', va='bottom')\n    \n    # Cost impact chart\n    ax3.set_title('API Cost Impact (per 1M docs)', fontsize=14, fontweight='bold')\n    \n    # Cost per 1K tokens\n    cost_per_1k = 0.002\n    cost_data = []\n    \n    for mem in memory_data:\n        # Estimate token count from memory\n        total_tokens = (mem * 1024**3) / 2  # Convert back to tokens\n        cost = (total_tokens / 1000) * cost_per_1k\n        cost_data.append(cost)\n    \n    bars3 = ax3.bar(tokenizer_names, cost_data, color=['#ff9999', '#66b3ff', '#99ff99', '#ffcc99'])\n    ax3.set_ylabel('Cost (USD)')\n    ax3.set_xlabel('Tokenizer')\n    \n    for bar, cost in zip(bars3, cost_data):\n        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 100,\n                f'${cost:,.0f}', ha='center', va='bottom')\n    \n    plt.tight_layout()\n    plt.show()\n\nelse:\n    # Text-based visualization fallback\n    print(f\"\\nTokenization of '{example_term}':\")\n    print(\"-\" * 60)\n    \n    tokenizers_to_test = [(\"BERT\", bert_tokenizer), (\"GPT-2\", gpt2_tokenizer)]\n    if has_biobert:\n        tokenizers_to_test.append((\"BioBERT\", biobert_tokenizer))\n    if has_medical:\n        tokenizers_to_test.append((\"Medical BPE\", medical_tokenizer_hf))\n    \n    for name, tokenizer in tokenizers_to_test:\n        if tokenizer:\n            tokens = tokenizer.tokenize(example_term)\n            print(f\"\\n{name} ({len(tokens)} tokens):\")\n            print(f\"  Tokens: {tokens}\")\n            print(f\"  Visual: {'|'.join(tokens)}\")\n            \n            # Calculate efficiency\n            efficiency = \"High\" if len(tokens) <= 5 else \"Medium\" if len(tokens) <= 8 else \"Low\"\n            print(f\"  Efficiency: {efficiency}\")\n\n# Additional analysis: Token composition breakdown\nprint(\"\\n\" + \"=\" * 80)\nprint(\"TOKEN COMPOSITION ANALYSIS\")\nprint(\"=\" * 80)\n\n# Analyze how different tokenizers handle medical terminology\nmedical_terms_analysis = [\n    \"electrocardiogram\",\n    \"thromboembolism\", \n    \"immunosuppressive\",\n    \"gastroenteritis\",\n    \"nephrosclerosis\"\n]\n\nprint(\"\\nHow tokenizers handle complex medical terms:\")\nprint(\"-\" * 80)\n\nfor term in medical_terms_analysis:\n    print(f\"\\nTerm: '{term}'\")\n    \n    # Test each tokenizer\n    for name, tokenizer in [(\"BERT\", bert_tokenizer), (\"GPT-2\", gpt2_tokenizer)]:\n        if tokenizer:\n            tokens = tokenizer.tokenize(term)\n            # Check if term is preserved\n            preserved = len(tokens) == 1 or (len(tokens) == 2 and tokens[0].startswith('ƒ†'))\n            print(f\"  {name:8} {len(tokens):2d} tokens - {'‚úÖ Preserved' if preserved else '‚ùå Fragmented'}: {tokens[:5]}{'...' if len(tokens) > 5 else ''}\")\n    \n    if has_medical:\n        tokens = medical_tokenizer_hf.tokenize(term)\n        preserved = len(tokens) == 1 or (len(tokens) == 2 and tokens[0].startswith('ƒ†'))\n        print(f\"  Medical  {len(tokens):2d} tokens - {'‚úÖ Preserved' if preserved else '‚ùå Fragmented'}: {tokens[:5]}{'...' if len(tokens) > 5 else ''}\")\n\nprint(\"\\nüéØ Key Insights:\")\nprint(\"‚Ä¢ Domain-specific tokenizers preserve medical terms better\")\nprint(\"‚Ä¢ Preserved terms = Better semantic understanding\")\nprint(\"‚Ä¢ Fragmented terms = Loss of meaning and context\")\nprint(\"‚Ä¢ Efficiency directly impacts model performance and cost\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "part3-header",
   "metadata": {},
   "source": [
    "## Part 4: Model Configuration & Initialization\n",
    "\n",
    "With your dataset ready, it's time to configure and initialize your model. Modern workflows typically start with pre-trained models and fine-tune them, dramatically reducing computational requirements while achieving superior results.\n",
    "\n",
    "### 4.1 Architecture Selection\n",
    "\n",
    "Start by matching your model architecture to your task:\n",
    "\n",
    "| Architecture | Best For | Examples | Key Characteristics |\n",
    "|-------------|----------|----------|-------------------|\n",
    "| **Encoder-only** | Understanding tasks | BERT, RoBERTa, DeBERTa | Bidirectional context, great for classification |\n",
    "| **Decoder-only** | Generation tasks | GPT, Llama, Mistral | Autoregressive, ideal for text generation |\n",
    "| **Encoder-decoder** | Seq2seq tasks | T5, BART, mT5 | Flexible, good for translation/summarization |\n",
    "\n",
    "### 4.2 Modern Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "gpt2-config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 Model Configuration:\n",
      "  Vocab size: 30,000\n",
      "  Max position embeddings: 512\n",
      "  Hidden size: 768\n",
      "  Layers: 12\n",
      "  Attention heads: 12\n",
      "  Total parameters: 108,489,216\n",
      "\n",
      "Model Architecture Summary:\n",
      "Token embeddings shape: torch.Size([30000, 768])\n",
      "Position embeddings shape: torch.Size([512, 768])\n"
     ]
    }
   ],
   "source": [
    "# Configuring a GPT-2 Model from Scratch\n",
    "from transformers import GPT2Config, GPT2LMHeadModel\n",
    "\n",
    "# Use modern config parameter names\n",
    "config = GPT2Config(\n",
    "    vocab_size=30000,                # Match your tokenizer's vocab size\n",
    "    max_position_embeddings=512,     # Max sequence length\n",
    "    n_embd=768,                      # Embedding size\n",
    "    n_layer=12,                      # Number of transformer layers\n",
    "    n_head=12,                       # Number of attention heads\n",
    "    use_cache=True                   # Enable caching for faster generation\n",
    ")\n",
    "\n",
    "model = GPT2LMHeadModel(config)\n",
    "\n",
    "# Sanity check: vocab size should match embedding matrix\n",
    "assert config.vocab_size == model.transformer.wte.weight.shape[0], \"Vocab size mismatch!\"\n",
    "\n",
    "print(\"GPT-2 Model Configuration:\")\n",
    "print(f\"  Vocab size: {config.vocab_size:,}\")\n",
    "print(f\"  Max position embeddings: {config.max_position_embeddings}\")\n",
    "print(f\"  Hidden size: {config.n_embd}\")\n",
    "print(f\"  Layers: {config.n_layer}\")\n",
    "print(f\"  Attention heads: {config.n_head}\")\n",
    "print(f\"  Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Inspect model architecture\n",
    "print(\"\\nModel Architecture Summary:\")\n",
    "print(f\"Token embeddings shape: {model.transformer.wte.weight.shape}\")\n",
    "print(f\"Position embeddings shape: {model.transformer.wpe.weight.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretrained-header",
   "metadata": {},
   "source": [
    "### 3.2 Loading and Adapting Pre-trained Models\n",
    "\n",
    "The most common and efficient approach is to start with a pre-trained model and adapt it to your domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "pretrained-adaptation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richardhightower/src/art_hug_11/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vocab size: 50257\n",
      "Original embedding shape: torch.Size([50257, 768])\n",
      "\n",
      "Added 7 new tokens\n",
      "New vocab size: 50264\n",
      "New embedding shape: torch.Size([50264, 768])\n",
      "\n",
      "Test text: <patient> presented with <symptom> requiring <treatment>\n",
      "Tokens: ['<patient>', 'ƒ†presented', 'ƒ†with', 'ƒ†', '<symptom>', 'ƒ†requiring', 'ƒ†', '<treatment>']\n",
      "Token IDs: [50260, 5545, 351, 220, 50261, 10616, 220, 50259]\n"
     ]
    }
   ],
   "source": [
    "# Loading and Adapting a Pre-trained GPT-2 Model\n",
    "from transformers import GPT2TokenizerFast, GPT2LMHeadModel\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "print(f\"Original vocab size: {len(tokenizer)}\")\n",
    "print(f\"Original embedding shape: {model.transformer.wte.weight.shape}\")\n",
    "\n",
    "# Add domain-specific tokens\n",
    "new_tokens = [\n",
    "    \"<medical>\", \"<diagnosis>\", \"<treatment>\", \"<patient>\",\n",
    "    \"<symptom>\", \"<medication>\", \"<procedure>\"\n",
    "]\n",
    "\n",
    "num_added = tokenizer.add_tokens(new_tokens)\n",
    "\n",
    "if num_added > 0:\n",
    "    # Resize model embeddings to match new vocabulary\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    print(f\"\\nAdded {num_added} new tokens\")\n",
    "    print(f\"New vocab size: {len(tokenizer)}\")\n",
    "    print(f\"New embedding shape: {model.transformer.wte.weight.shape}\")\n",
    "\n",
    "# Test the new tokens\n",
    "test_text = \"<patient> presented with <symptom> requiring <treatment>\"\n",
    "tokens = tokenizer.tokenize(test_text)\n",
    "token_ids = tokenizer.encode(test_text)\n",
    "\n",
    "print(f\"\\nTest text: {test_text}\")\n",
    "print(f\"Tokens: {tokens}\")\n",
    "print(f\"Token IDs: {token_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peft-header",
   "metadata": {},
   "source": [
    "### 4.3 Parameter-Efficient Fine-Tuning (PEFT)\n",
    "\n",
    "For large models, Parameter-Efficient Fine-Tuning (PEFT) methods like LoRA dramatically reduce computational requirements while maintaining performance.\n",
    "\n",
    "| Method | Trainable Params | Memory Usage | Performance | Best For |\n",
    "|--------|-----------------|--------------|-------------|----------|\n",
    "| **Full Fine-tuning** | 100% | Very High | Best | Small models, unlimited resources |\n",
    "| **LoRA** | ~0.1-1% | Low | Near-best | Most use cases, limited GPU |\n",
    "| **QLoRA** | ~0.1% | Very Low | Good | Large models on consumer GPUs |\n",
    "| **Prefix Tuning** | <0.1% | Low | Good | Generation tasks |\n",
    "| **Adapters** | ~1-5% | Medium | Good | Multi-task learning |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "peft-lora",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original GPT-2 Model:\n",
      "  Total parameters: 124,439,808\n",
      "  Trainable parameters: 124,439,808\n",
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richardhightower/src/art_hug_11/.venv/lib/python3.12/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With LoRA:\n",
      "  Trainable parameters: 811,008\n",
      "  Reduction: 99.35%\n",
      "  Memory savings: ~0.46 GB (FP32)\n",
      "\n",
      "Detailed parameter info:\n",
      "trainable params: 811,008 || all params: 125,250,816 || trainable%: 0.6475071587557562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richardhightower/src/art_hug_11/.venv/lib/python3.12/site-packages/peft/tuners/lora/model.py:347: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Parameter-Efficient Fine-Tuning with LoRA\n",
    "try:\n",
    "    from peft import LoraConfig, get_peft_model, TaskType\n",
    "except ImportError:\n",
    "    print(\"Installing PEFT library...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"peft\"])\n",
    "    from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load a small model for demonstration\n",
    "model_name = \"gpt2\"\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Count original parameters\n",
    "original_params = sum(p.numel() for p in base_model.parameters())\n",
    "trainable_params = sum(p.numel() for p in base_model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Original GPT-2 Model:\")\n",
    "print(f\"  Total parameters: {original_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Configure LoRA\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=8,  # LoRA rank\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"c_attn\", \"c_proj\"]  # GPT-2 attention layers\n",
    ")\n",
    "\n",
    "# Apply LoRA\n",
    "lora_model = get_peft_model(base_model, peft_config)\n",
    "\n",
    "# Count LoRA parameters\n",
    "lora_params = sum(p.numel() for p in lora_model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"\\nWith LoRA:\")\n",
    "print(f\"  Trainable parameters: {lora_params:,}\")\n",
    "print(f\"  Reduction: {(1 - lora_params/original_params)*100:.2f}%\")\n",
    "print(f\"  Memory savings: ~{(original_params - lora_params) * 4 / 1024**3:.2f} GB (FP32)\")\n",
    "\n",
    "# Show trainable parameters\n",
    "print(\"\\nDetailed parameter info:\")\n",
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4-header",
   "metadata": {},
   "source": [
    "## Part 4: Training Workflows\n",
    "\n",
    "With data prepared and model configured, it's time to train. Modern training includes monitoring, early stopping, and experiment tracking.\n",
    "\n",
    "### 4.1 Basic Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "training-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richardhightower/src/art_hug_11/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d282b41e0994f0c9c64edbd3bcb6b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Setup Complete!\n",
      "  Model: distilgpt2\n",
      "  Dataset size: 6\n",
      "  Device: mps\n",
      "  Model parameters: 81,912,576\n",
      "\n",
      "Note: Due to library version conflicts, we'll demonstrate\n",
      "model usage without the full Trainer API.\n"
     ]
    }
   ],
   "source": [
    "# Basic Training Setup with Simple Demo\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM, AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "\n",
    "# Create a sample dataset\n",
    "texts = [\n",
    "    \"The patient presented with chest pain and shortness of breath.\",\n",
    "    \"Diagnosis confirmed myocardial infarction based on ECG results.\",\n",
    "    \"Treatment included aspirin and thrombolytic therapy.\",\n",
    "    \"Post-operative care following cardiac surgery is essential.\",\n",
    "    \"Regular monitoring of cardiac function recommended.\",\n",
    "    \"Patient history includes hypertension and diabetes.\",\n",
    "]\n",
    "\n",
    "# Load a small model for demonstration\n",
    "model_name = \"distilgpt2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Create and tokenize dataset\n",
    "dataset = Dataset.from_dict({\"text\": texts})\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Data collator for language modeling\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # Causal LM, not masked LM\n",
    ")\n",
    "\n",
    "print(\"Training Setup Complete!\")\n",
    "print(f\"  Model: {model_name}\")\n",
    "print(f\"  Dataset size: {len(dataset)}\")\n",
    "print(f\"  Device: {get_device()}\")\n",
    "print(f\"  Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Due to version compatibility issues with Trainer, we'll demonstrate\n",
    "# a simple training loop instead\n",
    "print(\"\\nNote: Due to library version conflicts, we'll demonstrate\")\n",
    "print(\"model usage without the full Trainer API.\")\n",
    "\n",
    "# Save references for next cells\n",
    "model_for_generation = model\n",
    "tokenizer_for_generation = tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-metrics-header",
   "metadata": {},
   "source": [
    "### 5.2 Metrics & Early Stopping\n",
    "\n",
    "Effective training requires monitoring the right metrics for your task:\n",
    "\n",
    "| Metric | Task Type | Description | Good Values |\n",
    "|--------|-----------|-------------|-------------|\n",
    "| **Training Loss** | All | Model fit on training data | Decreasing |\n",
    "| **Validation Loss** | All | Generalization ability | Close to train loss |\n",
    "| **Perplexity** | Language Modeling | Prediction confidence | 10-50 |\n",
    "| **Accuracy** | Classification | Correct predictions | >90% |\n",
    "| **F1 Score** | Classification | Precision/recall balance | >0.8 |\n",
    "| **BLEU** | Translation | N-gram overlap | >30 |\n",
    "| **ROUGE** | Summarization | Recall-oriented measure | Varies |\n",
    "| **BERTScore** | Generation | Semantic similarity | >0.9 |\n",
    "\n",
    "> **üí° Pro Tip**: Combine automated metrics with human evaluation for production models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training-metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Training Demonstration\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Create a simple training function\n",
    "def simple_train_step(model, batch, device):\n",
    "    \"\"\"Perform a single training step.\"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    # Move inputs to device\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "    loss = outputs.loss\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "# Demonstrate training concept\n",
    "print(\"Training Concepts Demonstration:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nIn a full training loop, you would:\")\n",
    "print(\"1. Create data loaders for batching\")\n",
    "print(\"2. Initialize an optimizer (e.g., AdamW)\")\n",
    "print(\"3. Loop through epochs and batches\")\n",
    "print(\"4. Compute loss and gradients\")\n",
    "print(\"5. Update model weights\")\n",
    "print(\"6. Track metrics like loss and perplexity\")\n",
    "\n",
    "# Calculate initial perplexity (demonstration only)\n",
    "print(\"\\nModel Statistics:\")\n",
    "with torch.no_grad():\n",
    "    # Sample a small batch\n",
    "    sample_text = \"The patient presented with symptoms\"\n",
    "    inputs = tokenizer(sample_text, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs, labels=inputs.input_ids)\n",
    "    loss = outputs.loss.item()\n",
    "    perplexity = np.exp(loss)\n",
    "    \n",
    "print(f\"Sample loss: {loss:.4f}\")\n",
    "print(f\"Sample perplexity: {perplexity:.4f}\")\n",
    "print(\"\\nNote: Lower perplexity indicates better model performance\")\n",
    "\n",
    "# Save model state for next cells\n",
    "trained_model = model\n",
    "trained_tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "id": "2jvh4uyqj3o",
   "source": "# Advanced Training Progress Visualization\nprint(\"=\" * 80)\nprint(\"TRAINING PROGRESS VISUALIZATION & MONITORING\")\nprint(\"=\" * 80)\n\n# Import visualization libraries with error handling\ntry:\n    import matplotlib.pyplot as plt\n    from IPython.display import clear_output\n    import matplotlib.gridspec as gridspec\n    HAS_MATPLOTLIB = True\nexcept ImportError:\n    print(\"‚ö†Ô∏è matplotlib not available - install with: pip install matplotlib\")\n    print(\"   Text-based metrics will be shown instead.\")\n    HAS_MATPLOTLIB = False\n\ndef simulate_advanced_training_metrics(num_steps: int = 100, model_type: str = \"base\"):\n    \"\"\"\n    Simulate comprehensive training metrics for visualization.\n    \n    Args:\n        num_steps: Number of training steps to simulate\n        model_type: Type of model ('base', 'lora', 'qlora')\n    \"\"\"\n    steps = []\n    train_losses = []\n    eval_losses = []\n    learning_rates = []\n    gradient_norms = []\n    memory_usage = []\n    \n    # Initial values based on model type\n    if model_type == \"base\":\n        train_loss = 4.5\n        eval_loss = 4.6\n        base_lr = 5e-5\n        base_memory = 8.0  # GB\n    elif model_type == \"lora\":\n        train_loss = 4.2\n        eval_loss = 4.3\n        base_lr = 3e-4  # LoRA can use higher LR\n        base_memory = 2.0  # GB\n    else:  # qlora\n        train_loss = 4.3\n        eval_loss = 4.4\n        base_lr = 2e-4\n        base_memory = 1.0  # GB\n    \n    # Simulation parameters\n    best_eval_loss = float('inf')\n    patience_counter = 0\n    early_stop_patience = 10\n    \n    for step in range(num_steps):\n        # Simulate loss decrease with noise\n        train_loss *= 0.98 + np.random.normal(0, 0.01)\n        eval_loss *= 0.985 + np.random.normal(0, 0.015)\n        \n        # Simulate learning rate schedule\n        if step < 10:\n            lr = base_lr * (step + 1) / 10  # Warmup\n        elif step < 80:\n            lr = base_lr  # Constant\n        else:\n            lr = base_lr * 0.5 * (1 + np.cos(np.pi * (step - 80) / 20))  # Cosine decay\n        \n        # Simulate gradient norm\n        grad_norm = 2.0 * np.exp(-step/30) + np.random.normal(0.5, 0.1)\n        \n        # Simulate memory usage (increases slightly during training)\n        mem = base_memory + 0.5 * np.sin(step/10) + np.random.normal(0, 0.1)\n        \n        # Store metrics\n        steps.append(step)\n        train_losses.append(train_loss)\n        eval_losses.append(eval_loss)\n        learning_rates.append(lr)\n        gradient_norms.append(grad_norm)\n        memory_usage.append(mem)\n        \n        # Early stopping check\n        if eval_loss < best_eval_loss:\n            best_eval_loss = eval_loss\n            patience_counter = 0\n        else:\n            patience_counter += 1\n        \n        # Visualize every 10 steps\n        if step % 10 == 0 and HAS_MATPLOTLIB:\n            clear_output(wait=True)\n            \n            # Create comprehensive dashboard\n            fig = plt.figure(figsize=(16, 10))\n            gs = gridspec.GridSpec(3, 3, figure=fig)\n            \n            # --- Main loss plot (spans 2 columns) ---\n            ax1 = fig.add_subplot(gs[0, :2])\n            ax1.plot(steps, train_losses, label='Train Loss', color='blue', linewidth=2)\n            ax1.plot(steps, eval_losses, label='Eval Loss', color='orange', linewidth=2)\n            ax1.axhline(y=best_eval_loss, color='green', linestyle='--', alpha=0.5, label=f'Best Eval: {best_eval_loss:.4f}')\n            ax1.set_xlabel('Steps')\n            ax1.set_ylabel('Loss')\n            ax1.set_title(f'Training Progress - {model_type.upper()} Model', fontsize=14, fontweight='bold')\n            ax1.legend()\n            ax1.grid(True, alpha=0.3)\n            \n            # Add overfitting warning\n            if eval_loss > train_loss * 1.2:\n                ax1.text(0.5, 0.95, '‚ö†Ô∏è OVERFITTING DETECTED', transform=ax1.transAxes,\n                        ha='center', va='top', color='red', fontsize=12, fontweight='bold',\n                        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n            \n            # --- Metrics display ---\n            ax2 = fig.add_subplot(gs[0, 2])\n            ax2.axis('off')\n            metrics_text = f\"\"\"Current Metrics (Step {step})\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nTrain Loss: {train_loss:.4f}\nEval Loss: {eval_loss:.4f}\nLearning Rate: {lr:.2e}\nGradient Norm: {grad_norm:.3f}\nMemory Usage: {mem:.1f} GB\n\nEarly Stopping\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nBest Eval Loss: {best_eval_loss:.4f}\nPatience: {patience_counter}/{early_stop_patience}\nStatus: {'üü¢ Training' if patience_counter < early_stop_patience else 'üî¥ Stop'}\n\nModel Efficiency\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nType: {model_type.upper()}\nParams: {'100%' if model_type == 'base' else '~1%' if model_type == 'lora' else '~0.1%'}\nMemory: {'High' if model_type == 'base' else 'Low' if model_type == 'lora' else 'Very Low'}\"\"\"\n            \n            ax2.text(0.1, 0.9, metrics_text, transform=ax2.transAxes,\n                    fontsize=10, verticalalignment='top', family='monospace',\n                    bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n            \n            # --- Learning rate schedule ---\n            ax3 = fig.add_subplot(gs[1, 0])\n            ax3.plot(steps, learning_rates, color='green', linewidth=2)\n            ax3.axvline(x=10, color='gray', linestyle='--', alpha=0.5, label='Warmup End')\n            ax3.axvline(x=80, color='gray', linestyle='--', alpha=0.5, label='Decay Start')\n            ax3.set_xlabel('Steps')\n            ax3.set_ylabel('Learning Rate')\n            ax3.set_title('Learning Rate Schedule', fontsize=12)\n            ax3.grid(True, alpha=0.3)\n            ax3.legend()\n            \n            # --- Gradient norm ---\n            ax4 = fig.add_subplot(gs[1, 1])\n            ax4.plot(steps, gradient_norms, color='purple', linewidth=2)\n            ax4.axhline(y=1.0, color='red', linestyle='--', alpha=0.5, label='Clip Threshold')\n            ax4.set_xlabel('Steps')\n            ax4.set_ylabel('Gradient Norm')\n            ax4.set_title('Gradient Norm Evolution', fontsize=12)\n            ax4.grid(True, alpha=0.3)\n            ax4.legend()\n            \n            # --- Memory usage ---\n            ax5 = fig.add_subplot(gs[1, 2])\n            ax5.plot(steps, memory_usage, color='red', linewidth=2)\n            ax5.fill_between(steps, memory_usage, alpha=0.3, color='red')\n            ax5.set_xlabel('Steps')\n            ax5.set_ylabel('Memory (GB)')\n            ax5.set_title('GPU Memory Usage', fontsize=12)\n            ax5.grid(True, alpha=0.3)\n            \n            # --- Loss difference (train vs eval) ---\n            ax6 = fig.add_subplot(gs[2, 0])\n            loss_diff = [e - t for t, e in zip(train_losses, eval_losses)]\n            ax6.plot(steps, loss_diff, color='brown', linewidth=2)\n            ax6.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n            ax6.fill_between(steps, loss_diff, alpha=0.3, \n                            where=[d > 0 for d in loss_diff], color='red', label='Overfitting')\n            ax6.fill_between(steps, loss_diff, alpha=0.3,\n                            where=[d <= 0 for d in loss_diff], color='green', label='Underfitting')\n            ax6.set_xlabel('Steps')\n            ax6.set_ylabel('Eval - Train Loss')\n            ax6.set_title('Generalization Gap', fontsize=12)\n            ax6.legend()\n            ax6.grid(True, alpha=0.3)\n            \n            # --- Perplexity ---\n            ax7 = fig.add_subplot(gs[2, 1])\n            train_perplexity = [np.exp(loss) for loss in train_losses]\n            eval_perplexity = [np.exp(loss) for loss in eval_losses]\n            ax7.plot(steps, train_perplexity, label='Train Perplexity', color='blue', linewidth=2)\n            ax7.plot(steps, eval_perplexity, label='Eval Perplexity', color='orange', linewidth=2)\n            ax7.set_xlabel('Steps')\n            ax7.set_ylabel('Perplexity')\n            ax7.set_title('Model Perplexity', fontsize=12)\n            ax7.set_yscale('log')\n            ax7.legend()\n            ax7.grid(True, alpha=0.3)\n            \n            # --- Training speed ---\n            ax8 = fig.add_subplot(gs[2, 2])\n            # Simulate tokens/second based on model type\n            base_speed = 5000 if model_type == 'base' else 15000 if model_type == 'lora' else 20000\n            speeds = [base_speed + np.random.normal(0, 500) for _ in steps]\n            ax8.plot(steps, speeds, color='cyan', linewidth=2)\n            ax8.set_xlabel('Steps')\n            ax8.set_ylabel('Tokens/Second')\n            ax8.set_title('Training Speed', fontsize=12)\n            ax8.grid(True, alpha=0.3)\n            \n            plt.suptitle(f'Comprehensive Training Dashboard - Step {step}/{num_steps}', \n                        fontsize=16, fontweight='bold')\n            plt.tight_layout()\n            plt.show()\n            \n            # Check for early stopping\n            if patience_counter >= early_stop_patience:\n                print(f\"\\nüõë Early stopping triggered at step {step}\")\n                print(f\"   Best eval loss: {best_eval_loss:.4f}\")\n                break\n    \n    # Final summary\n    if not HAS_MATPLOTLIB or step == num_steps - 1:\n        print(f\"\\nüìä Training Summary for {model_type.upper()} Model:\")\n        print(f\"   Steps completed: {len(steps)}\")\n        print(f\"   Final train loss: {train_losses[-1]:.4f}\")\n        print(f\"   Final eval loss: {eval_losses[-1]:.4f}\")\n        print(f\"   Best eval loss: {best_eval_loss:.4f}\")\n        print(f\"   Final perplexity: {np.exp(eval_losses[-1]):.2f}\")\n    \n    return steps, train_losses, eval_losses, best_eval_loss\n\n# Demonstrate different training scenarios\nprint(\"\\nSelect training scenario to visualize:\")\nprint(\"1. Base Model (Full Fine-tuning)\")\nprint(\"2. LoRA (Parameter-Efficient)\")\nprint(\"3. QLoRA (Quantized + LoRA)\")\n\n# Simulate LoRA training as default\nprint(\"\\nSimulating LoRA training (most common scenario)...\")\nsteps, train_losses, eval_losses, best_loss = simulate_advanced_training_metrics(\n    num_steps=50, \n    model_type=\"lora\"\n)\n\n# Additional training insights\nprint(\"\\n\" + \"=\" * 80)\nprint(\"TRAINING BEST PRACTICES & INSIGHTS\")\nprint(\"=\" * 80)\n\nprint(\"\\nüìà Key Metrics to Monitor:\")\nprint(\"‚Ä¢ Loss convergence - Should decrease smoothly\")\nprint(\"‚Ä¢ Generalization gap - Keep eval close to train\")\nprint(\"‚Ä¢ Gradient norms - Should stabilize < 1.0\")\nprint(\"‚Ä¢ Learning rate - Follow your schedule\")\nprint(\"‚Ä¢ Memory usage - Watch for OOM\")\n\nprint(\"\\n‚ö° Performance Tips:\")\nprint(\"‚Ä¢ Use mixed precision (fp16/bf16) for 2x speedup\")\nprint(\"‚Ä¢ Enable gradient checkpointing for large models\")\nprint(\"‚Ä¢ Use gradient accumulation for larger effective batch size\")\nprint(\"‚Ä¢ Monitor for loss spikes indicating instability\")\n\nprint(\"\\nüéØ Model-Specific Recommendations:\")\nrecommendations = {\n    \"base\": {\n        \"lr\": \"2e-5 to 5e-5\",\n        \"batch_size\": \"4-8 per GPU\",\n        \"warmup\": \"500-1000 steps\",\n        \"weight_decay\": \"0.01\"\n    },\n    \"lora\": {\n        \"lr\": \"1e-4 to 3e-4\",\n        \"batch_size\": \"16-32 per GPU\",\n        \"warmup\": \"100-200 steps\", \n        \"lora_r\": \"8-16\",\n        \"lora_alpha\": \"16-32\"\n    },\n    \"qlora\": {\n        \"lr\": \"2e-4\",\n        \"batch_size\": \"32-64 per GPU\",\n        \"warmup\": \"100 steps\",\n        \"bits\": \"4-bit NF4\",\n        \"double_quant\": \"True\"\n    }\n}\n\nfor model_type, params in recommendations.items():\n    print(f\"\\n{model_type.upper()} Model:\")\n    for param, value in params.items():\n        print(f\"  ‚Ä¢ {param}: {value}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ygztuf96sth",
   "source": "### ‚ö†Ô∏è Training Diagnostics Tool\n\nWhen training doesn't go as expected, having a systematic diagnostic tool can save hours of debugging. This tool helps identify and resolve common training issues based on symptoms you observe.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "eqrk5c03lhv",
   "source": "# Comprehensive Training Diagnostics Tool\nfrom typing import List, Dict, Tuple\nimport re\n\ndef diagnose_training_issues(symptoms: List[str]) -> List[Tuple[str, Dict]]:\n    \"\"\"\n    Advanced diagnostic tool for identifying and resolving training issues.\n    \n    Args:\n        symptoms: List of observed symptoms during training\n        \n    Returns:\n        List of tuples containing (issue_name, diagnostic_details)\n    \"\"\"\n    # Comprehensive diagnostics database\n    diagnostics = {\n        \"loss_explosion\": {\n            \"symptoms\": [\"loss goes to inf\", \"loss increases rapidly\", \"nan loss\", \"loss explodes\"],\n            \"causes\": [\n                \"Learning rate too high\",\n                \"Gradient explosion\",\n                \"Numerical instability\",\n                \"Bad batch normalization\"\n            ],\n            \"solutions\": [\n                \"Reduce learning rate (try 1e-5 or lower)\",\n                \"Enable gradient clipping (max_grad_norm=1.0)\",\n                \"Use mixed precision training with loss scaling\",\n                \"Check for division by zero in custom loss\",\n                \"Verify input data doesn't contain NaN/Inf values\",\n                \"Use smaller warmup steps\"\n            ],\n            \"code_fixes\": [\n                \"training_args.learning_rate = 1e-5\",\n                \"training_args.max_grad_norm = 1.0\",\n                \"training_args.fp16 = True\",\n                \"training_args.warmup_steps = 100\"\n            ]\n        },\n        \"no_learning\": {\n            \"symptoms\": [\"loss stays constant\", \"no improvement\", \"stuck loss\", \"loss plateau\"],\n            \"causes\": [\n                \"Learning rate too low\",\n                \"Dead neurons/vanishing gradients\",\n                \"Data loading issues\",\n                \"Incorrect loss function\"\n            ],\n            \"solutions\": [\n                \"Increase learning rate (try 2e-4)\",\n                \"Check if model outputs are changing\",\n                \"Verify data loading and preprocessing\",\n                \"Try different initialization\",\n                \"Check if labels are correct\",\n                \"Ensure optimizer is stepping\"\n            ],\n            \"code_fixes\": [\n                \"training_args.learning_rate = 2e-4\",\n                \"model.apply(model._init_weights)\",\n                \"print(next(model.parameters()).grad) # Check gradients\",\n                \"optimizer.zero_grad() # Ensure gradients reset\"\n            ]\n        },\n        \"overfitting\": {\n            \"symptoms\": [\"train loss decreases but val loss increases\", \"gap between train and val\", \"validation metrics worsen\"],\n            \"causes\": [\n                \"Model too large for dataset\",\n                \"Too little data\",\n                \"No regularization\",\n                \"Training too long\"\n            ],\n            \"solutions\": [\n                \"Add dropout (0.1-0.3)\",\n                \"Reduce model size\",\n                \"Augment training data\",\n                \"Add weight decay (0.01-0.1)\",\n                \"Early stopping\",\n                \"Use smaller learning rate\",\n                \"Add more regularization\"\n            ],\n            \"code_fixes\": [\n                \"model.dropout = nn.Dropout(0.2)\",\n                \"training_args.weight_decay = 0.01\",\n                \"training_args.load_best_model_at_end = True\",\n                \"training_args.evaluation_strategy = 'steps'\",\n                \"training_args.eval_steps = 50\"\n            ]\n        },\n        \"oom\": {\n            \"symptoms\": [\"cuda out of memory\", \"oom error\", \"memory error\", \"gpu memory\"],\n            \"causes\": [\n                \"Batch size too large\",\n                \"Model too large\",\n                \"Memory leak\",\n                \"Gradient accumulation\"\n            ],\n            \"solutions\": [\n                \"Reduce batch size (try 1 or 2)\",\n                \"Enable gradient accumulation\",\n                \"Use gradient checkpointing\",\n                \"Clear cache: torch.cuda.empty_cache()\",\n                \"Use mixed precision (fp16)\",\n                \"Use parameter-efficient methods (LoRA)\",\n                \"Enable CPU offloading\"\n            ],\n            \"code_fixes\": [\n                \"training_args.per_device_train_batch_size = 1\",\n                \"training_args.gradient_accumulation_steps = 8\",\n                \"model.gradient_checkpointing_enable()\",\n                \"training_args.fp16 = True\",\n                \"torch.cuda.empty_cache()\"\n            ]\n        },\n        \"slow_training\": {\n            \"symptoms\": [\"training too slow\", \"low gpu utilization\", \"slow iteration\"],\n            \"causes\": [\n                \"Data loading bottleneck\",\n                \"Small batch size\",\n                \"CPU bottleneck\",\n                \"Inefficient operations\"\n            ],\n            \"solutions\": [\n                \"Increase num_workers in DataLoader\",\n                \"Use larger batch size if memory allows\",\n                \"Enable pin_memory for DataLoader\",\n                \"Profile code to find bottlenecks\",\n                \"Use mixed precision training\",\n                \"Optimize data preprocessing\"\n            ],\n            \"code_fixes\": [\n                \"dataloader = DataLoader(..., num_workers=4, pin_memory=True)\",\n                \"training_args.dataloader_num_workers = 4\",\n                \"training_args.fp16 = True\",\n                \"training_args.dataloader_pin_memory = True\"\n            ]\n        },\n        \"unstable_training\": {\n            \"symptoms\": [\"loss spikes\", \"erratic loss\", \"training unstable\", \"loss oscillates\"],\n            \"causes\": [\n                \"Learning rate too high\",\n                \"Bad batches\",\n                \"Gradient accumulation issues\",\n                \"Numerical precision\"\n            ],\n            \"solutions\": [\n                \"Use learning rate scheduler\",\n                \"Implement gradient clipping\",\n                \"Use larger batch size or accumulation\",\n                \"Switch to AdamW optimizer\",\n                \"Add warmup period\",\n                \"Check for outliers in data\"\n            ],\n            \"code_fixes\": [\n                \"training_args.warmup_ratio = 0.1\",\n                \"training_args.lr_scheduler_type = 'cosine'\",\n                \"training_args.max_grad_norm = 1.0\",\n                \"training_args.optim = 'adamw_torch'\"\n            ]\n        }\n    }\n    \n    # Find matching issues\n    matched_issues = []\n    \n    for symptom in symptoms:\n        symptom_lower = symptom.lower()\n        for issue, details in diagnostics.items():\n            if any(s in symptom_lower for s in details[\"symptoms\"]):\n                matched_issues.append((issue, details))\n                break  # Only match each symptom once\n    \n    return matched_issues\n\ndef display_diagnostic_results(symptoms: List[str], show_code: bool = True):\n    \"\"\"\n    Display diagnostic results in a formatted manner.\n    \n    Args:\n        symptoms: List of observed symptoms\n        show_code: Whether to show code fixes\n    \"\"\"\n    print(\"üîç Training Issue Diagnosis\")\n    print(\"=\" * 70)\n    \n    issues = diagnose_training_issues(symptoms)\n    \n    if not issues:\n        print(\"\\n‚ùå No matching issues found for the given symptoms.\")\n        print(\"\\nüí° Try describing symptoms using terms like:\")\n        print(\"   - 'loss goes to inf' or 'nan loss'\")\n        print(\"   - 'loss stays constant' or 'no improvement'\")\n        print(\"   - 'cuda out of memory' or 'oom error'\")\n        print(\"   - 'train loss decreases but val loss increases'\")\n        return\n    \n    for i, (issue_name, details) in enumerate(issues, 1):\n        print(f\"\\nüéØ Issue {i}: {issue_name.upper().replace('_', ' ')}\")\n        print(\"-\" * 50)\n        \n        print(\"\\nüìã Possible Causes:\")\n        for cause in details[\"causes\"]:\n            print(f\"   ‚Ä¢ {cause}\")\n        \n        print(\"\\nüí° Recommended Solutions:\")\n        for j, solution in enumerate(details[\"solutions\"], 1):\n            print(f\"   {j}. {solution}\")\n        \n        if show_code and \"code_fixes\" in details:\n            print(\"\\nüìù Code Fixes:\")\n            for fix in details[\"code_fixes\"]:\n                print(f\"   ```python\")\n                print(f\"   {fix}\")\n                print(f\"   ```\")\n\n# Interactive diagnostic examples\nprint(\"ü©∫ Training Diagnostics Tool Demo\")\nprint(\"=\" * 70)\n\n# Example 1: Memory issues\nprint(\"\\nüìç Example 1: Memory Issues\")\nsymptoms1 = [\"My model shows CUDA out of memory error during training\"]\ndisplay_diagnostic_results(symptoms1)\n\n# Example 2: Overfitting\nprint(\"\\n\\nüìç Example 2: Overfitting Issues\")\nsymptoms2 = [\"Training loss decreases but validation loss increases after epoch 2\"]\ndisplay_diagnostic_results(symptoms2)\n\n# Example 3: No learning\nprint(\"\\n\\nüìç Example 3: Model Not Learning\")\nsymptoms3 = [\"Loss stays constant at 4.5 for 100 steps\"]\ndisplay_diagnostic_results(symptoms3)\n\n# Create an interactive diagnostic function\ndef interactive_diagnosis():\n    \"\"\"Interactive training issue diagnosis.\"\"\"\n    print(\"\\n\\nü§ñ Interactive Training Diagnostics\")\n    print(\"=\" * 70)\n    print(\"Describe your training issues (separate multiple symptoms with ';'):\")\n    print(\"Example: 'loss goes to inf; cuda out of memory'\")\n    print(\"\\nCommon symptoms to describe:\")\n    print(\"  ‚Ä¢ Loss behavior: explosion, plateau, oscillation\")\n    print(\"  ‚Ä¢ Memory issues: OOM, GPU memory errors\")\n    print(\"  ‚Ä¢ Performance: slow training, low GPU usage\")\n    print(\"  ‚Ä¢ Generalization: overfitting, poor validation\")\n    \n    # In a notebook, you would use input()\n    # For demo, we'll show how it would work\n    print(\"\\n[In a notebook, you would enter your symptoms here]\")\n    \n# Show the interactive prompt\ninteractive_diagnosis()\n\n# Additional diagnostic utilities\nprint(\"\\n\\nüîß Additional Diagnostic Utilities\")\nprint(\"=\" * 70)\n\ndef check_model_health(model, sample_batch=None):\n    \"\"\"\n    Perform basic health checks on a model.\n    \"\"\"\n    health_report = {\n        \"total_params\": sum(p.numel() for p in model.parameters()),\n        \"trainable_params\": sum(p.numel() for p in model.parameters() if p.requires_grad),\n        \"frozen_params\": sum(p.numel() for p in model.parameters() if not p.requires_grad),\n        \"has_nan_params\": any(torch.isnan(p).any() for p in model.parameters()),\n        \"has_inf_params\": any(torch.isinf(p).any() for p in model.parameters()),\n    }\n    \n    print(\"\\nüìä Model Health Report:\")\n    print(f\"   Total parameters: {health_report['total_params']:,}\")\n    print(f\"   Trainable parameters: {health_report['trainable_params']:,}\")\n    print(f\"   Frozen parameters: {health_report['frozen_params']:,}\")\n    print(f\"   Contains NaN: {'‚ö†Ô∏è YES' if health_report['has_nan_params'] else '‚úÖ NO'}\")\n    print(f\"   Contains Inf: {'‚ö†Ô∏è YES' if health_report['has_inf_params'] else '‚úÖ NO'}\")\n    \n    if health_report['has_nan_params'] or health_report['has_inf_params']:\n        print(\"\\n‚ö†Ô∏è WARNING: Model contains NaN or Inf values!\")\n        print(\"   This will cause training to fail. Reinitialize the model.\")\n    \n    return health_report\n\n# Example usage (would work with actual model)\nprint(\"\\nExample model health check output:\")\nprint(\"(In practice, you would pass your actual model)\")\nmock_health = {\n    \"total_params\": 125_000_000,\n    \"trainable_params\": 125_000_000,\n    \"frozen_params\": 0,\n    \"has_nan_params\": False,\n    \"has_inf_params\": False\n}\nprint(\"\\nüìä Model Health Report:\")\nprint(f\"   Total parameters: {mock_health['total_params']:,}\")\nprint(f\"   Trainable parameters: {mock_health['trainable_params']:,}\")\nprint(f\"   Frozen parameters: {mock_health['frozen_params']:,}\")\nprint(f\"   Contains NaN: {'‚ö†Ô∏è YES' if mock_health['has_nan_params'] else '‚úÖ NO'}\")\nprint(f\"   Contains Inf: {'‚ö†Ô∏è YES' if mock_health['has_inf_params'] else '‚úÖ NO'}\")\n\nprint(\"\\n\\nüí° Pro Tips for Debugging Training Issues:\")\nprint(\"=\" * 70)\nprint(\"1. Always start with a tiny subset of data (10-100 examples)\")\nprint(\"2. Print shapes and values at each step when debugging\")\nprint(\"3. Use torch.autograd.set_detect_anomaly(True) in development\")\nprint(\"4. Monitor GPU memory with: watch -n 1 nvidia-smi\")\nprint(\"5. Save checkpoints frequently to recover from crashes\")\nprint(\"6. Keep a training log with all hyperparameters\")\nprint(\"7. Use wandb or tensorboard for real-time monitoring\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "zphmb3bz4wh",
   "source": "### üéØ How to Use the Diagnostic Tool Effectively\n\nThe diagnostic tool is most effective when you:\n\n1. **Be Specific About Symptoms**: Instead of \"training failed\", describe exactly what happened: \"loss went to inf at step 50\"\n\n2. **Check Multiple Indicators**: Look at loss curves, GPU memory, gradient norms, and validation metrics together\n\n3. **Apply Fixes Incrementally**: Don't change everything at once - apply one fix, test, then proceed\n\n4. **Document What Works**: Keep notes on which solutions work for your specific model and dataset\n\n5. **Prevention is Better**: Use the recommended settings from the start to avoid common issues\n\n**Example Workflow**:\n```python\n# 1. Observe symptoms\nsymptoms = [\"loss spikes after 100 steps\", \"validation loss increasing\"]\n\n# 2. Run diagnosis\ndisplay_diagnostic_results(symptoms)\n\n# 3. Apply recommended fixes one by one\ntraining_args.max_grad_norm = 1.0  # Start with gradient clipping\n\n# 4. Monitor and iterate\n# If issue persists, try next recommendation\n```",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "generation-header",
   "metadata": {},
   "source": [
    "### 4.3 Error Analysis with Model Generation\n",
    "\n",
    "After training, it's crucial to analyze your model's outputs to identify areas for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generation-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Analysis through Generation\n",
    "from transformers import pipeline\n",
    "\n",
    "# Use the model from previous cells\n",
    "# Note: using the saved references from training setup\n",
    "\n",
    "# Create text generation pipeline\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=trained_model,  # Using the model from previous cell\n",
    "    tokenizer=trained_tokenizer,  # Using the tokenizer from previous cell\n",
    "    device=0 if get_device() == \"cuda\" else -1\n",
    ")\n",
    "\n",
    "# Test prompts for medical domain\n",
    "test_prompts = [\n",
    "    \"The patient presented with\",\n",
    "    \"Diagnosis confirmed\",\n",
    "    \"Treatment included\",\n",
    "    \"Post-operative care\"\n",
    "]\n",
    "\n",
    "print(\"Model Generation Examples:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    output = generator(\n",
    "        prompt,\n",
    "        max_length=50,\n",
    "        num_return_sequences=1,\n",
    "        temperature=0.8,\n",
    "        pad_token_id=trained_tokenizer.eos_token_id,\n",
    "        do_sample=True\n",
    "    )\n",
    "    \n",
    "    generated_text = output[0]['generated_text']\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    print(f\"Generated: {generated_text}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\nError Analysis Checklist:\")\n",
    "print(\"‚úì Check for repetition or loops\")\n",
    "print(\"‚úì Verify domain terminology usage\")\n",
    "print(\"‚úì Look for coherence and relevance\")\n",
    "print(\"‚úì Identify any inappropriate content\")\n",
    "print(\"‚úì Note areas needing more training data\")\n",
    "print(\"\\nNote: This uses a pre-trained model without fine-tuning,\")\n",
    "print(\"so outputs may not be domain-specific.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-techniques-header",
   "metadata": {},
   "source": [
    "## Part 5: Advanced Techniques\n",
    "\n",
    "### 5.1 Few-Shot Learning\n",
    "\n",
    "Few-shot learning allows models to adapt to new tasks with just a few examples, without fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "few-shot-learning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-Shot Learning Example\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"gpt2\",\n",
    "    device=0 if get_device() == \"cuda\" else -1\n",
    ")\n",
    "\n",
    "# Medical diagnosis few-shot prompt\n",
    "few_shot_prompt = \"\"\"Classify medical conditions based on symptoms:\n",
    "\n",
    "Symptoms: Chest pain, shortness of breath, sweating\n",
    "Condition: Myocardial infarction\n",
    "\n",
    "Symptoms: Frequent urination, excessive thirst, fatigue\n",
    "Condition: Diabetes mellitus\n",
    "\n",
    "Symptoms: Severe headache, stiff neck, sensitivity to light\n",
    "Condition: Meningitis\n",
    "\n",
    "Symptoms: Persistent cough, fever, difficulty breathing\n",
    "Condition:\"\"\"\n",
    "\n",
    "output = generator(\n",
    "    few_shot_prompt,\n",
    "    max_new_tokens=10,\n",
    "    temperature=0.3,\n",
    "    pad_token_id=generator.tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "print(\"Few-Shot Learning Example:\")\n",
    "print(\"=\" * 60)\n",
    "print(few_shot_prompt)\n",
    "print(\"\\nModel prediction:\", output[0]['generated_text'][len(few_shot_prompt):].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cot-header",
   "metadata": {},
   "source": [
    "### 5.2 Chain of Thought Reasoning\n",
    "\n",
    "Chain of thought prompting helps models break down complex problems into steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chain-of-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain of Thought Example\n",
    "cot_prompt = \"\"\"Diagnose step by step:\n",
    "\n",
    "Patient: 45-year-old male with chest pain and shortness of breath\n",
    "Analysis: Let me evaluate step by step:\n",
    "1. Key symptoms: chest pain + shortness of breath\n",
    "2. These are cardinal symptoms of cardiac issues\n",
    "3. Age (45) puts patient in risk category\n",
    "4. Most likely: Acute coronary syndrome\n",
    "5. Immediate actions: ECG, cardiac enzymes, oxygen\n",
    "Conclusion: Possible myocardial infarction, requires immediate cardiac evaluation.\n",
    "\n",
    "Patient: 28-year-old female with severe headache, fever, and neck stiffness\n",
    "Analysis: Let me evaluate step by step:\"\"\"\n",
    "\n",
    "output = generator(\n",
    "    cot_prompt,\n",
    "    max_new_tokens=120,\n",
    "    temperature=0.3,\n",
    "    pad_token_id=generator.tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "print(\"Chain of Thought Reasoning:\")\n",
    "print(\"=\" * 60)\n",
    "print(cot_prompt)\n",
    "print(\"\\nModel's analysis:\", output[0]['generated_text'][len(cot_prompt):])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "You've completed a comprehensive journey through building custom language models! Let's recap what we've learned:\n",
    "\n",
    "### üéØ Key Achievements:\n",
    "\n",
    "1. **Data Curation Excellence**\n",
    "   - Cleaned and processed text data at scale\n",
    "   - Implemented privacy protection with PII redaction\n",
    "   - Used streaming for memory-efficient processing\n",
    "\n",
    "2. **Custom Tokenization**\n",
    "   - Trained domain-specific tokenizers\n",
    "   - Compared performance with general tokenizers\n",
    "   - Optimized vocabulary for your domain\n",
    "\n",
    "3. **Model Configuration**\n",
    "   - Configured models from scratch\n",
    "   - Adapted pre-trained models efficiently\n",
    "   - Implemented parameter-efficient fine-tuning with LoRA\n",
    "\n",
    "4. **Training Workflows**\n",
    "   - Set up robust training pipelines\n",
    "   - Implemented early stopping and metrics\n",
    "   - Performed error analysis on outputs\n",
    "\n",
    "5. **Advanced Techniques**\n",
    "   - Applied few-shot learning\n",
    "   - Used chain of thought reasoning\n",
    "\n",
    "### üìö Next Steps:\n",
    "\n",
    "1. **Scale Up**: Apply these techniques to larger datasets and models\n",
    "2. **Domain Specialization**: Fine-tune for your specific use case\n",
    "3. **Production Deployment**: Use tools like Hugging Face Hub for model sharing\n",
    "4. **Continuous Learning**: Keep models updated with new data\n",
    "5. **Responsible AI**: Implement bias detection and mitigation\n",
    "\n",
    "### üîó Resources:\n",
    "\n",
    "- Hugging Face Documentation: https://huggingface.co/docs\n",
    "- Dataset Cards: Document your data properly\n",
    "- Model Cards: Share your models responsibly\n",
    "- Community Forums: Join the discussion\n",
    "\n",
    "Remember: Great models start with great data, and success comes from iteration!"
   ]
  },
  {
   "cell_type": "code",
   "id": "sgqadjnpd0m",
   "source": "# Advanced Pipeline Summary Visualization\nprint(\"=\" * 80)\nprint(\"LANGUAGE MODEL DEVELOPMENT PIPELINE - COMPREHENSIVE VISUALIZATION\")\nprint(\"=\" * 80)\n\n# Import visualization libraries\ntry:\n    import matplotlib.pyplot as plt\n    import matplotlib.patches as mpatches\n    from matplotlib.patches import FancyBboxPatch, Circle, Rectangle, Arrow\n    import matplotlib.lines as mlines\n    HAS_MATPLOTLIB = True\nexcept ImportError:\n    print(\"‚ö†Ô∏è matplotlib not available - showing text-based summary instead\")\n    HAS_MATPLOTLIB = False\n\nif HAS_MATPLOTLIB:\n    # Create a comprehensive pipeline visualization\n    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 16))\n    \n    # === Top subplot: Complete Pipeline Flow ===\n    ax1.set_title('Complete Language Model Development Pipeline', fontsize=18, fontweight='bold', pad=20)\n    \n    # Define pipeline stages with enhanced metadata\n    stages = [\n        {\n            'name': 'Data Collection',\n            'y': 8,\n            'color': '#e3f2fd',\n            'icon': 'üìä',\n            'details': ['Quality > Quantity', 'Domain relevance', 'Diverse sources']\n        },\n        {\n            'name': 'Text Cleaning',\n            'y': 7,\n            'color': '#f3e5f5',\n            'icon': 'üßπ',\n            'details': ['Remove noise', 'Normalize text', 'Handle encoding']\n        },\n        {\n            'name': 'Bias Detection',\n            'y': 6,\n            'color': '#fce4ec',\n            'icon': '‚öñÔ∏è',\n            'details': ['Check fairness', 'Mitigate bias', 'Ensure ethics']\n        },\n        {\n            'name': 'Privacy Protection',\n            'y': 5,\n            'color': '#fff3e0',\n            'icon': 'üîí',\n            'details': ['PII redaction', 'GDPR compliance', 'Data security']\n        },\n        {\n            'name': 'Tokenization',\n            'y': 4,\n            'color': '#e8f5e9',\n            'icon': 'üî§',\n            'details': ['Custom vocab', 'Domain terms', 'Efficiency']\n        },\n        {\n            'name': 'Model Config',\n            'y': 3,\n            'color': '#e1f5fe',\n            'icon': '‚öôÔ∏è',\n            'details': ['Architecture', 'PEFT methods', 'Optimization']\n        },\n        {\n            'name': 'Training',\n            'y': 2,\n            'color': '#f1f8e9',\n            'icon': 'üöÄ',\n            'details': ['Monitor metrics', 'Early stopping', 'Checkpointing']\n        },\n        {\n            'name': 'Evaluation',\n            'y': 1,\n            'color': '#efebe9',\n            'icon': 'üìà',\n            'details': ['Error analysis', 'Iteration', 'Validation']\n        },\n        {\n            'name': 'Deployment',\n            'y': 0,\n            'color': '#eceff1',\n            'icon': 'üåê',\n            'details': ['Production ready', 'Scalable', 'Monitored']\n        }\n    ]\n    \n    # Draw enhanced pipeline stages\n    for i, stage in enumerate(stages):\n        # Main stage box\n        box = FancyBboxPatch(\n            (0.1, stage['y'] - 0.4), 6, 0.8,\n            boxstyle=\"round,pad=0.1\",\n            facecolor=stage['color'],\n            edgecolor='black',\n            linewidth=2\n        )\n        ax1.add_patch(box)\n        \n        # Stage icon and name\n        ax1.text(0.2, stage['y'], stage['icon'], fontsize=20, va='center')\n        ax1.text(0.7, stage['y'], stage['name'], fontsize=14, fontweight='bold', va='center')\n        \n        # Stage details\n        details_text = ' ‚Ä¢ '.join(stage['details'])\n        ax1.text(2.5, stage['y'], details_text, fontsize=10, va='center', style='italic')\n        \n        # Progress indicators\n        if i < len(stages) - 1:\n            arrow = mpatches.FancyArrowPatch(\n                (3.1, stage['y'] - 0.5), (3.1, stages[i+1]['y'] + 0.4),\n                connectionstyle=\"arc3,rad=0\", \n                arrowstyle='-|>',\n                mutation_scale=20,\n                color='gray',\n                linewidth=2\n            )\n            ax1.add_patch(arrow)\n        \n        # Side annotations for key considerations\n        if i % 2 == 0:\n            ax1.text(6.5, stage['y'], f\"Step {i+1}\", fontsize=10, \n                    bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))\n    \n    # Add decision points\n    decision_points = [\n        {'y': 6.5, 'text': 'Data Quality Check', 'color': 'orange'},\n        {'y': 3.5, 'text': 'Model Selection', 'color': 'green'},\n        {'y': 0.5, 'text': 'Production Ready?', 'color': 'red'}\n    ]\n    \n    for dp in decision_points:\n        diamond = mpatches.FancyBboxPatch(\n            (7, dp['y'] - 0.2), 1.5, 0.4,\n            boxstyle=\"sawtooth,pad=0.1\",\n            facecolor=dp['color'],\n            alpha=0.3,\n            edgecolor='black'\n        )\n        ax1.add_patch(diamond)\n        ax1.text(7.75, dp['y'], dp['text'], fontsize=9, ha='center', va='center')\n    \n    ax1.set_xlim(-0.5, 9)\n    ax1.set_ylim(-1, 9)\n    ax1.axis('off')\n    \n    # === Bottom subplot: Resource Usage & Efficiency Metrics ===\n    ax2.set_title('Resource Usage & Efficiency Across Pipeline Stages', fontsize=16, fontweight='bold', pad=20)\n    \n    # Create efficiency metrics visualization\n    stage_names = [s['name'] for s in stages]\n    \n    # Simulated metrics for each stage\n    time_hours = [2, 4, 1, 1, 8, 2, 24, 4, 2]  # Time required\n    compute_intensity = [1, 3, 2, 1, 8, 3, 10, 5, 2]  # Compute intensity (1-10)\n    human_effort = [8, 5, 7, 6, 3, 6, 2, 8, 7]  # Human effort required (1-10)\n    \n    x = np.arange(len(stage_names))\n    width = 0.25\n    \n    # Create grouped bar chart\n    bars1 = ax2.bar(x - width, time_hours, width, label='Time (hours)', color='skyblue')\n    bars2 = ax2.bar(x, compute_intensity, width, label='Compute Intensity', color='orange')\n    bars3 = ax2.bar(x + width, human_effort, width, label='Human Effort', color='green')\n    \n    # Add value labels\n    def autolabel(rects, ax):\n        for rect in rects:\n            height = rect.get_height()\n            ax.annotate(f'{height:.0f}',\n                       xy=(rect.get_x() + rect.get_width() / 2, height),\n                       xytext=(0, 3),\n                       textcoords=\"offset points\",\n                       ha='center', va='bottom',\n                       fontsize=8)\n    \n    autolabel(bars1, ax2)\n    autolabel(bars2, ax2)\n    autolabel(bars3, ax2)\n    \n    ax2.set_xlabel('Pipeline Stages', fontsize=12)\n    ax2.set_ylabel('Metric Value', fontsize=12)\n    ax2.set_xticks(x)\n    ax2.set_xticklabels([s.replace(' ', '\\n') for s in stage_names], fontsize=9)\n    ax2.legend()\n    ax2.grid(True, alpha=0.3, axis='y')\n    \n    # Add insights box\n    insights_text = \"\"\"Key Insights:\n‚Ä¢ Tokenization and Training are most compute-intensive\n‚Ä¢ Data collection and evaluation require most human effort\n‚Ä¢ Total pipeline time: ~48 hours for small model\n‚Ä¢ GPU hours can be reduced 90% with PEFT methods\"\"\"\n    \n    ax2.text(0.02, 0.98, insights_text, transform=ax2.transAxes,\n            fontsize=10, verticalalignment='top',\n            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n    \n    plt.tight_layout()\n    plt.savefig('pipeline_comprehensive_visualization.png', dpi=300, bbox_inches='tight')\n    plt.show()\n    \n    # Create a cost-benefit analysis visualization\n    fig, ax = plt.subplots(figsize=(10, 8))\n    \n    # Define approaches\n    approaches = ['Scratch Training', 'Full Fine-tuning', 'LoRA', 'QLoRA', 'Few-shot']\n    costs = [100000, 10000, 1000, 500, 10]  # Estimated costs in USD\n    performance = [100, 95, 92, 90, 85]  # Performance percentage\n    time_to_deploy = [30, 7, 3, 2, 0.1]  # Days\n    \n    # Create bubble chart\n    colors = ['red', 'orange', 'yellow', 'lightgreen', 'green']\n    \n    for i, approach in enumerate(approaches):\n        # Bubble size represents time to deploy\n        size = time_to_deploy[i] * 100\n        ax.scatter(costs[i], performance[i], s=size, c=colors[i], \n                  alpha=0.6, edgecolors='black', linewidth=2)\n        \n        # Add labels\n        ax.annotate(approach, (costs[i], performance[i]), \n                   xytext=(5, 5), textcoords='offset points',\n                   fontsize=10, fontweight='bold')\n    \n    ax.set_xscale('log')\n    ax.set_xlabel('Cost (USD)', fontsize=12)\n    ax.set_ylabel('Performance (%)', fontsize=12)\n    ax.set_title('Cost vs Performance Trade-offs in Language Model Development', \n                fontsize=14, fontweight='bold')\n    ax.grid(True, alpha=0.3)\n    \n    # Add legend for bubble sizes\n    legend_elements = [\n        mlines.Line2D([0], [0], marker='o', color='w', \n                     markerfacecolor='gray', markersize=np.sqrt(100),\n                     label='Size = Time to Deploy (days)')\n    ]\n    ax.legend(handles=legend_elements, loc='lower left')\n    \n    # Add recommendation box\n    rec_text = \"\"\"Recommendations:\n‚Ä¢ Start with Few-shot for rapid prototyping\n‚Ä¢ Use QLoRA for best cost/performance ratio\n‚Ä¢ Consider LoRA for production deployments\n‚Ä¢ Reserve full training for unique requirements\"\"\"\n    \n    ax.text(0.98, 0.02, rec_text, transform=ax.transAxes,\n           fontsize=10, ha='right', va='bottom',\n           bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n    \n    plt.tight_layout()\n    plt.show()\n\nelse:\n    # Text-based summary\n    print(\"\\nüéØ Language Model Development Pipeline Summary\")\n    print(\"=\" * 60)\n    \n    stages_summary = [\n        (\"1. Data Collection\", \"Quality > Quantity, Domain relevance\"),\n        (\"2. Text Cleaning\", \"Remove noise, Normalize text\"),\n        (\"3. Bias Detection\", \"Check fairness, Mitigate bias\"),\n        (\"4. Privacy Protection\", \"PII redaction, Compliance\"),\n        (\"5. Tokenization\", \"Custom vocab, Domain terms\"),\n        (\"6. Model Config\", \"Architecture, PEFT methods\"),\n        (\"7. Training\", \"Monitor metrics, Early stopping\"),\n        (\"8. Evaluation\", \"Error analysis, Iteration\"),\n        (\"9. Deployment\", \"Production ready, Scalable\")\n    ]\n    \n    for stage, details in stages_summary:\n        print(f\"\\n{stage}\")\n        print(f\"   ‚Üí {details}\")\n    \n    print(\"\\n\\nüìä Resource Requirements by Stage:\")\n    print(\"-\" * 60)\n    print(\"Stage               Time    Compute   Human Effort\")\n    print(\"-\" * 60)\n    \n    metrics = [\n        (\"Data Collection\", \"2h\", \"Low\", \"High\"),\n        (\"Text Cleaning\", \"4h\", \"Medium\", \"Medium\"),\n        (\"Bias Detection\", \"1h\", \"Low\", \"High\"),\n        (\"Privacy Protection\", \"1h\", \"Low\", \"Medium\"),\n        (\"Tokenization\", \"8h\", \"High\", \"Low\"),\n        (\"Model Config\", \"2h\", \"Medium\", \"Medium\"),\n        (\"Training\", \"24h\", \"Very High\", \"Low\"),\n        (\"Evaluation\", \"4h\", \"Medium\", \"High\"),\n        (\"Deployment\", \"2h\", \"Low\", \"High\")\n    ]\n    \n    for stage, time, compute, human in metrics:\n        print(f\"{stage:<20} {time:<8} {compute:<10} {human}\")\n    \n    print(\"\\n\\nüí∞ Cost-Performance Trade-offs:\")\n    print(\"-\" * 60)\n    print(\"Approach          Cost      Performance   Time to Deploy\")\n    print(\"-\" * 60)\n    print(\"Scratch Training  $100,000  100%         30 days\")\n    print(\"Full Fine-tuning  $10,000   95%          7 days\")\n    print(\"LoRA             $1,000    92%          3 days\")\n    print(\"QLoRA            $500      90%          2 days\")\n    print(\"Few-shot         $10       85%          2 hours\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"FINAL RECOMMENDATIONS\")\nprint(\"=\" * 80)\n\nprint(\"\\nüöÄ Quick Start Guide:\")\nprint(\"1. Begin with few-shot learning for rapid prototyping\")\nprint(\"2. Use QLoRA for cost-effective fine-tuning\")\nprint(\"3. Implement comprehensive monitoring from day one\")\nprint(\"4. Iterate based on real-world performance\")\n\nprint(\"\\n‚ö° Efficiency Tips:\")\nprint(\"‚Ä¢ Train custom tokenizers for 20-50% token reduction\")\nprint(\"‚Ä¢ Use mixed precision training for 2x speedup\")\nprint(\"‚Ä¢ Implement gradient checkpointing for memory savings\")\nprint(\"‚Ä¢ Enable model parallelism for large models\")\n\nprint(\"\\nüìö Next Steps:\")\nprint(\"‚Ä¢ Experiment with your own domain data\")\nprint(\"‚Ä¢ Join the Hugging Face community\")\nprint(\"‚Ä¢ Share your models and learnings\")\nprint(\"‚Ä¢ Keep learning and iterating!\")\n\nprint(\"\\n‚ú® Remember: Great models come from great data and thoughtful iteration!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "xpqav2eito9",
   "metadata": {},
   "source": [
    "## Common Pitfalls & Troubleshooting\n",
    "\n",
    "Avoid these frequent issues to save time and compute:\n",
    "\n",
    "| Pitfall | Symptoms | Solution |\n",
    "|---------|----------|----------|\n",
    "| **OOM Errors** | CUDA out of memory | Reduce batch size, enable gradient accumulation, use mixed precision |\n",
    "| **Tokenizer Mismatch** | Unexpected tokens, errors | Verify vocab_size matches, check special tokens alignment |\n",
    "| **Learning Rate Issues** | Loss explosion or no progress | Use warmup, try different schedulers, start with 2e-5 |\n",
    "| **Data Leakage** | Unrealistic high performance | Ensure train/val/test splits are clean, check for duplicates |\n",
    "| **Checkpoint Bloat** | Disk space issues | Save only best models, delete intermediate checkpoints |\n",
    "| **Version Conflicts** | Import errors, API issues | Use accelerate>=0.26.0, check transformers compatibility |\n",
    "\n",
    "### üöÄ Quick Debugging Checklist:\n",
    "- ‚úÖ Print model and data shapes before training\n",
    "- ‚úÖ Test with a tiny subset first (10-100 examples)  \n",
    "- ‚úÖ Monitor GPU memory with `nvidia-smi -l 1`\n",
    "- ‚úÖ Use gradient clipping for stability\n",
    "- ‚úÖ Enable anomaly detection in development: `torch.autograd.set_detect_anomaly(True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercises-header",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Try these exercises to deepen your understanding:\n",
    "\n",
    "1. **Data Quality Challenge**: Create a more sophisticated PII detector that handles edge cases\n",
    "2. **Tokenizer Optimization**: Train a tokenizer on your own domain data and measure improvement\n",
    "3. **PEFT Exploration**: Compare LoRA with other PEFT methods like Prefix Tuning\n",
    "4. **Metrics Design**: Implement custom evaluation metrics for your domain\n",
    "5. **Deployment Pipeline**: Create a complete pipeline from data to deployed model\n",
    "\n",
    "Share your results with the community!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y9u96xun0e",
   "metadata": {},
   "source": [
    "## Glossary of Terms\n",
    "\n",
    "| Term | Definition |\n",
    "|------|------------|\n",
    "| **Tokenization** | Splitting text into model-ready pieces (tokens) |\n",
    "| **Streaming** | Loading data in batches instead of all at once |\n",
    "| **Checkpointing** | Saving model progress during training |\n",
    "| **Early Stopping** | Halting training when improvement stalls |\n",
    "| **PEFT** | Parameter-Efficient Fine-Tuning techniques |\n",
    "| **LoRA** | Low-Rank Adaptation for efficient fine-tuning |\n",
    "| **QLoRA** | Quantized LoRA for even lower memory usage |\n",
    "| **Perplexity** | Measure of how well a model predicts text |\n",
    "| **Human-in-the-Loop** | Involving people in labeling or reviewing data |\n",
    "| **PII** | Personally Identifiable Information |\n",
    "| **Bias Mitigation** | Techniques to reduce unfair model behavior |\n",
    "| **Synthetic Data** | Artificially generated training examples |\n",
    "| **Data Versioning** | Tracking changes to datasets over time |\n",
    "| **Mixed Precision** | Using FP16/BF16 for faster training |\n",
    "| **Gradient Accumulation** | Simulating larger batches on limited memory |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}